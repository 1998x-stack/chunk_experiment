\section{Introduction}

In many language modeling applications, the speech or text is associated with some metadata or contextual information. For example, in speech recognition, if a user is speaking to a personal assistant then the system might know the time of day or the identity of the task that the user is trying to accomplish. If the user takes a picture of a sign to translate it with their smart phone, the system would have contextual information related to the geographic location and the user's preferred language. The context-aware language model targets these types of applications with a model that can adapt its predictions based on the provided contextual information.

There has been much work on using context information to adapt language models. Here, we are interested in contexts described by metadata (vs.\ word history or related documents) and in neural network approaches due to their flexibility for representing diverse types of contexts. Specifically, we focus on recurrent neural networks (RNNs) due to their widespread use. 

The standard approach to adapt an RNN language model is to concatenate the context representation with the word embedding at the input to the RNN \cite{mikolov2012context}. Optionally, the context embedding is also concatenated with the output from the recurrent layer to adapt the softmax layer. This basic strategy has been adopted for various types of adaptation such as for LM personalization \cite{wen2013recurrent,li2016persona}, adapting to television show genres \cite{chen2015recurrent}, adapting to long range dependencies in a document \cite{Ji2015DocumentCL}, etc.

We propose a more powerful mechanism for using a context vector, which we call the FactorCell. Rather than simply using context as an additional input, it is used to control a factored (low-rank) transformation of the recurrent layer weight matrix. The motivation is that allowing a greater fraction of the model parameters to be adjusted in response to the input context will produce a model that is more adaptable and responsive to that context. 


We evaluate the resulting models in terms of context-dependent perplexity and context classification accuracy on six tasks reflecting different types of context variables, comparing to baselines that represent the most popular methods for using context in neural models. 
We choose tasks where context is specified by metadata, rather than text samples as used in many prior studies.
The combination of experiments on a variety of data sources provides strong evidence for the utility of the FactorCell model, but the results show that it can be useful to consider more than just perplexity in training a language model.


The remainder proceeds as follows. In Section \ref{sec:model}, we introduce the FactorCell model and show how it differs mathematically from alternative approaches. Next, Section \ref{sec:data} describes the six datasets used to probe the performance of different models. Experiments and analyses contrasting perplexity and classification results for a variety of context variables are provided in Section \ref{sec:experiments}, demonstrating consistent improvements in both criteria for the FactorCell model but also confirming that perplexity is not correlated with classification performance for all models. Analyses 
explore the effectiveness of the model  for characterizing high-dimensional context spaces. The model is compared to related work in Section~\ref{sec:prior}. Finally, Section~\ref{sec:concl} summarizes contributions and open questions.
