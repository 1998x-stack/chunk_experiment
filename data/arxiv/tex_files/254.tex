\section{Conclusion}
\label{sec:concls}

In this paper, we propose Contrastive Learning,
a new learning method for image captioning.
By employing a state-of-the-art model as a reference,
the proposed method is able to maintain the optimality of the target model,
while encouraging it to learn from distinctiveness,
which is an important property of high quality captions.
On two challenging datasets, namely MSCOCO and InstaPIC-1.1M,
the proposed method improves the target model by significant margins,
and gains state-of-the-art results across multiple metrics.
On comparative studies,
the proposed method extends well to models with different structures,
which clearly shows its generalization ability.

\paragraph{Acknowledgment}
This work is partially supported by
the Big Data Collaboration Research grant from SenseTime Group (CUHK Agreement No.TS1610626), 
the General Research Fund (GRF) of Hong Kong (No.14236516)
and the Early Career Scheme (ECS) of Hong Kong (No.24204215).
