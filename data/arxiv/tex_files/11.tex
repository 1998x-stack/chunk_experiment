\subsection{User Experiments}

%Once we had a working prototype, measuring user acceptance of the proposed interfaces and interactions were the natural following step towards proposing an affordable CRS, aiming its broader usage.

We applied usability testing on a small subject sample (N = 11), employing direct observation, user and interaction recording, semi-structured interviews and a questionnaire. Although we have found relevant usability issues, we concluded that the proposed prototype was adequate as CRS. Usability tests are effective when compared to the field testing~\cite{kaikkonen2005usabilitytests}, and can be cost effective with a small number of subjects: Nielsen Normal Group\footnote{How Many Test Users in a Usability Study - https://www.nngroup.com/articles/how-many-test-users/} points out 5 samples can provide an important usability insight. We detail the user-interaction/interview findings in Table~\ref{tab:user_device_interaction_findings}, and summarize the questionnaire findings in Table~~\ref{tab:user_questionnaire_findings_compilation}.

%, although this is still open to research~\cite{turner2006usabilitytestsamplesize}.


% We considered usability testing evaluation paradigm would suit our needs, as it consists of "measuring typical users' performance on carefully prepared tasks that are typical of those for which the system was designed"~\cite{preece2002interaction}, frequently using a system or interface prototype. Usability testing is also a proven paradigm, as it has being around since computational systems gained popularity, encompassing several activities reaching non-specialized end users~\cite{melkus1985labtesting}.

%Despite the controlled environment,

We tested two use cases, covering typical usage:

\textit{First use case --- starting the class: launching the app and performing a roll call.} The teacher starts the paperclickers application on her mobile device, and then chooses the class to start. After the students arrive, she touches the roll call icon. She asks the students to raise their cards (in any orientation) and films the entire class. She touches the screen to advance to the result screen. The application shows the roll call result, if some student is present but has not been detected, the teacher can correct the status by tapping the corresponding icon on the device screen. The teacher touches the "done" icon to finish the roll call procedure.

\textit{Second use case --- asking a question: during class the teacher polls the students.} The teacher wants to verify the students' understanding of a given topic. He opens the paperclickers application and touches the "Start" button. He chooses a number for the question. He enunciates a multiple-choice question, and waits for the students to commit to an answer; then he asks the students to lift their cardboards to indicate the chosen answer, using the letters printed on the back of the card as cue (the chosen letter must be upright). The teacher touches the "Collect answer" button to advance to the scan screen. After capturing the answers, he touches the screen to advance to the detailed results screen. If many answers are missing, he can choose to go back to the scan screen, and then the application would merge the results from both scans. He can also touch the icons to manually change the answers. If the answers are correct, the teacher can touch the graph icon to advance to the summary results screen, that shows a pie chart. At this point, the teacher can touch the "Try again" button to return to the scan screen or the "New question" button to pick the number of the next question.

The prompts we gave to the test subjects were much less directive than the detailed scripts shown above. For example, we would ask the users "please, start a roll-call" not "touch the roll-call icon", and would observe if the users were able to figure the interface by themselves. Only when the users were blocked for several minutes we would give a direct prompt.

Our experiments ended up reflecting the DECIDE framework, as described by Preece et al.~\cite{preece2002interaction}, which establishes a checklist comprised of 6 steps to guide the evaluation preparation: \textit{“Determine the overall goals that the evaluation addresses; Explore the specific questions to be answered; Choose the evaluation paradigm and techniques to answer the questions; Identify the practical issues that must be addressed, such as selecting participants; Decide how to deal with the ethical issues; Evaluate, interpret, and present the data”}.

\emph{Determine the goals:}
\begin{itemize}
    \item The solution offers a convenient and consistent user interaction, satisfying the user;
    \item The overall design allows the user to perform easily and efficiently the required tasks, suitable to the users' real problem;
    \item It is easy to learn how to use the solution.
\end{itemize}

\emph{Explore the questions:}
\begin{itemize}
    \item Is the \textit{answers capturing} screen, with the augmented reality codes visualization, legible and readily explainable to the user?

    \item Are the \textit{detailed answers visualization} and \textit{answers chart} screens legible and readily explainable to the user?

    \item Is the screen navigation throughout the application consistent and does it match user expectations?
\end{itemize}

\emph{Choose evaluation paradigm and techniques:}

%We decided to apply the following usability test techniques (considering Preece et al.~\cite{preece2002interaction} terminology):

\begin{itemize}
    \item Direct observation and monitoring;

    \item Recording of the user with a video camera;

    \item Recording of the user interface with screencap;

    \item Semi-structured interview after the experiments, asking about the overall experience and main difficulties;
    %: \textit{"How do you like the overall idea?"}, \textit{"Do you believe this application would be useful in the classroom, considering both teachers and students?"}, \textit{"Did you have any difficulties to use the application? Have you found any issue which might prevent its proper usage in a classroom?"}, \textit{"Do you have any improvement suggestion, either for the overall solution or the application usability?"};

    \item Questionnaire after the experiments, exploring quantitative information on the user satisfaction and understanding about specific visual elements.
    %; we used Google Forms\footnote{Google Forms - https://www.google.com/forms/about/}.
\end{itemize}


% During the semi-structured interview we posed general questions in order to gather information about the overall user experience and the main difficulties faced while using the solution; we also asked about the user opinion about the application proposal and its applicability/feasibility considering the original problem: \textit{"How do you like the overall idea?"}, \textit{"Do you believe this application would be useful in the classroom, considering both teachers and students?"}, \textit{"Did you have any difficulties to use the application? Have you found any issue which might prevent its proper usage in a classroom?"}, \textit{"Do you have any improvement suggestion, either for the overall solution or the application usability?"}.

% Through the questionnaire we aimed to gather quantitative information, exploring the user satisfaction and understanding about specific visual elements on each application's screens. We used Google Forms\footnote{Google Forms - https://www.google.com/forms/about/} to apply this questionnaire.


\emph{Identify practical issues:}

\begin{itemize}
    \item The tests would be applied on volunteer participants older than 18-year old. We did not put any other restrictions, but since we announced the test in the University, we knew we would be mainly sampling graduate and undergraduate students. Although a broader audience would be desirable, we considered that a sample of students was aligned with at least part of the target users, providing thus already valuable feedback. Broader audiences could be addressed later, on a refined product.

    \item We defined test scripts, to be used as instructions during the experiment, for both the applier and the test subjects.

    \item The experiment procedure considered only one participant using the application; we fixed the cardboards on the backrests of the class' seats, simulating the students answering performance during the class. A research team member would follow for support.

    \item We defined a controlled environment, using two rooms at the University: the first for subjects using the app, and the second room for the semi-structured interview and filling the questionnaire.
\end{itemize}

% We defined the tests would be applied on volunteer participants older than 18-year old, but user characteristics --- such as gender or formal education level --- would not be accounted.

% We used public calls for professors and students from the School of Electrical and Computer Engineering and from the Computer Science Institute, both at the University of Campinas - UNICAMP.

% We defined test scripts to be followed during the experiments both by the applier and by the test subject; that helped predicting possible adverse situations. The applier script contained general instructions, as environment configuration and recommendations to the users; the test subject script was intended to be used as instructions during the experiment, defining structured tasks to be executed to explore the use cases described in the test scenario.

% The experiment procedure considered only one participant using the application, since we fixed the cardboards on the backrests of the class' seats, simulating the students answering performance during the class. A member from our research group were present during the experiment to support the test subject if required.

% The experiments were conducted in a controlled environment: we used two rooms at the research group university, optimizing the experiments execution. The first classroom was designed for the application usage and the second room was a separated environment used to collect the participation opinion through the semi-structured interview and the questionnaire completion.

% In the first classroom, we distributed 9 codes all over the class; the cardboards were full A4 page sized and we provided the user test script. We positioned a camera in the classroom to capture the subject reactions and handled to the user the test device with the interaction recording enabled. We certified the environment conditions were appropriated (e.g. lights, climate) and all participants received the same instructions, following the defined tester script.

% In the second room, we installed two computers with the post-test questionnaire in order to optimize the experiment; we also audio recorded the semi-structured interview.

\emph{Decide how to deal with the ethical issues:}

Although the proposed tests corresponded to the simple indoor usage of a smartphone application, without repetitive actions or sensitive data collection, we identified and planned to mitigate any ethical concerns.

\begin{itemize}
    \item The privacy of user information gathered throughout the usability tests, the interview and questionnaire, also including the recorded personal image; we created an Informed Consent Form to clarify our privacy agreement.

    \item Any discomfort the users might few performing the tests, related to shyness of begin recorded or interviewed, for example; we provided clear and formal recommendations about the absolute freedom the participants had to leave the experiment during any phase.
\end{itemize}

The experiment was approved by the Brazilian research ethics committee.

% To deal with these issues, we created an Informed Consent Form to clarify our privacy agreement and to provide clear and formal recommendations about the absolute freedom the participants had to leave the experiment anytime.

% We received the approval\footnote{UNICAMP Ethical Committee approval is registered under number 1.073.125 from 21/05/2015} for our user experiments from the UNICAMP Ethical Committee, the entity responsible for analyzing the project risks, benefits and confidentially compromise.

% During the experiments we did our best effort to keep the environment as much informal as possible, making sure to confirm the test participant desire to carry on the test steps, right before the application usage but also before starting the semi-structure interview and the questionnaire completion.

\begin{table*}[!t]
    \begin{center}
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}{ p{0.04\textwidth} | >{\raggedright\arraybackslash}p{0.15\textwidth} | >{\raggedright\arraybackslash}p{0.15\textwidth} | >{\raggedright\arraybackslash}p{0.15\textwidth} | >{\raggedright\arraybackslash}p{0.15\textwidth} | >{\raggedright\arraybackslash}p{0.20\textwidth}}
            \hline
            \textbf{Tester} & \textbf{Backward navigation} & \textbf{Roll call (task 1)} & \textbf{Answers scan (task 2)} & \textbf{Test script} & \textbf{Additional comments} \\
            \hline
            \centering 1 & Misleading “Camera close” message; Inconsistent behavior & Could not change student status & Didn't use “New question” for next question & & Might reduce the teachers/students relation \\
            \hline
            \centering 2 & Inconsistent behavior & Unable to execute roll-call feature & Didn't use “New question” for next question & \\
            \hline
            \centering 3 & & Could not start feature without help; Could not change student status & Looked for additional information on chart screen & Didn't understand how to answer script question & \\
            \hline
            \centering 4 & & Unclear presence/absence icons & Looked for additional information on chart screen & & Liked roll call feature agility \\
            \hline
            \centering 5 & & Problems to start roll-call feature; Detection problems & Detection problems; Looked for additional information on chart screen & Didn't understand how to answer script question & Problems to dismiss about screen \\
            \hline
            \centering 6 & Misleading “Camera close” message & Unclear roll-call icon; Detection problems & Detection problems; Didn't use “New question” for next question & & Application low speed; Missing back option in detection screens; Focused on specific usage scenarios \\
            \hline
            \centering 7 & Misleading “Camera close” message; Inconsistent behavior & Problems to understand roll call feature & Detection problems & & The single device requirement might not be low cost; Students having to keep big cardboard signs might be a problem \\
            \hline
            \centering 8 & & Problems to start roll call feature & Detection problems & & Scanning large classroom could be cumbersome \\
            \hline
            \centering 9 & Inconsistent behavior & Unable to execute roll call feature & Used "New question" but couldn't realize the question number auto increment & \\
            \hline
            \centering 10 & & Problems to start roll call feature & Detection problems & Didn't understood how to answer script question & Forced landscape orientation; Found inconsistent the ability to change student presence while changing answer; Asked for more than 4 answers' choices; Question about detection in real classrooms \\
            \hline
            \centering 11 & & Detection problems & Detection problems & & Problems to dismiss class selection list; Would be nice to have the question text; Its usage might distrait the students \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Recording the interaction of user with the app provided the most actionable information on the usability tests test, which were positive regarding application usage, but revealed that some features and navigation were confusing to users.}
    \label{tab:user_device_interaction_findings}
\end{table*}


\begin{table*}[!t]
    \begin{minipage}[t]{0.5\linewidth}
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}[t]{ >{\raggedright\arraybackslash}p{0.50\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth}}
            \hline
            \textbf{Element} & \textbf{L/A} & \textbf{In} & \textbf{D} & \textbf{DU} \\
            \hline
            Application forced landscape & 2 & 3 & 6 & \\
            \hline
            Initial screen -- class selection option & 8 & & & 3 \\
            \hline
            2\textsuperscript{nd} screen -- question selection option & 8 & & 1 & 2 \\
            \hline
            2\textsuperscript{nd} screen -- question auto increment & 4 & 7 & & \\
            \hline
            2\textsuperscript{nd} screen -- roll call separated from answers scanning & 6 & 2 & 3 & \\
            \hline
            2\textsuperscript{nd} screen -- roll call icon & 5 & & 3 & 3 \\
            \hline
            Scanning screen -- understood augmented reality cardboard indications & 8 & 3 & & \\
            \hline
            Scanning screen -- augmented reality cardboard indications & 6 & 5 & & \\
            \hline
            Scanning screen -- found augmented reality feedback slow & 6 & 5 & & \\
            \hline
            Scanning screen -- cardboards capture finalization method & & 3 & 8 & \\
            \hline
		    Roll call results screen -- easily understood & 9 & 2 & & \\
            \hline
		    Roll call results screen -- presence/absence icons understanding & 5 & & & 1 \\
            \hline
		    Roll call results screen -- would like to have student name or picture along presence/absence icons & 5 & 6 & & \\
            \hline
		    Roll call results screen -- easily understood presence/absence icons were clickable & 5 & 6 & & \\
            \hline
		    Roll call results screen -- screen closing icon & 5 & & 6 & \\
            \hline
            Detailed answers screen -- layout & 10 & 1& & \\
            \hline
            Detailed answers screen -- easily understood answers were clickable and could be changed & 6 & 1 & & 4  \\
            \hline
            Detailed answers screen -- understood “X” answer indication & 7 & 3 & & 1 \\
            \hline
            Detailed answers screen -- understood chart screen icon & 11 & & & \\
            \hline
            Detailed answers screen -- “back” icon & 8 & & 3 & \\
            \hline
        \end{tabular}%
    \end{minipage}%
    \begin{minipage}[t]{0.5\linewidth}
        \renewcommand{\arraystretch}{1.5}
        \begin{tabular}[t]{ >{\raggedright\arraybackslash}p{0.50\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth} | >{\centering\arraybackslash}p{0.05\textwidth}}
            \hline
            \textbf{Element} & \textbf{L/A} & \textbf{In} & \textbf{D} & \textbf{DU} \\
            \hline
            Detailed answers screen -- correctly understood “back” icon would return to the scanning screen & & 2 & & 9 \\
            \hline
            Detailed answers screen -- understood “back” icon would return to the process beginning & 4 & 7 & & \\
            \hline
            Chart screen & 10 & & 1 & \\
            \hline
            Chart screen -- correctly understood “Try again” button would return to scan screen keeping the question & 7 & 1 & & 3 \\
            \hline
            Chart screen -- understood “Try again” button would return to detailed answers screen keeping the question & 1 & 1 & & 9 \\
            \hline
            Chart screen -- understood “Try again” button would return to the initial screen for class selection screen & 2 & 1 & & 8 \\
            \hline
            Chart screen -- correctly understood “New question” button would finalize the question and return to the question selection screen & 8 & & & 3 \\
            \hline
            Chart screen -- understood “New question” button would return to the answers scanning screen & 2 & & & 9 \\
            \hline
            Chart screen -- understood “New question” button would return to the detailed answers screen & 1 & & & 10 \\
            \hline
            Chart screen -- correctly understood “BACK” button would finalize the question and return to the initial screen for class selection & 3 & & & 8 \\
            \hline
            Chart screen -- understood “back” button would finalize the question and return to the question selection screen & 4 & & & 7 \\
            \hline
            Chart screen -- understood “back” button would finalize the question and return to the answers scanning screen & 1 & & & 10 \\
            \hline
            Chart screen -- understood “back” button would finalize the question and return to the detailed answers screen & 3 & & & 8 \\
		    \hline
        \end{tabular}%
    \end{minipage}%
    \caption{User questionnaire findings compilation: L = Liked; A = Agree; D = Disliked; DU = Didn't understand; In = Indifferent. Semi-structured interviews provided quantitative data, mostly reinforcing the usability test findings of the device interaction recording. We also captured users' preferences on other aspects, e.g., discontentment with the forced landscape orientation.}
    \label{tab:user_questionnaire_findings_compilation}
\end{table*}


\emph{Evaluate, interpret and present the data:}

\begin{itemize}
    \item The overall feedback was positive regarding the application usage and suitability to the proposed tasks: its main features were easily recognized and all the intended tasks successfully and easily performed by the majority of the testers;

    \item All the testers were able to successfully scan the class for results --- understanding the overall usability, including the augmented reality feedback --- as well as to read and manipulate the detection results in the detailed answers screen;

    \item We found two major usability issues about application convenience (roll call feature identification and initialization) and consistency (backward navigation throughout the application's screens);

    \item The user interaction recording provided the most valuable data, identifying the users' actions along with users' impressions, through touches or audible comments (also recorded); the post-test semi-structured interview provided important data to confirm the findings, adding overall impressions on the application proposal.
\end{itemize}



% We had a total of 11 participants on paperclickers user experiments, whom have given an overall positive feedback regarding the application usage and suitability to the proposed tasks: its main features were easily recognized and all the intended tasks successfully and easily performed by the majority of the testers.

% The results have indicated positive answers to our research questions, with good user performance on the answers scanning screen and also on the detailed answers screen: all the testers were able to successfully scan the class for results --- understanding the overall usability, including the augmented reality feedback --- as well as to read and manipulate the detection results in the detailed answers screen. However we found two major usability issues about application convenience (roll call feature identification and initialization) and consistency (backward navigation throughout the application's screens).

% During the experiment analysis, we found the user interaction recording provided the most valuable data, being the information source which unmistakably identified the users' actions on the application along with their behavior, giving clear clues on their sureness --- or uncertainty --- about how to perform the script tasks, noticeable through their interaction pace and audible comments, which were also recorded by the used tool.

% The post-test semi-structured interview provided important data to confirm the findings of the user interaction recording, along with the overall impressions on the application proposal.


% Regarding the roll call feature, it is important to notice that:

% \begin{itemize}
%     \item 3 users could not execute the feature at all; 1 of them only executed after receiving a unexpected help from the test supervisor;
%     \item 3 users experimented difficulties to start the roll call feature, taking time to recognize the roll call icon;
%     \item 1 user had difficulties in understanding the roll call feature;
%     \item 2 users could not change the students' presence status
% \end{itemize}

The recordings made clear the second screen was confusing and inconvenient: users were requested to perform a roll call --- reachable by an icon on the upper left corner --- but the main graphic elements were the "question number definition" box and its controls, and the "Collect answer" button (refer to figure~\ref{fig:old_questionSelection}). We can infer this confusion through the users reactions: some of them navigated backwards --- either through the device operational system "back" key or using the "home" icon --- and some of them even expressed audible surprise, giving the impression they were expecting something else.

% Regarding the backward navigation, although only 5 users directly experimented or reported difficulties on the user interaction recordings or the semi-structured interview, some interaction problems became very clear --- and were deeply confirmed through the questionnaire analysis:

% \begin{itemize}
%     \item there were different icons representing essentially the same action --- going back in the application flow;
%     \item inconsistent behavior of backward navigation elements: depending on the screen they return one, two or three screens back, frustrating the regular user experience of returning to the immediately previous screen
% \end{itemize}

We found consistency issues related to backwards navigation. Depending on the screen, backward navigation lead the user one, two or even three screens back. That was not only internally inconsistent, but also mismatched Android's expected behavior. One egregious example was the navigation from the chart screen, which represents the end of the scanning process: as visible in figure~\ref{fig:old_chart}, there were 4 different UI elements to navigate backwards, each one with a different behavior. Although those options gave users flexibility, they were very confusing.

% , besides the device operational system "BACK" key; the test script requested the user to scan a second question and the proper way was using the "New question" button --- this would lead to the question auto increment; 3 users haven't used that button and it was not clear the others who used were properly aware of its meaning.

% Other observation worth mentioning was 3 users tried to slide up the chart screen, apparently looking for additional information; the fact that happen right at the point the test script asked the user \textit{"Can you tell how many students have answered A?"} gives the impression they were looking for this information somewhere else, since the pie chart only presented the answers' percentage values.

% This test script question has also pointed out a minor deficiency on the instructions, since 3 users clearly stated doubt on how to answer it, looking for a place to fill out the answer.

During the semi-structured interview all the testers gave positive feedback on the application and usage scenario, but expressed a few concerns, like whether its usage might distract the students, might reduce intimacy between teachers and students distance, or might be unreliable on large classrooms.

% however, some of them added some comments considering its usage would be restricted, might distrait the students and increase the teachers/students distance. There were also concerns about the detection reliability and usability on large classrooms, as well as the requirement of the students keeping large cardboards with them.

The questionnaire data analysis (Table~~\ref{tab:user_questionnaire_findings_compilation}) was important mainly to confirm the same issues detected through the user interaction and interview, providing quantitative data regarding users' preferences on other aspects, like the fact most of the users disliked the forced landscape orientation of the app.

% : the backward navigation problem became more explicit, indicating the misunderstanding about the icons meaning and expected behavior; in one case --- the "BACK" button behavior in the chart screen --- the majority of users (8) wrongly understood the intended meaning. In fact, having so many questions about the backward navigation in the questionnaire --- as for the chart screen --- shows an anticipation of the problem, as we already understood screen navigation is a important aspect of the user experience.

% Considering our initial research questions, one important information we have got from the questionnaire data analysis, is the fact the majority of the users (8) complained about the scanning screen finalization method, indicating they had difficulties like \textit{"unresponsive touch"}, having \textit{"had to make several attempts before exiting"}, \textit{"exiting by accident"} or even \textit{"having difficulties to understand how to exit"}.



% ; almost half of them would like to have the students names or pictures in the roll call results screen; or the fact half of the users disliked the roll call results screen closing icon.


\begin{table*}[p]
    \begin{tabular}[t]{m{0.5\textwidth}m{0.5\textwidth}}
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/old_initialScreen_800x450}}
            \captionof{figure}{Initial screen -- original version}
            \label{fig:old_initialScreen}
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\linewidth]{figures/initialScreen_800x450}}
            \captionof{figure}{Initial screen -- released version}
            \label{fig:initialScreen}
        \end{minipage} \\
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/old_questionSelection_800x450}}
            \captionof{figure}{Question selection screen -- original version; roll call feature accessible in upper-right icon}
            \label{fig:old_questionSelection}
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            Screen removed on released version
        \end{minipage} \\
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/old_rollCallResult_800x450}}
            \captionof{figure}{Roll call result screen -- original version}
            \label{fig:old_rollCallResult}
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            Screen removed on released version
        \end{minipage} \\
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/old_answersScan_800x450}}
            \captionof{figure}{Scan screen -- original version}
            \label{fig:old_answersScan}
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\linewidth]{figures/answersScan_800x450}}
            \captionof{figure}{Scan screen -- released version}
            \label{fig:answersScan}
        \end{minipage} \\
    \end{tabular}
\end{table*}

\begin{table*}[p]
    \begin{tabular}[t]{m{0.5\textwidth}m{0.5\textwidth}}
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/old_detailedAnswers_800x450}}
            \captionof{figure}{Detailed answers screen -- original version}
            \label{fig:old_detailedAnswers}
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\linewidth]{figures/detailedAnswers_800x450}}
            \captionof{figure}{Detailed answers screen -- released version}
            \label{fig:detailedAnswers}
        \end{minipage} \\
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/old_chart_800x450}}
            \captionof{figure}{Chart screen -- original version}
            \label{fig:old_chart}
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.9\textwidth]{figures/chart_800x450}}
            \captionof{figure}{Chart screen -- released version}
            \label{fig:chart}
        \end{minipage} \\
        \begin{minipage}{0.5\textwidth}
            \centering
            Not included in original version
        \end{minipage} &
        \begin{minipage}{0.5\textwidth}
            \centering
            \setlength{\fboxsep}{0pt}\fbox{\includegraphics[width=.5\textwidth]{figures/settings_450x800}}
            \captionof{figure}{Settings screen -- released version}
            \label{fig:settings}
        \end{minipage} \\
    \end{tabular}
\end{table*}



