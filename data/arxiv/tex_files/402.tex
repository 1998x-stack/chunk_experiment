%
%
%
Let $ \{ B(t),  t \in [0,T] \}$ be a Brownian motion adapted to the natural filtration on some measurable space $ (\Omega, \mathscr F) $
and let $ \{ P_u , u \in \mathbb R \} $ be a family of probability measures such that, under each $ P_u $, $ B $ is a Brownian motion and $  P(B(0) = u) = 1$. 
We consider a drifted Brownian motion $ \{ B^\mu (t), 0 \leq t \leq T\}  $ 
defined as $ B^\mu ( t) = B(t) + \mu t \, , 0 \leq t \leq T  $, 
with $ \mu \in \mathbbm{R} $.
The space $ C[0,T] $ of its sample paths, sometimes indicated as $ \omega = \omega(t) $,
is endowed with the Borel $ \sigma $-algebra $ \mathscr C $ generated by the open sets induced 
by the supremum metric. 

For a given probability space $ (\Omega, \mathscr F, P) $
we define the random function 
\begin{equation}\label{eq:rand-fun}
Y: (\Omega, \mathscr F) \mapsto (C[0,T], \mathscr C) \,\, .
 \end{equation}
%
%
We take a probability measure $ \mu $ on $ (C[0,T], \mathscr C) $ defined as
%
%
\begin{equation}
\mu(A) = P(Y^{-1} ( A)) \qquad A \in \mathscr C \,\, .
\end{equation}
%
%
%The random function $ Y $ induces a new probability 
%$ (C[0,T], \mathscr C, Q) $ . 

For a set $ \Lambda \in \mathscr C $ such that $ \mu(\Lambda) > 0 $  we consider the space 
%\begin{equation}\label{eq:trace}
$
( \Lambda,  \mathscr C, \mu(\,\cdot \, | \Lambda ))
$
%\end{equation}
%
which is the trace of $ (C[0,T], \mathscr C, \mu) $ on the set $ \Lambda $,  where 
the conditional  probability measure $  \mu(\,\cdot \, | \Lambda ) : \Lambda \cap \mathscr C \mapsto [0,1]  $
is defined in the usual sense as
%
\begin{equation}
\mu(A  | \Lambda )= \frac{\mu(A \cap \Lambda )}{\mu(\Lambda)} \qquad A \in  \mathscr C \,\, .
\end{equation}
%
%
We then construct the space 
$
\big ( Y^{-1} (\Lambda),\mathscr F \cap  Y^{-1} (\Lambda), P ( \,\cdot \, | Y^{-1}(\Lambda) ) \big )
$
where
%
%
\begin{equation}
	P ( A | Y^{-1}(\Lambda) ) = \frac{P(A \cap Y^{-1} (\Lambda ) )}{P(Y^{-1} (\Lambda ) )} \qquad 
	\text{ for } A 
	\in \mathscr  F \cap  Y^{-1} (\Lambda) \,\, .
\end{equation}
%
\begin{definition}
	Given a random function $ Y  $ as in \eqref{eq:rand-fun} and a set $ \Lambda \in \mathscr C $ the \emph{conditional process} $ Y| \Lambda $ is defined  
	as the restriction of $ Y $ to the set $ \Lambda $:
	\begin{equation}
	Y|\Lambda : 
	\big (
	\,  Y^{-1} (\Lambda), \mathscr F  \cap  Y^{-1} (\Lambda), P (\, \cdot \,  | {Y^{-1}(\Lambda)} )  \, \big )
	\mapsto
	( \Lambda, \mathscr C, \mu(\, \cdot \,| \Lambda )  ) \,\, 
	\end{equation} 
\end{definition}
%
%
%Clearly the measure $ \mu_\Lambda $ can then be extended back to the whole space $ (C[0,T], \mathscr C) $ by setting 
%\[
%\tilde \mu_\Lambda (A) = \mu_\Lambda( A \cap \Lambda) \qquad A \in \mathscr C.
%\]
%This is needed when dealing with sequences of processes conditional on different sets $ \Lambda $, in order for them to be defined on a common 
%probability space, and will be assumed implicitly in the following. 


%
%


The following lemma provides the conditions for a conditional process to be Markov (see \cite{durrett77}). 

\begin{lemma}\label{lem:markov-cond}
	Let $ Y $ be a Markov process on $ C[0,T] $ and let $ \Lambda \in \mathscr C $ such that $ \mu(\Lambda) > 0 $. 
	Let $ \pi_{[0,t]} $ and  $ \pi_{[t,1]} $ be the projection maps on $ C[0,T] $ onto  $ C[0,t] $ and 
	 $ C[t,1] $, respectively. If for all $ t \in [0,T] $ there exist sets $ A_t \in \mathscr B(C[0,t] )$ and $ B_t \in \mathscr B(C[t,1] ) $ such that 
	 $ \Lambda   =   \pi_{[0,t]} ^{-1} A_t  \cap \pi_{[t,1]} ^{-1} B_t$ then $ Y|\Lambda  $ is Markov, 
	 where $ \mathscr B $ denotes the Borel sigma-algebra. 
\end{lemma}


%
%

In the following $ \mu(\,\cdot \,) $ denotes  the Wiener measure on $ (C[0,T], \mathscr C) $. 
For a Brownian motion starting at $ u $ we usually write $ P(\,\cdot \, | B(0) = u ) $  to denote $ P_u(\,\cdot \,) $
to underline the dependence on the starting point. 
The \emph{ drifted Brownian meander} can be represented as a conditional process $ B^\mu | \Lambda_{u,v} $ where 
 the conditioning event $ \Lambda_{u,v} $ is of the form
%
\[ \Lambda_{u,v} = \Big\{  \min_{ 0\leq z \leq t} B^{\mu}(z)  > v, B^\mu(0) = u\Big\} \, .\]
Analogously the \emph{Brownian excursion} is a conditional process $ B^\mu | \Lambda_{u,v,c}  $ with
\[ \Lambda_{u,v,c} = \Big\{ \min_{ 0\leq z \leq t} B^{\mu}(z)>v,\, B^\mu(0) = u, B^\mu(t) = c \Big\} 
\qquad u,c > v \,\, .
\]


We remark that the conditional processes introduced above are Markovian in light of \autoref{lem:markov-cond}.

For some fixed $ v > 0 $, we need to study the weak convergence of the measures 
$ \mu_{u,v} := \mu( \, \cdot \, | \Lambda_{u,v}) $ as $ u \downarrow v $. 
See \citet{billingsley2009convergence} for a treatise of the general theory of weak convergence. We here recall the main 
concepts we will make use of. 



\begin{definition}
	Given a metric space $ (S, \rho) $ and a family $ \Pi $ of probability measures on $ (S, \mathscr B ( S)) $, 
	 $ \mathscr B ( S) $ being the Borel $ \sigma- $field on $ S $, we say that $ \Pi $ is tight if
	 \[
	 \forall \eta > 0 \quad  \exists \text{ compact } K \subset S  \quad  \text{s.t.} \quad \forall \mu \in \Pi \quad  \mu(K) > 1 - \eta 
	 .
	 \]
\end{definition}

The tightness property  is equivalent to  relative compactness if $ (S, \rho) $ is separable and complete,
as estabilished in a well-known theorem due to Prohorov, and it is thus relevant to prove the weak convergence of measures. 
In fact the following theorem holds (see \cite{billingsley2009convergence}, Theorem 7.1, or \cite{karatzas2014brownian}, Theorem 4.15).
%
%
%
\begin{theorem}\label{thm:weak-conv}
	Let $ \{ X^{(n)} \}_n $ and $ X $ be stochastic processes on some probability space $ (\Omega, \mathscr F, P) $ onto $(C([0,T]), \mathscr C )$ and let $ \{\mu_n \}_n $ and $ \mu $, respectively, the induced measures. 
	If for every $ m $ and for every $ 0 \leq t_1 < t_2 < \cdots t_m \leq t $, 
	the finite dimensional distributions of $ (X^{(n)}_{t_1}, \ldots, X^{(n)}_{t_m} ) $ converge 
	to those of $ (X_{t_1}, \ldots, X_{t_m} ) $ and the family $ \{\mu_n\}  $ is tight then $ \mu_n \Rightarrow \mu $.
\end{theorem}
%
%
%
In the following section we will compute the limit of the finite dimensional distributions. 
As far as the tightness is concerned we will make use of the following theorem 
(\cite{billingsley2009convergence}, Theorem 7.3)
which characterizes the tightness
of a family of measures induced by a process with a.s. continuous paths 
in terms of its modulus of continuity $ m_\omega^T (\delta) = \sup_{s,t \in [0,T]: |t-s| < \delta} |\omega(s) - \omega(t)| $.

\begin{theorem}\label{thm:tight}
	A sequence of probability measures $ \{P_n\}_n $ on $ (C[0,T], \mathscr C) $ is tight if and only if
	\begin{enumerate}[(i)]
		\item  $ \qquad  \forall \eta > 0 \,\,  \exists a  $ and $  N $ such that 
		$ \displaystyle P_n(\omega :  |\omega(0)| > a  )  < \eta, \,\, \forall n \geq  N ,  $ and 
		\item  $ \qquad  \displaystyle \forall \eta > 0 \quad  
		 \lim_{\delta \downarrow 0} \limsup_{n \to \infty } P_n\{ \omega: m_\omega^T ( \delta) \geq \eta   \} = 0.
		$	
	\end{enumerate}
\end{theorem}
%
%
%

%Condition \emph{(ii)} may result difficult to prove; in this case one can resolve to suitably  bounding the expectation of the increments. 

Condition $ (ii) $ is difficult to prove directly so we use the Kolmogorov-Cent\v sov theorem 
which necessitates bounds on the expectation of the increments. 
%
%
%
We first recall the Kolmogorov-\v Centsov theorem (\cite{karatzas2014brownian}, Th. 2.8).
\begin{theorem}\label{thm:kolmo-cen}
Suppose that a process $ X = \{X(t), 0 \leq t \leq T \} $ on a probability space $ (\Omega, \mathscr F, P) $ satisfies the condition 
\begin{equation}\label{eq:kolmo-cen-cond}
\mathbb E | X(t) - X(s) | ^\alpha \leq C | t-s|^{1 + \beta} \,\,,\quad 0 \leq s,t \leq T
\end{equation}
for some positive constants $ \alpha, \beta $ and $ C $. Then there exists a continuous modification of $ X $ which is locally H\"older continuous 
with exponent $ \gamma \in (0, \beta / \alpha) $ i.e., 
\begin{equation}
P\left\{  \omega : \sup_{ \substack{  s,t \in [0,T] \\ |t-s| < h(w)} }
\frac{  | \tilde X(\omega, t)    -   \tilde X(\omega, s)  |}{|t-s|^\gamma}  
\leq \delta 
\right\} = 1
\end{equation}
where $ h $ is an a.s. positive random variable and $ \delta > 0 $ is an appropriate constant. 
\end{theorem} 
%
%
%
%
%
The  Kolmogorov-\v Centsov theorem can be exploited to prove the tightness property of a family of measures as 
stated in the following result (\cite{karatzas2014brownian}, Problem 4.11) 
%
%
%
\begin{prop}\label{pr:kolmo-cen-tight}
	Let $ \{ X^{(m)}, m\geq 1 \} $ be a sequence of stochastic processes $ X^{(m)} = \{X^{(m)}(t), 0 \leq t \leq T \} $
	on $ (\Omega, \mathscr F, P) $, satisfying the following conditions
	\begin{enumerate}[(i)]
		\item  $ \qquad  \sup_{m \geq 1 } \mathbb E |X_0^{(m)}|^\nu < \infty $, 
		\item  $ \qquad \sup_{m \geq 1 }  \mathbb E | X^{(m)}(t) - X^{(m)}(s) | ^\alpha \leq C_T | t-s|^{1 + \beta} \,\,,\quad 0 \leq s,t \leq T $
	\end{enumerate}
for some positive constants $ \alpha, \beta, \nu $ and $ C_T $ (depending on $ T $). Then the probability measures 
$ P_m = P(X_m^{-1}) \,, m\geq 1$  induced by these processes form a tight sequence. 
\end{prop}
It is easily seen that conditions $ (\emph{i}) $  and $ (\emph{ii}) $ of Proposition \autoref{pr:kolmo-cen-tight} imply the 
corresponding conditions of \autoref{thm:tight}. 
%
%

Returning to our main task, once proved that the collection of measures $ \{\mu_{u,v}\}_{u > v}$ satisfies the conditions of \autoref{thm:weak-conv} and \autoref{thm:tight}, by exploiting Proposition \autoref{pr:kolmo-cen-tight}, we are able to assess the existence of some process whose finite dimensional distributions 
coincide with those of the weak limit $ \mu_v $ of $ \mu_{u,v}$ when $ u \downarrow v $. This measure will coincide with that induced by
$ B^\mu | \Lambda_v $ where 
\[
\Lambda_v = \Big \{\omega : \inf_{ 0 < z < T } \omega(z) > v , \omega(0)  = v \Big \}.
\]

This means that the continuous mapping theorem holds, i.e.
 $ \mu_{u,v} \circ g^{-1}$  \raisebox{-3pt} {$\xRightarrow{u\to v }$ }$  \mu_{v} \circ g^{-1} $ for any bounded uniformly continuous $ g $. 
 Using this fact we can derive the distribution of the maximum of $ \max B^\mu | \Lambda_v $ as the weak limit 
 of $ \max B^\mu | \Lambda_{u,v} $. 
 This was done in the driftless case by \citet{iglehart77}.
% !TeX root = mdr-main.pdf