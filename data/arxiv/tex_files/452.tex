\documentclass[11pt]{article}  

\input{packages_only_arxiv.tex}
\input{theorems_std.tex}
\input{macros.tex}


%\newcommand{\Anote}[1]{{\color{blue}\authnote{Andrej}{{#1}}}}
%\newcommand{\Rnote}[1]{{\color{red}\authnote{Rong}{{#1}}}}
%\newcommand{\Hnote}[1]{{\color{brown}\authnote{Holden}{{#1}}}}

\newcommand{\Anote}[1]{}
\newcommand{\Rnote}[1]{}
\newcommand{\Hnote}[1]{}


\newcommand{\citep}[1]{\cite{#1}}
\newcommand{\weight}[0]{w} %in case I want to change this


\addbibresource{langevin.bib}

\begin{document}

\title{Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo}

\author{Rong Ge\thanks{Duke University, Computer Science Department \texttt{rongge@cs.duke.edu}}, Holden Lee\thanks{Princeton University, Mathematics Department \texttt{holdenl@princeton.edu}}, Andrej Risteski\thanks{Massachusetts Institute of Technology, Applied Mathematics and IDSS \texttt{risteski@mit.edu}}}
%add names

\date{\today}
\maketitle
\begin{abstract}
In the last several years, 
provable guarantees for iterative optimization algorithms like gradient descent and expectation-maximization in non-convex settings have become a topic of intense research 
in the machine learning community. These works have shed light on the practical success of these algorithms in many unsupervised learning settings such as matrix completion, sparse coding, and learning latent variable Bayesian models.

Another elementary task at inference-time in Bayesian settings, besides model learning, is sampling from distributions that are only specified up to a partition function (i.e., constant of proportionality). As a concrete example, in latent-variable models, sampling the posterior on the latent variables is how a model is \emph{used} after it has been learned. Similar worst-case theoretical issues plague this task as do the learning one: without any assumptions, sampling (even approximately) can be \#P-hard. However, few works have provided ``beyond worst-case'' guarantees for such settings.  

%\Hnote{Do we need so much intro? I would want proportionally more on our result/techniques. (I added some.)}

The analogue of ``convexity'' for inference is ``log-concavity'': for log-concave distributions, classical results going back to \cite{bakry1985diffusions} show that natural continuous-time Markov chains called \emph{Langevin diffusions} mix in polynomial time. The most salient feature of log-concavity violated in practice is uni-modality: commonly, the distributions we wish to sample from are multi-modal. In the presence of multiple deep and well-separated modes, Langevin diffusion suffers from torpid mixing.

We address this problem by combining Langevin diffusion with \emph{simulated tempering}. The result is a Markov chain that mixes more rapidly by transitioning between different temperatures of the distribution. 
We analyze this Markov chain for the canonical multi-modal distribution: a mixture of gaussians (of equal variance). The algorithm based on our Markov chain provably samples from distributions that are close to mixtures of gaussians, given access to the gradient of the log-pdf.
%In particular, we study one of the simplest multimodal distributions: a mixture of gaussians. 
For the analysis, we use a spectral decomposition theorem for graphs~ \cite{gharan2014partitioning} and a Markov chain decomposition technique \cite{madras2002markov}.   
%We combine two popular algorithms, namely, discretized \emph{Langevin dynamics} and \emph{simulated tempering}, to produce an algorithm with polynomial-time guarantees for sampling from distributions that are close to a mixture-of-gaussians given access to the gradient of their log-pdf. 
\end{abstract}

\newpage

\tableofcontents


\input{overview}
\input{proof_overview}
\input{bounding_temperinggap}
\input{defining_partitions} 
\input{highest_temp}
\input{discretization} 
\input{estimates_partition} 
\section{Acknowledgements} 

This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing. We thank Matus Telgarsky and Maxim Raginsky for illuminating conversations in the early stages of this work. 


\printbibliography
\appendix
\input{mc_background}
\input{example}
\input{tolerance_perturbation}
\input{other_simulated_tempering}

\end{document}

