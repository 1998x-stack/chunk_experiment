<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1710.02855] The IIT Bombay English-Hindi Parallel Corpus</title><meta property="og:description" content="We present the IIT Bombay English-Hindi Parallel Corpus. The corpus is a compilation of parallel corpora previously available in the public domain as well as new parallel corpora we collected. The corpus contains 1.49 …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The IIT Bombay English-Hindi Parallel Corpus">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The IIT Bombay English-Hindi Parallel Corpus">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1710.02855">
<link rel="canonical" target="_blank" href="https://ar5iv.labs.arxiv.org/html/1710.02855">

<!--Generated on Sat Mar  2 01:28:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">The IIT Bombay English-Hindi Parallel Corpus</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">We present the IIT Bombay English-Hindi Parallel Corpus. The corpus is a compilation of parallel corpora previously available in the public domain as well as new parallel corpora we collected. The corpus contains 1.49 million parallel segments, of which 694k segments were not previously available in the public domain. The corpus has been pre-processed for machine translation, and we report baseline phrase-based SMT and NMT translation results on this corpus. This corpus has been used in two editions of shared tasks at the Workshop on Asian Language Translation (2016 and 2017). The corpus is freely available for non-commercial research. To the best of our knowledge, this is the largest publicly available English-Hindi parallel corpus.

<br class="ltx_break">
<br class="ltx_break">
<span id="id7.id1.1" class="ltx_text ltx_font_bold">Keywords: </span>machine translation, parallel corpus, Indian languages</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\newcites</span>
<p id="p1.2" class="ltx_p">languageresourceLanguage Resources

















</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text"></span></p>
</div>
<div id="id6" class="ltx_logical-block">
<div id="id6.p1" class="ltx_para">
<p id="id6.p1.1" class="ltx_p ltx_align_center"><span id="id6.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">The IIT Bombay English-Hindi Parallel Corpus</span></p>
<br class="ltx_break ltx_centering">
<table id="id5.5" class="ltx_tabular ltx_centering ltx_align_top">
<tbody class="ltx_tbody">
<tr id="id3.3.3" class="ltx_tr">
<td id="id3.3.3.3" class="ltx_td ltx_align_center"><span id="id3.3.3.3.3" class="ltx_text ltx_font_bold" style="font-size:120%;">Anoop Kunchukuttan<sup id="id3.3.3.3.3.1" class="ltx_sup"><span id="id3.3.3.3.3.1.1" class="ltx_text ltx_font_medium">†</span></sup>, Pratik Mehta<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex1.1.1.1" class="ltx_text ltx_font_medium" style="font-size:83%;">1</span></span>work done at IIT Bombay</span></span></span><sup id="id3.3.3.3.3.2" class="ltx_sup"><span id="id3.3.3.3.3.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1‡</span></sup>, Pushpak Bhattacharyya<sup id="id3.3.3.3.3.3" class="ltx_sup"><span id="id3.3.3.3.3.3.1" class="ltx_text ltx_font_medium">†</span></sup></span></td>
</tr>
<tr id="id4.4.4" class="ltx_tr">
<td id="id4.4.4.1" class="ltx_td ltx_align_center">
<sup id="id4.4.4.1.1" class="ltx_sup">†</sup>Center for Indian Language Technology,</td>
</tr>
<tr id="id5.5.6.1" class="ltx_tr">
<td id="id5.5.6.1.1" class="ltx_td ltx_align_center">Department of Computer Science and Technology,</td>
</tr>
<tr id="id5.5.7.2" class="ltx_tr">
<td id="id5.5.7.2.1" class="ltx_td ltx_align_center">Indian Institute of Technology Bombay.</td>
</tr>
<tr id="id5.5.5" class="ltx_tr">
<td id="id5.5.5.1" class="ltx_td ltx_align_center">
<sup id="id5.5.5.1.1" class="ltx_sup">‡</sup> College of Information and Computer Sciences,</td>
</tr>
<tr id="id5.5.8.3" class="ltx_tr">
<td id="id5.5.8.3.1" class="ltx_td ltx_align_center">University of Massachusetts Amherst.</td>
</tr>
<tr id="id5.5.9.4" class="ltx_tr">
<td id="id5.5.9.4.1" class="ltx_td ltx_align_center">{anoopk,pb}@cse.iitb.ac.in, psmehta@cs.umass.edu</td>
</tr>
</tbody>
</table>
<p id="id6.p1.2" class="ltx_p ltx_align_center"><span id="id6.p1.2.1" class="ltx_text ltx_font_italic">Abstract content</span></p>
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Hindi is one of the major languages of the world, spoken primarily in the Indian subcontinent, and is a recognised regional language in Mauritius, Trinidad and Tobago, Guyana, and Suriname. In addition, it serves as a major <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">lingua franca</span> in India. According to the 2001 Census of India, Hindi has 422 million native speakers and more than 500 million total speakers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx22" title="" class="ltx_ref">Wikipedia, 2017</a>]</cite>. It is also an official language of the Union Government of India as well as major Indian states like Uttar Pradesh, Bihar, Rajasthan, <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">etc. </span>and is used for conducting business and administrative tasks. Many languages and dialects in the Gangetic plains are closely related to Hindi <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">e.g. </span>Bhojpuri, Awadhi, Maithili, <span id="S1.p1.1.4" class="ltx_text ltx_font_italic">etc. </span>Hindi is the fourth-most spoken language in the world, and third-most spoken language along with Urdu (both are registers of the Hindustani language). In contrast, English is spoken by just around 125 million people in India, of which a very small fraction are native speakers.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Hence, there is a large requirement for digital communication in Hindi and interfacing with the rest of the word via English. Hence, there is immense potential for English-Hindi machine translation. However, the parallel corpora available in the public domain is quite limited. This work is an effort to consolidate all publicly available parallel corpora for English-Hindi as well as significantly add to the available parallel corpus through corpora collected in the course of this work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Dataset</h2>

<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.7" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.7.8.1" class="ltx_tr">
<th id="S2.T1.7.8.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.7.8.1.1.1" class="ltx_text ltx_font_bold">Corpus Id</span></th>
<th id="S2.T1.7.8.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.7.8.1.2.1" class="ltx_text ltx_font_bold">Source</span></th>
<th id="S2.T1.7.8.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S2.T1.7.8.1.3.1" class="ltx_text ltx_font_bold">Number of segments</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.7.9.1" class="ltx_tr">
<td id="S2.T1.7.9.1.1" class="ltx_td ltx_align_left ltx_border_t">1</td>
<td id="S2.T1.7.9.1.2" class="ltx_td ltx_align_left ltx_border_t">GNOME (OPUS) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">Tiedemann, 2012</a>]</cite>
</td>
<td id="S2.T1.7.9.1.3" class="ltx_td ltx_align_right ltx_border_t">145,706</td>
</tr>
<tr id="S2.T1.7.10.2" class="ltx_tr">
<td id="S2.T1.7.10.2.1" class="ltx_td ltx_align_left">2</td>
<td id="S2.T1.7.10.2.2" class="ltx_td ltx_align_left">KDE4 (OPUS)</td>
<td id="S2.T1.7.10.2.3" class="ltx_td ltx_align_right">97,227</td>
</tr>
<tr id="S2.T1.7.11.3" class="ltx_tr">
<td id="S2.T1.7.11.3.1" class="ltx_td ltx_align_left">3</td>
<td id="S2.T1.7.11.3.2" class="ltx_td ltx_align_left">Tanzil (OPUS)</td>
<td id="S2.T1.7.11.3.3" class="ltx_td ltx_align_right">187,080</td>
</tr>
<tr id="S2.T1.7.12.4" class="ltx_tr">
<td id="S2.T1.7.12.4.1" class="ltx_td ltx_align_left">4</td>
<td id="S2.T1.7.12.4.2" class="ltx_td ltx_align_left">Tatoeba (OPUS)</td>
<td id="S2.T1.7.12.4.3" class="ltx_td ltx_align_right">4,698</td>
</tr>
<tr id="S2.T1.7.13.5" class="ltx_tr">
<td id="S2.T1.7.13.5.1" class="ltx_td ltx_align_left">5</td>
<td id="S2.T1.7.13.5.2" class="ltx_td ltx_align_left">OpenSubs2013 (OPUS)</td>
<td id="S2.T1.7.13.5.3" class="ltx_td ltx_align_right">4,222</td>
</tr>
<tr id="S2.T1.7.14.6" class="ltx_tr">
<td id="S2.T1.7.14.6.1" class="ltx_td ltx_align_left">6</td>
<td id="S2.T1.7.14.6.2" class="ltx_td ltx_align_left">HindEnCorp <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">Bojar et al., 2014b</a>]</cite>
</td>
<td id="S2.T1.7.14.6.3" class="ltx_td ltx_align_right">273,885</td>
</tr>
<tr id="S2.T1.7.15.7" class="ltx_tr">
<td id="S2.T1.7.15.7.1" class="ltx_td ltx_align_left">7</td>
<td id="S2.T1.7.15.7.2" class="ltx_td ltx_align_left">Hindi-English Linked Wordnets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">Bhattacharyya, 2010</a>]</cite>
</td>
<td id="S2.T1.7.15.7.3" class="ltx_td ltx_align_right">175,175</td>
</tr>
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_left">8</td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_left">Mahashabdkosh: Administrative Domain Dictionary<sup id="S2.T1.1.1.1.1" class="ltx_sup">∗</sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">Kunchukuttan et al., 2013</a>]</cite>
</td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_right">66,474</td>
</tr>
<tr id="S2.T1.2.2" class="ltx_tr">
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_left">9</td>
<td id="S2.T1.2.2.1" class="ltx_td ltx_align_left">Mahashabdkosh: Administrative Domain Examples<sup id="S2.T1.2.2.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S2.T1.2.2.3" class="ltx_td ltx_align_right">46,825</td>
</tr>
<tr id="S2.T1.3.3" class="ltx_tr">
<td id="S2.T1.3.3.2" class="ltx_td ltx_align_left">10</td>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_left">Mahashabdkosh: Administrative Domain Definitions<sup id="S2.T1.3.3.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S2.T1.3.3.3" class="ltx_td ltx_align_right">46,523</td>
</tr>
<tr id="S2.T1.7.16.8" class="ltx_tr">
<td id="S2.T1.7.16.8.1" class="ltx_td ltx_align_left">11</td>
<td id="S2.T1.7.16.8.2" class="ltx_td ltx_align_left">TED talks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">Abdelali et al., 2014</a>]</cite>
</td>
<td id="S2.T1.7.16.8.3" class="ltx_td ltx_align_right">42,583</td>
</tr>
<tr id="S2.T1.7.17.9" class="ltx_tr">
<td id="S2.T1.7.17.9.1" class="ltx_td ltx_align_left">12</td>
<td id="S2.T1.7.17.9.2" class="ltx_td ltx_align_left">Indic Multi-parallel corpus <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">Alexandra Birch and Post, 2011</a>]</cite>
</td>
<td id="S2.T1.7.17.9.3" class="ltx_td ltx_align_right">10,349</td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_left">13</td>
<td id="S2.T1.4.4.1" class="ltx_td ltx_align_left">Judicial domain corpus - I<sup id="S2.T1.4.4.1.1" class="ltx_sup">∗</sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">Kunchukuttan et al., 2013</a>]</cite>
</td>
<td id="S2.T1.4.4.3" class="ltx_td ltx_align_right">5,007</td>
</tr>
<tr id="S2.T1.5.5" class="ltx_tr">
<td id="S2.T1.5.5.2" class="ltx_td ltx_align_left">14</td>
<td id="S2.T1.5.5.1" class="ltx_td ltx_align_left">Judicial domain corpus - II<sup id="S2.T1.5.5.1.1" class="ltx_sup">∗</sup> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">Kunchukuttan et al., 2012</a>]</cite>
</td>
<td id="S2.T1.5.5.3" class="ltx_td ltx_align_right">3,727</td>
</tr>
<tr id="S2.T1.6.6" class="ltx_tr">
<td id="S2.T1.6.6.2" class="ltx_td ltx_align_left">15</td>
<td id="S2.T1.6.6.1" class="ltx_td ltx_align_left">Indian Government corpora<sup id="S2.T1.6.6.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S2.T1.6.6.3" class="ltx_td ltx_align_right">123,360</td>
</tr>
<tr id="S2.T1.7.18.10" class="ltx_tr">
<td id="S2.T1.7.18.10.1" class="ltx_td ltx_align_left">16</td>
<td id="S2.T1.7.18.10.2" class="ltx_td ltx_align_left">Wiki Headlines (Provided by CMU: <a href="www.statmt.org/wmt14/wiki-titles.tgz" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">www.statmt.org/wmt14/wiki-titles.tgz</a>)</td>
<td id="S2.T1.7.18.10.3" class="ltx_td ltx_align_right">32,863</td>
</tr>
<tr id="S2.T1.7.7" class="ltx_tr">
<td id="S2.T1.7.7.2" class="ltx_td ltx_align_left">17</td>
<td id="S2.T1.7.7.1" class="ltx_td ltx_align_left">Gyaan-Nidhi Corpus <sup id="S2.T1.7.7.1.1" class="ltx_sup">∗</sup>
</td>
<td id="S2.T1.7.7.3" class="ltx_td ltx_align_right">227,123</td>
</tr>
<tr id="S2.T1.7.19.11" class="ltx_tr">
<td id="S2.T1.7.19.11.1" class="ltx_td"></td>
<td id="S2.T1.7.19.11.2" class="ltx_td ltx_align_left">(<a href="tdil-dc.in/index.php?option=com_download&amp;task=showresourceDetails&amp;toolid=281" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">tdil-dc.in/index.php?option=com_download&amp;task=showresourceDetails&amp;toolid=281</a>)</td>
<td id="S2.T1.7.19.11.3" class="ltx_td"></td>
</tr>
<tr id="S2.T1.7.20.12" class="ltx_tr">
<td id="S2.T1.7.20.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" colspan="2"><span id="S2.T1.7.20.12.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S2.T1.7.20.12.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S2.T1.7.20.12.2.1" class="ltx_text ltx_font_bold">1,492,827</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Details of the IITB English-Hindi Parallel Corpus (training set). <sup id="S2.T1.11.1" class="ltx_sup">∗</sup> indicates new corpora not in the public domain previously.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.1" class="ltx_p">The parallel corpus has been compiled from a variety of existing sources (primarily OPUS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">Tiedemann, 2012</a>]</cite>, HindEn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">Bojar et al., 2014b</a>]</cite> and TED <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">Abdelali et al., 2014</a>]</cite>) as well as corpora developed at the <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">Center for Indian Language Technology<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnote2.1.1.1" class="ltx_text ltx_font_upright">2</span></span><a href="www.cfilt.iitb.ac.in" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" style="font-size:70%;">www.cfilt.iitb.ac.in</a></span></span></span></span> (CFILT), IIT Bombay over the years. The training corpus consists of sentences, phrases as well as dictionary entries, spanning many applications and domains.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Corpus Details</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.p1.1" class="ltx_p">The details of the training corpus are shown in Table <a href="#S2.T1" title="Table 1 ‣ 2. Dataset ‣ The IIT Bombay English-Hindi Parallel Corpus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. We briefly describe the new sub-corpora we have added to the collection. For the corpora compiled from existing sources, please refer to the papers mentioned in the table.</p>
</div>
<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Judicial domain corpus - I</h4>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px1.p1.1" class="ltx_p">contains translations of legal judgements by in-house translators with many years of experience, though not with a legal background.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Judicial domain corpus - II</h4>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px2.p1.1" class="ltx_p">contains translation done by graduate students taking a graduate course on natural language processing as part of a course project. This was part of an exercise of collecting translations in complex domain by non-expert translators. The translations included in the corpus were determined to be of good quality by annotators.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Mahashabdkosh</h4>

<div id="S2.SS1.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px3.p1.1" class="ltx_p">is an online official terminology dictionary website<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a href="e-mahashabdkosh.rb-aai.in" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">e-mahashabdkosh.rb-aai.in</a></span></span></span> which is hosted by Department of Official Language, India. It contains Hindi as well as English terms along with definitions and example usage which are translations. The translation pairs were crawled from the website.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Indian Government corpora</h4>

<div id="S2.SS1.SSS0.Px4.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px4.p1.1" class="ltx_p">has been manually collected by CFILT staff from various websites related to the Indian government like the National Portal of India, Reserve Bank of India, Ministry of Human Resource Development, NABARD, <span id="S2.SS1.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_italic">etc.</span></p>
</div>
</section>
<section id="S2.SS1.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Hindi-English Linked Wordnet</h4>

<div id="S2.SS1.SSS0.Px5.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px5.p1.1" class="ltx_p">contains bilingual dictionary entries created from the linked Hindi and English wordnets.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Gyaan-Nidhi Corpus</h4>

<div id="S2.SS1.SSS0.Px6.p1" class="ltx_para ltx_noindent">
<p id="S2.SS1.SSS0.Px6.p1.1" class="ltx_p">is a multilingual parallel corpus between English and multiple Indian languages. The data is available in HTML format, hence it is not sentence aligned. We used the sentence alignment technique proposed by <span id="S2.SS1.SSS0.Px6.p1.1.1" class="ltx_text ltx_font_bold">?</span>) to extract parallel corpora from this comparable corpus. This method combines sentence-length models and word-correspondence based models, and requires no language or corpus specific knowledge. We manually checked a small sample of 300 sentences from the parallel sentences extracted. We found that the precision of extraction of parallel sentences was 88.6%.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Corpus Statistics</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p id="S2.SS2.p1.1" class="ltx_p">The test and dev corpora consist of newswire sentences, which are the same ones as used in the WMT 2014 English-Hindi shared task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Bojar et al., 2014a</a>]</cite>.
The training, dev and test corpora consist of 1,492,827 and 520 and 2507 segments respectively. Detailed Statistics are shown in Table <a href="#S2.T2" title="Table 2 ‣ 2.2. Corpus Statistics ‣ 2. Dataset ‣ The IIT Bombay English-Hindi Parallel Corpus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The Hindi and English OOV rate (for word types) is 11.4% and 6.7%.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<div id="S2.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:220.2pt;height:80.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-24.8pt,9.1pt) scale(0.815890395594758,0.815890395594758) ;">
<table id="S2.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T2.1.1.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S2.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Language</span></th>
<th id="S2.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Train</span></th>
<th id="S2.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Test</span></th>
<th id="S2.T2.1.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S2.T2.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Dev</span></th>
</tr>
<tr id="S2.T2.1.1.2.2" class="ltx_tr">
<th id="S2.T2.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">#Sentences</th>
<th id="S2.T2.1.1.2.2.2" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
<th id="S2.T2.1.1.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">1,492,827</th>
<th id="S2.T2.1.1.2.2.4" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">2,507</th>
<th id="S2.T2.1.1.2.2.5" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t">520</th>
</tr>
<tr id="S2.T2.1.1.3.3" class="ltx_tr">
<td id="S2.T2.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t">#Tokens</td>
<td id="S2.T2.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">eng</td>
<td id="S2.T2.1.1.3.3.3" class="ltx_td ltx_align_right ltx_border_t">20,667,259</td>
<td id="S2.T2.1.1.3.3.4" class="ltx_td ltx_align_right ltx_border_t">57,803</td>
<td id="S2.T2.1.1.3.3.5" class="ltx_td ltx_align_right ltx_border_t">10,656</td>
</tr>
<tr id="S2.T2.1.1.4.4" class="ltx_tr">
<td id="S2.T2.1.1.4.4.1" class="ltx_td"></td>
<td id="S2.T2.1.1.4.4.2" class="ltx_td ltx_align_center">hin</td>
<td id="S2.T2.1.1.4.4.3" class="ltx_td ltx_align_right">22,171,543</td>
<td id="S2.T2.1.1.4.4.4" class="ltx_td ltx_align_right">63,853</td>
<td id="S2.T2.1.1.4.4.5" class="ltx_td ltx_align_right">10,174</td>
</tr>
<tr id="S2.T2.1.1.5.5" class="ltx_tr">
<td id="S2.T2.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_t">#Types</td>
<td id="S2.T2.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_t">eng</td>
<td id="S2.T2.1.1.5.5.3" class="ltx_td ltx_align_right ltx_border_t">250,782</td>
<td id="S2.T2.1.1.5.5.4" class="ltx_td ltx_align_right ltx_border_t">8,957</td>
<td id="S2.T2.1.1.5.5.5" class="ltx_td ltx_align_right ltx_border_t">2,569</td>
</tr>
<tr id="S2.T2.1.1.6.6" class="ltx_tr">
<td id="S2.T2.1.1.6.6.1" class="ltx_td ltx_border_bb"></td>
<td id="S2.T2.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_bb">hin</td>
<td id="S2.T2.1.1.6.6.3" class="ltx_td ltx_align_right ltx_border_bb">343,601</td>
<td id="S2.T2.1.1.6.6.4" class="ltx_td ltx_align_right ltx_border_bb">8,489</td>
<td id="S2.T2.1.1.6.6.5" class="ltx_td ltx_align_right ltx_border_bb">2,625</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Statistics of data sets</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Baseline Systems</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">We trained baseline machine translation models using the parallel corpus with popular off-the-shelf machine translation toolkits to provide benchmark translation accuracies for comparison. We trained phrase-based Statistical Machine Translation (PBSMT) systems as well as Neural Machine Translation systems for English-Hindi and Hindi-English translation.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Data Preparation</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_bold">Text Normalization:</span> For Hindi, characters with <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">nukta</span> can have two Unicode representations. In one case, the character and nukta are represented as two Unicode characters. In the other case, a single Unicode character represents the composite character. We choose the former representation. The normalization script is part of the <span id="S3.SS1.p1.1.3" class="ltx_text ltx_font_italic">IndicNLP<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">4</span></span><a href="anoopkunchukuttan.github.io/indic_nlp_library" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" style="font-size:70%;">anoopkunchukuttan.github.io/indic_nlp_library</a></span></span></span></span> library .</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p id="S3.SS1.p2.1" class="ltx_p">For English, we used true-cased representation for our experiments. However, the parallel corpus being distributed is available in the original case.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Tokenization:</span> We use the <span id="S3.SS1.p3.1.2" class="ltx_text ltx_font_italic">Moses</span> tokenizer for English and the <span id="S3.SS1.p3.1.3" class="ltx_text ltx_font_italic">IndicNLP</span> tokenizer for Hindi.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>SMT Setup</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">We trained PBSMT systems with <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Moses<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note"><span id="footnote5.1.1.1" class="ltx_text ltx_font_upright">5</span></span><a href="www.statmt.org/moses" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" style="font-size:70%;">www.statmt.org/moses</a></span></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Koehn et al., 2007</a>]</cite>. We used the <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">grow-diag-final-and</span> heuristic for extracting phrases, lexicalised reordering and Batch MIRA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx9" title="" class="ltx_ref">Cherry and Foster, 2012</a>]</cite> for tuning (default parameters). We trained 5-gram language models with Kneser-Ney smoothing using <span id="S3.SS2.p1.1.3" class="ltx_text ltx_font_italic">KenLM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">Heafield, 2011</a>]</cite>. We used the <span id="S3.SS2.p1.1.4" class="ltx_text ltx_font_italic">HindMono</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">Bojar et al., 2014b</a>]</cite> corpus for Hindi and the WMT NEWS Crawl 2015 corpus for English as additional monolingual corpora to train language models. These contain roughly 44 million and 23 million sentence for Hindi and English respectively.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>NMT Setup</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS3.p1.1" class="ltx_p">We trained a subword-level encoder-decoder architecture based NMT system with attention <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">Bahdanau et al., 2015</a>]</cite>. We used <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">Nematus</span> <span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a href="github.com/EdinburghNLP/nematus" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">github.com/EdinburghNLP/nematus</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">Sennrich et al., 2017</a>]</cite> for training our NMT systems.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p id="S3.SS3.p2.1" class="ltx_p"><span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_bold">Vocabulary:</span> We used Byte Pair Encoding (BPE) to learn the vocabulary (with 15500 merge operations) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">Sennrich et al., 2016b</a>]</cite>. We used the <span id="S3.SS3.p2.1.2" class="ltx_text ltx_font_italic">subword-nmt</span> <span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a href="github.com/rsennrich/subword-nmt" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">github.com/rsennrich/subword-nmt</a></span></span></span> tool for learning the BPE vocabulary. Since the writing systems and vocabularies of English and Hindi are separate, BPE models are trained separately.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p id="S3.SS3.p3.1" class="ltx_p"><span id="S3.SS3.p3.1.1" class="ltx_text ltx_font_bold">Network parameters:</span> The network contains a single hidden encoder and decoder RNN layer, containing 512 GRU units each. The dimension of input and output embedding layers is 256 units.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p id="S3.SS3.p4.1" class="ltx_p"><span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_bold">Training details:</span> The model is trained with a batch size of 50 sentences and maximum sentence length of 100 using Adam optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">Kingma and Ba, 2014</a>]</cite> with a learning rate of 0.0001. The output parameters were saved after every 10,000 iterations. We used early-stopping based on validation loss with <span id="S3.SS3.p4.1.2" class="ltx_text ltx_font_italic">patience=10</span>.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para ltx_noindent">
<p id="S3.SS3.p5.1" class="ltx_p"><span id="S3.SS3.p5.1.1" class="ltx_text ltx_font_bold">Decoding:</span> We used a beam size of 12. We decoded the test set with an ensemble of four models (best model and the last three saved models).</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Results</h3>

<div id="S3.SS4.p1" class="ltx_para ltx_noindent">
<p id="S3.SS4.p1.1" class="ltx_p">We evaluated our system using BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">Papineni et al., 2002</a>]</cite> and METEOR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">Banerjee and Lavie, 2005</a>]</cite>. We used a <span id="S3.SS4.p1.1.1" class="ltx_text ltx_font_italic">METEOR-Indic<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note"><span id="footnote8.1.1.1" class="ltx_text ltx_font_upright">8</span></span><a href="github.com/anoopkunchukuttan/meteor_indic" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright" style="font-size:70%;">github.com/anoopkunchukuttan/meteor_indic</a></span></span></span></span>, a customized version of METEOR Indic, for evaluation of Hindi as target language. <span id="S3.SS4.p1.1.2" class="ltx_text ltx_font_italic">METEOR-Indic</span> can perform synonym matches for Indian languages using synsets from IndoWordNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">Bhattacharyya, 2010</a>]</cite>. It can also perform stem matches for Indian languages using a trie-based stemmer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">Bhattacharyya et al., 2014</a>]</cite>. This is useful for a morphologically rich language like Hindi.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para ltx_noindent">
<p id="S3.SS4.p2.1" class="ltx_p">Table <a href="#S3.T3" title="Table 3 ‣ 3.4. Results ‣ 3. Baseline Systems ‣ The IIT Bombay English-Hindi Parallel Corpus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of our experiments.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.1.1.1" class="ltx_tr">
<th id="S3.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S3.T3.1.1.1.1.1" class="ltx_text ltx_font_bold">System</span></th>
<th id="S3.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S3.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">eng-hin</span></th>
<th id="S3.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2"><span id="S3.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">hin-eng</span></th>
</tr>
<tr id="S3.T3.1.2.2" class="ltx_tr">
<th id="S3.T3.1.2.2.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S3.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T3.1.2.2.2.1" class="ltx_text ltx_font_italic">BLEU</span></th>
<th id="S3.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T3.1.2.2.3.1" class="ltx_text ltx_font_italic">METEOR</span></th>
<th id="S3.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T3.1.2.2.4.1" class="ltx_text ltx_font_italic">BLEU</span></th>
<th id="S3.T3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S3.T3.1.2.2.5.1" class="ltx_text ltx_font_italic">METEOR</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.1.3.1" class="ltx_tr">
<th id="S3.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">SMT</th>
<td id="S3.T3.1.3.1.2" class="ltx_td ltx_align_right ltx_border_t">11.75</td>
<td id="S3.T3.1.3.1.3" class="ltx_td ltx_align_right ltx_border_t">0.313</td>
<td id="S3.T3.1.3.1.4" class="ltx_td ltx_align_right ltx_border_t">14.49</td>
<td id="S3.T3.1.3.1.5" class="ltx_td ltx_align_right ltx_border_t">0.266</td>
</tr>
<tr id="S3.T3.1.4.2" class="ltx_tr">
<th id="S3.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">NMT</th>
<td id="S3.T3.1.4.2.2" class="ltx_td ltx_align_right ltx_border_bb">12.23</td>
<td id="S3.T3.1.4.2.3" class="ltx_td ltx_align_right ltx_border_bb">0.308</td>
<td id="S3.T3.1.4.2.4" class="ltx_td ltx_align_right ltx_border_bb">12.83</td>
<td id="S3.T3.1.4.2.5" class="ltx_td ltx_align_right ltx_border_bb">0.219</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results for Baseline Systems</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Availability</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">The homepage for the dataset can be accessed here: <a target="_blank" href="http://www.cfilt.iitb.ac.in/iitb_parallel" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.cfilt.iitb.ac.in/iitb_parallel</a>. The new corpora we release are available for research and non-commercial use under a Creative Commons Attribution-NonCommercial-ShareAlike License <span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:70%;">http://creativecommons.org/licenses/by-nc-sa/4.0</a></span></span></span>. The corpora we compiled from other sources are available under their respective licenses. The sub-corpora (in the corpus distribution that we make available) are in the same order as listed in the Table <a href="#S2.T1" title="Table 1 ‣ 2. Dataset ‣ The IIT Bombay English-Hindi Parallel Corpus" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, so they can be separately extracted, if required (<span id="S4.p1.1.1" class="ltx_text ltx_font_italic">e.g. </span>for domain adaptation).</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion and Future Work</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">We presented the IIT Bombay English-Hindi Parallel corpus version 1.0, and provided benchmark baseline SMT and NMT results on this corpus. This corpus has been used for the two shared tasks (Workshop on Asian Language Translation 2016 and 2017). The <span id="S5.p1.1.1" class="ltx_text ltx_font_italic">HindiEn</span> component of the corpus has also been used for the WMT 2014 shared task. The corpus is available under a Creative Commons Licence.</p>
</div>
<div id="S5.p2" class="ltx_para ltx_noindent">
<p id="S5.p2.1" class="ltx_p">In future, we plan to enhance the corpus from additional sources, mostly websites of the Government of India which is still a largely untapped source of parallel corpora. We also plan to build stronger baselines like pre-ordering with PBSMT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx17" title="" class="ltx_ref">Ramanathan et al., 2008</a>]</cite> for English-Hindi translation, and use of synthetic corpora generated via back-translation for NMT systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">Sennrich et al., 2016a</a>]</cite>.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Acknowledgements</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p id="S6.p1.1" class="ltx_p">We thank past and present members of the Center for Indian Language Technology for their efforts in creating various parts of the corpora over the years: Pallabh Bhattacharjee, Kashyap Popat, Rahul Sharnagat, Mitesh Khapra, Jaya Jha, Rajita Shukla, Laxmi Kashyap, Gajanan Rane and many members of the Hindi WordNet team.
We also thank the Technology Development for Indian Languages (TDIL) Programme and the Department of Electronics &amp; Information Technology, Government of India for their support.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Bibliographical References</h2>

</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdelali et al., 2014</span>
<span class="ltx_bibblock">
Abdelali, A., Guzman, F., Sajjad, H., and Vogel, S.

</span>
<span class="ltx_bibblock">(2014).

</span>
<span class="ltx_bibblock">The AMARA Corpus: Building Parallel Language Resources for the
Educational Domain.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx1.1.1" class="ltx_text ltx_font_italic">Proceedings of the Ninth International Conference on Language
Resources and Evaluation (LREC’14)</span>.

</span>
</li>
<li id="bib.bibx2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alexandra Birch and Post, 2011</span>
<span class="ltx_bibblock">
Alexandra Birch, Chris Callison-Burch, M. O. and Post, M.

</span>
<span class="ltx_bibblock">(2011).

</span>
<span class="ltx_bibblock">The Indic multi-parallel corpus.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://homepages.inf.ed.ac.uk/miles/babel.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://homepages.inf.ed.ac.uk/miles/babel.html</a>.

</span>
</li>
<li id="bib.bibx3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bahdanau et al., 2015</span>
<span class="ltx_bibblock">
Bahdanau, D., Cho, K., and Bengio, Y.

</span>
<span class="ltx_bibblock">(2015).

</span>
<span class="ltx_bibblock">Neural machine translation by jointly learning to align and
translate.

</span>
<span class="ltx_bibblock"><span id="bib.bibx3.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>.

</span>
</li>
<li id="bib.bibx4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banerjee and Lavie, 2005</span>
<span class="ltx_bibblock">
Banerjee, S. and Lavie, A.

</span>
<span class="ltx_bibblock">(2005).

</span>
<span class="ltx_bibblock">METEOR: An automatic metric for MT evaluation with improved
correlation with human judgments.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx4.1.1" class="ltx_text ltx_font_italic">Proceedings of the ACL workshop on intrinsic and extrinsic
evaluation measures for machine translation and/or summarization</span>.

</span>
</li>
<li id="bib.bibx5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhattacharyya et al., 2014</span>
<span class="ltx_bibblock">
Bhattacharyya, P., Bahuguna, A., Talukdar, L., and Phukan, B.

</span>
<span class="ltx_bibblock">(2014).

</span>
<span class="ltx_bibblock">Facilitating multi-lingual sense annotation: Human mediated
lemmatizer.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx5.1.1" class="ltx_text ltx_font_italic">Global WordNet Conference</span>.

</span>
</li>
<li id="bib.bibx6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhattacharyya, 2010</span>
<span class="ltx_bibblock">
Bhattacharyya, P.

</span>
<span class="ltx_bibblock">(2010).

</span>
<span class="ltx_bibblock">IndoWordNet.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx6.1.1" class="ltx_text ltx_font_italic">Language Resources and Evaluation Conference</span>.

</span>
</li>
<li id="bib.bibx7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar et al., 2014a</span>
<span class="ltx_bibblock">
Bojar, O., Buck, C., Federmann, C., Haddow, B., Koehn, P., Leveling, J., Monz,
C., Pecina, P., Post, M., Saint-Amand, H., et al.

</span>
<span class="ltx_bibblock">(2014a).

</span>
<span class="ltx_bibblock">Findings of the 2014 workshop on statistical machine translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx7.1.1" class="ltx_text ltx_font_italic">Proceedings of the Ninth Workshop on Statistical Machine
Translation</span>.

</span>
</li>
<li id="bib.bibx8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojar et al., 2014b</span>
<span class="ltx_bibblock">
Bojar, O., Diatka, V., Rychlỳ, P., Stranák, P., Suchomel, V., Tamchyna,
A., and Zeman, D.

</span>
<span class="ltx_bibblock">(2014b).

</span>
<span class="ltx_bibblock">HindEnCorp-Hindi-English and Hindi-only Corpus for Machine
Translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx8.1.1" class="ltx_text ltx_font_italic">Language Resources and Evaluation Conference</span>.

</span>
</li>
<li id="bib.bibx9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cherry and Foster, 2012</span>
<span class="ltx_bibblock">
Cherry, C. and Foster, G.

</span>
<span class="ltx_bibblock">(2012).

</span>
<span class="ltx_bibblock">Batch tuning strategies for Statistical Machine Translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx9.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2012 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies</span>.

</span>
</li>
<li id="bib.bibx10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heafield, 2011</span>
<span class="ltx_bibblock">
Heafield, K.

</span>
<span class="ltx_bibblock">(2011).

</span>
<span class="ltx_bibblock">KenLM: Faster and smaller language model queries.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx10.1.1" class="ltx_text ltx_font_italic">Proceedings of the Sixth Workshop on Statistical Machine
Translation</span>.

</span>
</li>
<li id="bib.bibx11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Ba, 2014</span>
<span class="ltx_bibblock">
Kingma, D. and Ba, J.

</span>
<span class="ltx_bibblock">(2014).

</span>
<span class="ltx_bibblock">Adam: A method for stochastic optimization.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx11.1.1" class="ltx_text ltx_font_italic">International Conference on Learning Representations</span>.

</span>
</li>
<li id="bib.bibx12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn et al., 2007</span>
<span class="ltx_bibblock">
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi,
N., Cowan, B., Shen, W., Moran, C., Zens, R., et al.

</span>
<span class="ltx_bibblock">(2007).

</span>
<span class="ltx_bibblock">Moses: Open source toolkit for Statistical Machine
Translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx12.1.1" class="ltx_text ltx_font_italic">Proceedings of the 45th Annual Meeting of the ACL on
Interactive Poster and Demonstration Sessions</span>.

</span>
</li>
<li id="bib.bibx13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kunchukuttan et al., 2012</span>
<span class="ltx_bibblock">
Kunchukuttan, A., Roy, S., Patel, P., Ladha, K., Gupta, S., Khapra, M. M., and
Bhattacharyya, P.

</span>
<span class="ltx_bibblock">(2012).

</span>
<span class="ltx_bibblock">Experiences in Resource Generation for Machine Translation through
Crowdsourcing.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx13.1.1" class="ltx_text ltx_font_italic">Language Resources and Evaluation Conference</span>.

</span>
</li>
<li id="bib.bibx14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kunchukuttan et al., 2013</span>
<span class="ltx_bibblock">
Kunchukuttan, A., Chatterjee, R., Roy, S., Mishra, A., and Bhattacharyya, P.

</span>
<span class="ltx_bibblock">(2013).

</span>
<span class="ltx_bibblock">TransDoop: A Map-Reduce based Crowdsourced Translation for Complex
Domain.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx14.1.1" class="ltx_text ltx_font_italic">Conference of the Association of Computational Linguistics
(System Demonstrations)</span>.

</span>
</li>
<li id="bib.bibx15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moore, 2002</span>
<span class="ltx_bibblock">
Moore, R.

</span>
<span class="ltx_bibblock">(2002).

</span>
<span class="ltx_bibblock">Fast and accurate sentence alignment of bilingual corpora.

</span>
<span class="ltx_bibblock"><span id="bib.bibx15.1.1" class="ltx_text ltx_font_italic">Machine Translation: From Research to Real Users</span>.

</span>
</li>
<li id="bib.bibx16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al., 2002</span>
<span class="ltx_bibblock">
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.

</span>
<span class="ltx_bibblock">(2002).

</span>
<span class="ltx_bibblock">BLEU: A method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx16.1.1" class="ltx_text ltx_font_italic">Association for Computational Linguistics</span>.

</span>
</li>
<li id="bib.bibx17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramanathan et al., 2008</span>
<span class="ltx_bibblock">
Ramanathan, A., Hegde, J., Shah, R., Bhattacharyya, P., and Sasikumar, M.

</span>
<span class="ltx_bibblock">(2008).

</span>
<span class="ltx_bibblock">Simple Syntactic and Morphological Processing Can Help English-Hindi
Statistical Machine Translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx17.1.1" class="ltx_text ltx_font_italic">International Joint Conference on Natural Language
Processing</span>.

</span>
</li>
<li id="bib.bibx18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al., 2016a</span>
<span class="ltx_bibblock">
Sennrich, R., Haddow, B., and Birch, A.

</span>
<span class="ltx_bibblock">(2016a).

</span>
<span class="ltx_bibblock">Edinburgh Neural Machine Translation Systems for WMT 16.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx18.1.1" class="ltx_text ltx_font_italic">Workshop on Machine Translation (Shared Task)</span>.

</span>
</li>
<li id="bib.bibx19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al., 2016b</span>
<span class="ltx_bibblock">
Sennrich, R., Haddow, B., and Birch, A.

</span>
<span class="ltx_bibblock">(2016b).

</span>
<span class="ltx_bibblock">Neural machine translation of rare words with subword units.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx19.1.1" class="ltx_text ltx_font_italic">Conference of the Association of Computational Linguistics</span>.

</span>
</li>
<li id="bib.bibx20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et al., 2017</span>
<span class="ltx_bibblock">
Sennrich, R., Firat, O., Cho, K., Birch, A., Haddow, B., Hitschler, J.,
Junczys-Dowmunt, M., Läubli, S., Miceli Barone, A. V., Mokry, J., and
Nadejde, M.

</span>
<span class="ltx_bibblock">(2017).

</span>
<span class="ltx_bibblock">Nematus: a Toolkit for Neural Machine Translation.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx20.1.1" class="ltx_text ltx_font_italic">Proceedings of the Software Demonstrations of the 15th
Conference of the European Chapter of the Association for Computational
Linguistics</span>.

</span>
</li>
<li id="bib.bibx21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann, 2012</span>
<span class="ltx_bibblock">
Tiedemann, J.

</span>
<span class="ltx_bibblock">(2012).

</span>
<span class="ltx_bibblock">Parallel Data, Tools and Interfaces in OPUS.

</span>
<span class="ltx_bibblock">In <span id="bib.bibx21.1.1" class="ltx_text ltx_font_italic">Language Resources and Evaluation Conference</span>.

</span>
</li>
<li id="bib.bibx22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wikipedia, 2017</span>
<span class="ltx_bibblock">
Wikipedia.

</span>
<span class="ltx_bibblock">(2017).

</span>
<span class="ltx_bibblock">Hindi.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://en.wikipedia.org/w/index.php?title=Hindi&amp;oldid=802224343" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/w/index.php?title=Hindi&amp;oldid=802224343</a>.

</span>
<span class="ltx_bibblock">[Online; accessed 02-October-2017].

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1710.02854" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/land_of_honey_and_milk" rel="nofollow" aria-hidden="true" tabindex="-1"></a>
    <a href="/log/1710.02855" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1710.02855">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1710.02855" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1710.02856" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 01:28:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
