\section{Pedagogical Context} \label{sec:relatedwork}
Feedback is a powerful tool --- if not \emph{the most} powerful tool --- for effective teaching and learning, especially when it flows “from the student to the teacher”, that is, “when teachers seek, or at least are open to, feedback from students as to what students know, what they understand, where they make errors, when they have misconceptions, when they are not engaged”~\cite{hattie2009visiblelearning}. However, to deliver such power, feedback has to provide timely information about the process of learning. Instead of focusing on assignments' correctness, or on students' performance --- as praising, punishing or giving external rewards do --- feedback needs to fill “the gap between what is understood and what is aimed to be understood”. % However, feedback should be based on something: it is what happens after a instruction has been provided through a pedagogical method.

Peer Instruction (PI)~\cite{mazur1997peer} is a teaching method that institutes regular feedback to probe student understanding. It differs from traditional lectures, introducing topic-specific questions (“concept tests”) designed to reveal conceptual misunderstandings. The procedure:

\begin{itemize}
    \item Start class by presenting a topic;
    \item Ask a conceptual question (“concept test”) to check students’ understanding;
    \item Wait a moment for the students commit to an answer, then make a poll;
    \item If a large majority of the answers is right, clarify the few wrong answers and move on. If a large majority of the answers is wrong, present the topic again;
    \item If the answers are  divided, withhold the right answer, and have the students discuss the topic in small groups. After a set time, poll again. Almost invariably, the class will converge towards the right answer;
    \item Repeat for the next topic.
\end{itemize}

Due to its flexibility --- it adapts to any topic or teaching style --- PI has been extensively adopted.
%been extensively used, mostly because it adapts to practically any teaching style or topic: the teacher defines the lecture duration, the number of questions and the time assigned to answer those questions. 
The concept tests can be collected, organized, reused, and shared, within and across institutions~\cite{crouch2001peer, mazur1997peer}.

Vickrey et al.~\cite{vickrey2015PI} review 56 studies at STEM colleges, which report PI in large (\textgreater50 students) classrooms. They find PI offers measurable learning gains, twice larger than those offered by traditional lectures; PI also improves problem-solving, some of the studies reporting increased “ability to answer questions designed to measure mastery of material” and “to solve novel problems (i.e. transfer knowledge)”, as well as improved “quantitative problem-solving skills”. Finally, PI reduces attrition rates, with reduced dropout, and less failures.

PI's conceptual tests require polling the students, which, in a pinch, can be done by show of hands. But, as any teacher can report, students are tempted to follow the majority, or simply refuse to raise their hands for any of the presented alternatives. Giving the students cards of different colors, and asking them to raise one of them (corresponding to a yes/no or multiple-choice answer) is a better alternative: still, some students will attempt to follow the majority. Those “low-tech” alternatives only provide the teacher a rough aggregate feedback from the classroom, they preclude later analysis of individual answers.

% Also, peer instruction adopts small group discussion leading the students to pay attention and listen the arguments said during lecture, which contributes to reduce or eliminate the lack of attention tendency~\cite{beatty2006designing, yourstone2008classroom}.

% Classroom response systems (sometimes called audience response systems, student response systems, or personal response systems) offer a new interactivity model by enabling peer instruction~\cite{beatty2006designing}. Classroom response systems have been used in different courses formats, from formal lecture to cooperative learning and different levels, from introductory classes to graduation majors~\cite{fies2006classroom, caldwell2007clickers}. The literature exposes applications and classroom outcomes of using this system, presenting benefits but also challenges that will be addressed on the following section.


\subsection{Impacts of Classroom Response Systems}

Several studies~\cite{yourstone2008classroom, caldwell2007clickers} suggest that CRSs make the students more attentive: knowing that they will be polled make them better prepared for classes. %In addition CRSs allow anonymous answers, which allow the students to participate without exposing themselves to the entire group. 
Other studies~\cite{kay2009examining, caldwell2007clickers} mention frequent and positive interactions  when using CRSs during discussion sessions, reporting better articulated thinking~\cite{beatty2005transforming}, since students have to commit to an answer, and, if required, defend it (when CRS are used in combination with PI).

There are also potential benefits of CRSs for instructors, since they can analyze learning in real time~\cite{yourstone2008classroom} and adapt the lecture accordingly~\cite{caldwell2007clickers, cutts2006practical}. Some~\cite{yourstone2008classroom, caldwell2007clickers} suggest that such immediate feedback increases learning performance.

Hunsu et al.'s meta-analysis~\cite{hunsu2016ARSeffect} investigated the cognitive and non-cognitive effects of CRSs, compared to conventional lectures, comprising over 50 selected articles, with a total of 26,085 participants. They considered 111 independent learning outcomes, coded from all the variables present in the original studies, split in 86 cognitive and 25 non-cognitive outcomes. The meta-analysis shows that CRSs improve students' participation in large lecture halls (a common, and particularly challenging, environment for STEM courses). It also reveals small, but positive, cognitive outcomes of those technologies, specially on higher-level learning goals, like knowledge transfer, or knowledge application.

Despite those positive results, CRS implementation is challenging. Technological problems may occur (devices not working properly, communication problems)~\cite{siau2006use}. Applying CRSs without pedagogical preparation may not benefit the learning process, and can even harm the positive perception about those devices within classes. Preparing proper questions --- those which identify misconceptions --- is hard; if a standard set of questions is not available for using the CRS, the instructor will have the burden of choosing them for each lecture~\cite{caldwell2007clickers}.

Furthermore, CRS benefits only appear if classroom culture supports student engagement and interaction. Students must feel their answers are important, in order to engage, and to take the procedure seriously. Otherwise, adverse situations may arise, like giving wrong answers on purpose~\cite{siau2006use}.



