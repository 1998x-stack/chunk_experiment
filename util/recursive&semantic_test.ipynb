{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from chunk_experiment.util.helpers import (\n",
    "    semantic_chunks_to_text,\n",
    "    process_batch_chunk_output,\n",
    "\n",
    ")\n",
    "from chunk_experiment.util.chunk_highlight import TextHighlighter\n",
    "import time\n",
    "# è¯­ä¹‰åˆ†å—\n",
    "from chunk_experiment.util.embedding_api import EmbeddingClient\n",
    "from chunk_experiment.src.semantic_chunk import SemanticChunker, EmbeddingModel\n",
    "\n",
    "# é€’å½’åˆ†å—æ–¹æ³•1(chunk_size)\n",
    "from chunk_experiment.src.recursive_chunk import RecursiveCharacterTextSplitter\n",
    "\n",
    "# é€’å½’åˆ†å—æ–¹æ³•2(sentence&chunk_size)\n",
    "from chunk_experiment.util.sentence_split import GeneralTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"en_files\"\n",
    "#input_dir=\"zh_files\" \n",
    "file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".txt\") and os.path.isfile(os.path.join(input_dir, f))]\n",
    "\n",
    "# æµ‹è¯•æ–‡æœ¬\n",
    "# 100å•ä½é•¿åº¦\n",
    "sample_text_en =(\"This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By r\")\n",
    "sample_text =(\"è¿™æ˜¯ä¸€ä¸ªç”¨äºå±•ç¤ºå¦‚ä½•åœ¨Jupyter Notebookä¸­é«˜äº®æ˜¾ç¤ºæ–‡æœ¬åˆ†å—çš„ç¤ºä¾‹æ–‡æœ¬ã€‚é€šè¿‡éšæœºé€‰å–æ–‡æœ¬ç‰‡æ®µï¼Œå¹¶ä½¿ç”¨åˆ†å—APIè¿›è¡Œåˆ†å—å¤„ç†ï¼Œæœ€ç»ˆä»¥ä¸åŒé¢œè‰²é«˜äº®æ˜¾ç¤ºæ¯ä¸ªåˆ†å—ï¼Œç¡®ä¿ç›¸é‚»åˆ†å—é¢œè‰²ä¸åŒ,ä»è€Œæé«˜æ–‡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic_chunker\n",
    "TEST_URL = \"https://ai-platform-cloud-proxy.polymas.com/ai/common/kb-get-embedding\"\n",
    "embedding_client = EmbeddingClient(embedding_url=TEST_URL)\n",
    "embedding_model = EmbeddingModel(embedding_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic_cumulative_chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semanticcumulativechunker = SemanticChunker(\n",
    "    embedding_model=embedding_model,\n",
    "    min_characters_per_sentence=5,\n",
    "    similarity_threshold=None,  # ä½¿ç”¨åŠ¨æ€è®¡ç®—é˜ˆå€¼\n",
    "    similarity_percentile=90,\n",
    "    similarity_window=1,\n",
    "    mode=\"cumulative\",\n",
    "    initial_sentences=1,\n",
    "    min_sentences=1,\n",
    "    chunk_size=50,\n",
    "    min_chunk_size=20,\n",
    "    threshold_step=0.05,\n",
    "    sep=\"ğŸ®ğŸº\",\n",
    ").chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    semanticcumulativechunker(sample_text)  # è°ƒç”¨æµ‹è¯•å‡½æ•°\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"Semantic_cumulative_chunker 100ä¸ªæ–‡æ¡£å¹³å‡è¿è¡Œæ—¶é—´:{average_time:.4f}ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic_window_chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "semanticwindowchunker = SemanticChunker(\n",
    "    embedding_model=embedding_model,\n",
    "    min_characters_per_sentence=5,\n",
    "    similarity_threshold=None,  # ä½¿ç”¨åŠ¨æ€è®¡ç®—é˜ˆå€¼\n",
    "    similarity_percentile=90,\n",
    "    similarity_window=1,\n",
    "    mode=\"window\",\n",
    "    initial_sentences=1,\n",
    "    min_sentences=1,\n",
    "    chunk_size=50,\n",
    "    min_chunk_size=20,\n",
    "    threshold_step=0.05,\n",
    "    sep=\"ğŸ®ğŸº\",\n",
    ").chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    semanticwindowchunker(sample_text)  # è°ƒç”¨æµ‹è¯•å‡½æ•°\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"Semantic_window_chunker 100ä¸ªæ–‡æ¡£å¹³å‡è¿è¡Œæ—¶é—´:{average_time:.4f}ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecursiveChunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveChunker(æŒ‰ç…§chunk_sizeé€’å½’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursivesplitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"ã€‚\", \"ï¼Ÿ\", \"ï¼\", \"ï¼Œ\", \" \", \"\"],\n",
    ")\n",
    "recursivechunker = recursivesplitter.split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    recursivechunker(sample_text)  # è°ƒç”¨æµ‹è¯•å‡½æ•°\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"RecursiveChunker 100ä¸ªæ–‡æ¡£å¹³å‡è¿è¡Œæ—¶é—´:{average_time:.4f}ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveChunker(æŒ‰ç…§sentence&chunk_sizeé€’å½’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_sentence_splitter = GeneralTextSplitter(max_sentence_length=500)\n",
    "recursive_sentence_chunker = recursive_sentence_splitter.batch_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    recursive_sentence_chunker([sample_text])  # è°ƒç”¨æµ‹è¯•å‡½æ•°\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"RecursiveChunker 100ä¸ªæ–‡æ¡£å¹³å‡è¿è¡Œæ—¶é—´:{average_time:.4f}ç§’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é«˜äº®å±•ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "éšæœºé€‰å–çš„æ–‡æœ¬ç‰‡æ®µèµ·å§‹ç´¢å¼•: 1568, é•¿åº¦: 500\n",
      "é€‰å–çš„æ–‡æœ¬ç‰‡æ®µ:\n",
      "arameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications.\n",
      "\n",
      "æ–‡æœ¬å·²åˆ†æˆ 4 å—ã€‚\n",
      "åˆ†å—ç»“æœ:\n",
      "Chunk 1: arameter configurations, to adapt to different types of text and application requirements.For instance,\n",
      "Chunk 2: the chunking process can dynamically adjust chunk sizes based on text length,paragraph structure,or semantic relevance.\n",
      "Chunk 3: At the same time,the choice of colors can be customized based on user preferences,thereby meeting different aesthetic and usability needs.\n",
      "Chunk 4: This approach not only improves the technical level of text processing but also brings new possibilities for practicalapplications.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">arameter configurations, to adapt to different types of text and application requirements.For instance,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the chunking process can dynamically adjust chunk sizes based on text length,paragraph structure,or semantic relevance.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">At the same time,the choice of colors can be customized based on user preferences,thereby meeting different aesthetic and usability needs.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This approach not only improves the technical level of text processing but also brings new possibilities for practicalapplications.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 500\n",
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text_en, chunking_api=semanticcumulativechunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text(wrapper_func=semantic_chunks_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "éšæœºé€‰å–çš„æ–‡æœ¬ç‰‡æ®µèµ·å§‹ç´¢å¼•: 969, é•¿åº¦: 500\n",
      "é€‰å–çš„æ–‡æœ¬ç‰‡æ®µ:\n",
      "ents, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve\n",
      "\n",
      "æ–‡æœ¬å·²åˆ†æˆ 2 å—ã€‚\n",
      "åˆ†å—ç»“æœ:\n",
      "Chunk 1: ents, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.In the education field,teachers can use this highlighting and chunking technique to provide students with visual learning materials,such as emphasizing grammar points,\n",
      "Chunk 2: key phrases,and paragraph structures in texts.The flexibility of this technique makes it suitable for a wide range of scenarios,offering great convenience for both teaching and research purposes.To achieve\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ents, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.In the education field,teachers can use this highlighting and chunking technique to provide students with visual learning materials,such as emphasizing grammar points,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">key phrases,and paragraph structures in texts.The flexibility of this technique makes it suitable for a wide range of scenarios,offering great convenience for both teaching and research purposes.To achieve</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text_en, chunking_api=semanticwindowchunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text(wrapper_func=semantic_chunks_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "éšæœºé€‰å–çš„æ–‡æœ¬ç‰‡æ®µèµ·å§‹ç´¢å¼•: 673, é•¿åº¦: 500\n",
      "é€‰å–çš„æ–‡æœ¬ç‰‡æ®µ:\n",
      ". Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique t\n",
      "\n",
      "æ–‡æœ¬å·²åˆ†æˆ 13 å—ã€‚\n",
      "åˆ†å—ç»“æœ:\n",
      "Chunk 1: .\n",
      "\n",
      "Additionally,\n",
      "\n",
      "this\n",
      "\n",
      "approach\n",
      "\n",
      "can\n",
      "\n",
      "be\n",
      "\n",
      "applied\n",
      "Chunk 2: e\n",
      "\n",
      "appliedin\n",
      "\n",
      "natural\n",
      "\n",
      "language\n",
      "\n",
      "processing\n",
      "\n",
      "(NLP)\n",
      "\n",
      "tasks\n",
      "Chunk 3: LP)\n",
      "\n",
      "tasksfor\n",
      "\n",
      "text\n",
      "\n",
      "visualization,\n",
      "\n",
      "such\n",
      "\n",
      "as\n",
      "\n",
      "displaying\n",
      "Chunk 4: displayingsentiment\n",
      "\n",
      "analysis\n",
      "\n",
      "results,\n",
      "\n",
      "keyword\n",
      "Chunk 5: ,\n",
      "\n",
      "keywordextraction,\n",
      "\n",
      "or\n",
      "\n",
      "topic\n",
      "\n",
      "modeling\n",
      "\n",
      "outputs.\n",
      "\n",
      "By\n",
      "Chunk 6: tputs.\n",
      "\n",
      "Byusing\n",
      "\n",
      "different\n",
      "\n",
      "colors\n",
      "\n",
      "or\n",
      "\n",
      "formats\n",
      "\n",
      "to\n",
      "Chunk 7: ormats\n",
      "\n",
      "todistinguish\n",
      "\n",
      "positive,\n",
      "\n",
      "negative,\n",
      "\n",
      "and\n",
      "\n",
      "neutral\n",
      "Chunk 8: d\n",
      "\n",
      "neutralsentiments,\n",
      "\n",
      "the\n",
      "\n",
      "analysis\n",
      "\n",
      "results\n",
      "\n",
      "become\n",
      "Chunk 9: ts\n",
      "\n",
      "becomeintuitive\n",
      "\n",
      "and\n",
      "\n",
      "easy\n",
      "\n",
      "to\n",
      "\n",
      "understand,\n",
      "Chunk 10: nderstand,facilitating\n",
      "\n",
      "team\n",
      "\n",
      "collaboration\n",
      "\n",
      "and\n",
      "Chunk 11: ation\n",
      "\n",
      "anddecision-making.\n",
      "\n",
      "In\n",
      "\n",
      "the\n",
      "\n",
      "education\n",
      "\n",
      "field,\n",
      "Chunk 12: on\n",
      "\n",
      "field,teachers\n",
      "\n",
      "can\n",
      "\n",
      "use\n",
      "\n",
      "this\n",
      "\n",
      "highlighting\n",
      "\n",
      "and\n",
      "Chunk 13: hting\n",
      "\n",
      "andchunking\n",
      "\n",
      "technique\n",
      "\n",
      "t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">.\n",
       "\n",
       "Additionally,\n",
       "\n",
       "this\n",
       "\n",
       "approach\n",
       "\n",
       "can\n",
       "\n",
       "be\n",
       "\n",
       "applied</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">e\n",
       "\n",
       "appliedin\n",
       "\n",
       "natural\n",
       "\n",
       "language\n",
       "\n",
       "processing\n",
       "\n",
       "(NLP)\n",
       "\n",
       "tasks</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">LP)\n",
       "\n",
       "tasksfor\n",
       "\n",
       "text\n",
       "\n",
       "visualization,\n",
       "\n",
       "such\n",
       "\n",
       "as\n",
       "\n",
       "displaying</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">displayingsentiment\n",
       "\n",
       "analysis\n",
       "\n",
       "results,\n",
       "\n",
       "keyword</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">,\n",
       "\n",
       "keywordextraction,\n",
       "\n",
       "or\n",
       "\n",
       "topic\n",
       "\n",
       "modeling\n",
       "\n",
       "outputs.\n",
       "\n",
       "By</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tputs.\n",
       "\n",
       "Byusing\n",
       "\n",
       "different\n",
       "\n",
       "colors\n",
       "\n",
       "or\n",
       "\n",
       "formats\n",
       "\n",
       "to</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ormats\n",
       "\n",
       "todistinguish\n",
       "\n",
       "positive,\n",
       "\n",
       "negative,\n",
       "\n",
       "and\n",
       "\n",
       "neutral</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">d\n",
       "\n",
       "neutralsentiments,\n",
       "\n",
       "the\n",
       "\n",
       "analysis\n",
       "\n",
       "results\n",
       "\n",
       "become</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ts\n",
       "\n",
       "becomeintuitive\n",
       "\n",
       "and\n",
       "\n",
       "easy\n",
       "\n",
       "to\n",
       "\n",
       "understand,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">nderstand,facilitating\n",
       "\n",
       "team\n",
       "\n",
       "collaboration\n",
       "\n",
       "and</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ation\n",
       "\n",
       "anddecision-making.\n",
       "\n",
       "In\n",
       "\n",
       "the\n",
       "\n",
       "education\n",
       "\n",
       "field,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">on\n",
       "\n",
       "field,teachers\n",
       "\n",
       "can\n",
       "\n",
       "use\n",
       "\n",
       "this\n",
       "\n",
       "highlighting\n",
       "\n",
       "and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">hting\n",
       "\n",
       "andchunking\n",
       "\n",
       "technique\n",
       "\n",
       "t</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text_en, chunking_api=recursivechunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é•¿æ–‡æœ¬é•¿åº¦å°äºæˆ–ç­‰äºmax_length (500)ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬ã€‚\n",
      "é€‰å–çš„æ–‡æœ¬ç‰‡æ®µ:\n",
      "['This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors. This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text. This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation. For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension. Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications. In summary, by combining text chunking and visualization techniques, we can process complex information more efficiently, providing stronger support for data-driven decision-making.']\n",
      "\n",
      "æ–‡æœ¬å·²åˆ†æˆ 2 å—ã€‚\n",
      "åˆ†å—ç»“æœ:\n",
      "Chunk 1: This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook.\n",
      "Chunk 2: This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors.\n",
      "Chunk 3: By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors. This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text.\n",
      "Chunk 4: This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text. This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation.\n",
      "Chunk 5: This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation. For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension.\n",
      "Chunk 6: For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension. Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs.\n",
      "Chunk 7: Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.\n",
      "Chunk 8: By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts.\n",
      "Chunk 9: In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes.\n",
      "Chunk 10: The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements.\n",
      "Chunk 11: To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance.\n",
      "Chunk 12: For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs.\n",
      "Chunk 13: At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications.\n",
      "Chunk 14: This approach not only improves the technical level of text processing but also brings new possibilities for practical applications. In summary, by combining text chunking and visualization techniques, we can process complex information more efficiently, providing stronger support for data-driven decision-making.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors. This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text. This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation. For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension. Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This approach not only improves the technical level of text processing but also brings new possibilities for practical applications. In summary, by combining text chunking and visualization techniques, we can process complex information more efficiently, providing stronger support for data-driven decision-making.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlighter = TextHighlighter(\n",
    "    long_text=[sample_text_en], chunking_api=recursive_sentence_chunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text(wrapper_func=process_batch_chunk_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
