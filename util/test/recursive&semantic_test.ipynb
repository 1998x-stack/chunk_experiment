{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from chunk_experiment.util.helpers import (\n",
    "    semantic_chunks_to_text,\n",
    "    process_batch_chunk_output,\n",
    "\n",
    ")\n",
    "from chunk_experiment.util.chunk_highlight import TextHighlighter\n",
    "import time\n",
    "# 语义分块\n",
    "from chunk_experiment.util.embedding_api import EmbeddingClient\n",
    "from chunk_experiment.src.semantic_chunk import SemanticChunker, EmbeddingModel\n",
    "\n",
    "# 递归分块方法1(chunk_size)\n",
    "from chunk_experiment.src.recursive_chunk import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 递归分块方法2(sentence&chunk_size)\n",
    "from chunk_experiment.util.sentence_split import GeneralTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir=\"en_files\"\n",
    "#input_dir=\"zh_files\" \n",
    "file_paths = [os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith(\".txt\") and os.path.isfile(os.path.join(input_dir, f))]\n",
    "\n",
    "# 测试文本\n",
    "# 100单位长度\n",
    "sample_text_en =(\"This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By r\")\n",
    "sample_text =(\"这是一个用于展示如何在Jupyter Notebook中高亮显示文本分块的示例文本。通过随机选取文本片段，并使用分块API进行分块处理，最终以不同颜色高亮显示每个分块，确保相邻分块颜色不同,从而提高文\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic_chunker\n",
    "TEST_URL = \"https://ai-platform-cloud-proxy.polymas.com/ai/common/kb-get-embedding\"\n",
    "embedding_client = EmbeddingClient(embedding_url=TEST_URL)\n",
    "embedding_model = EmbeddingModel(embedding_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic_cumulative_chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semanticcumulativechunker = SemanticChunker(\n",
    "    embedding_model=embedding_model,\n",
    "    min_characters_per_sentence=5,\n",
    "    similarity_threshold=None,  # 使用动态计算阈值\n",
    "    similarity_percentile=90,\n",
    "    similarity_window=1,\n",
    "    mode=\"cumulative\",\n",
    "    initial_sentences=1,\n",
    "    min_sentences=1,\n",
    "    chunk_size=50,\n",
    "    min_chunk_size=20,\n",
    "    threshold_step=0.05,\n",
    "    sep=\"🐮🍺\",\n",
    ").chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    semanticcumulativechunker(sample_text)  # 调用测试函数\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"Semantic_cumulative_chunker 100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic_window_chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "semanticwindowchunker = SemanticChunker(\n",
    "    embedding_model=embedding_model,\n",
    "    min_characters_per_sentence=5,\n",
    "    similarity_threshold=None,  # 使用动态计算阈值\n",
    "    similarity_percentile=90,\n",
    "    similarity_window=1,\n",
    "    mode=\"window\",\n",
    "    initial_sentences=1,\n",
    "    min_sentences=1,\n",
    "    chunk_size=50,\n",
    "    min_chunk_size=20,\n",
    "    threshold_step=0.05,\n",
    "    sep=\"🐮🍺\",\n",
    ").chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    semanticwindowchunker(sample_text)  # 调用测试函数\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "\n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"Semantic_window_chunker 100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecursiveChunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveChunker(按照chunk_size递归)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursivesplitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"。\", \"？\", \"！\", \"，\", \" \", \"\"],\n",
    ")\n",
    "recursivechunker = recursivesplitter.split_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    recursivechunker(sample_text)  # 调用测试函数\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"RecursiveChunker 100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecursiveChunker(按照sentence&chunk_size递归)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_sentence_splitter = GeneralTextSplitter(max_sentence_length=500)\n",
    "recursive_sentence_chunker = recursive_sentence_splitter.batch_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    recursive_sentence_chunker([sample_text])  # 调用测试函数\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time += (end_time - start_time)\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"RecursiveChunker 100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 高亮展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 1568, 长度: 500\n",
      "选取的文本片段:\n",
      "arameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications.\n",
      "\n",
      "文本已分成 4 块。\n",
      "分块结果:\n",
      "Chunk 1: arameter configurations, to adapt to different types of text and application requirements.For instance,\n",
      "Chunk 2: the chunking process can dynamically adjust chunk sizes based on text length,paragraph structure,or semantic relevance.\n",
      "Chunk 3: At the same time,the choice of colors can be customized based on user preferences,thereby meeting different aesthetic and usability needs.\n",
      "Chunk 4: This approach not only improves the technical level of text processing but also brings new possibilities for practicalapplications.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">arameter configurations, to adapt to different types of text and application requirements.For instance,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the chunking process can dynamically adjust chunk sizes based on text length,paragraph structure,or semantic relevance.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">At the same time,the choice of colors can be customized based on user preferences,thereby meeting different aesthetic and usability needs.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This approach not only improves the technical level of text processing but also brings new possibilities for practicalapplications.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 500\n",
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text_en, chunking_api=semanticcumulativechunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text(wrapper_func=semantic_chunks_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 969, 长度: 500\n",
      "选取的文本片段:\n",
      "ents, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve\n",
      "\n",
      "文本已分成 2 块。\n",
      "分块结果:\n",
      "Chunk 1: ents, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.In the education field,teachers can use this highlighting and chunking technique to provide students with visual learning materials,such as emphasizing grammar points,\n",
      "Chunk 2: key phrases,and paragraph structures in texts.The flexibility of this technique makes it suitable for a wide range of scenarios,offering great convenience for both teaching and research purposes.To achieve\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ents, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.In the education field,teachers can use this highlighting and chunking technique to provide students with visual learning materials,such as emphasizing grammar points,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">key phrases,and paragraph structures in texts.The flexibility of this technique makes it suitable for a wide range of scenarios,offering great convenience for both teaching and research purposes.To achieve</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text_en, chunking_api=semanticwindowchunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text(wrapper_func=semantic_chunks_to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 673, 长度: 500\n",
      "选取的文本片段:\n",
      ". Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique t\n",
      "\n",
      "文本已分成 13 块。\n",
      "分块结果:\n",
      "Chunk 1: .\n",
      "\n",
      "Additionally,\n",
      "\n",
      "this\n",
      "\n",
      "approach\n",
      "\n",
      "can\n",
      "\n",
      "be\n",
      "\n",
      "applied\n",
      "Chunk 2: e\n",
      "\n",
      "appliedin\n",
      "\n",
      "natural\n",
      "\n",
      "language\n",
      "\n",
      "processing\n",
      "\n",
      "(NLP)\n",
      "\n",
      "tasks\n",
      "Chunk 3: LP)\n",
      "\n",
      "tasksfor\n",
      "\n",
      "text\n",
      "\n",
      "visualization,\n",
      "\n",
      "such\n",
      "\n",
      "as\n",
      "\n",
      "displaying\n",
      "Chunk 4: displayingsentiment\n",
      "\n",
      "analysis\n",
      "\n",
      "results,\n",
      "\n",
      "keyword\n",
      "Chunk 5: ,\n",
      "\n",
      "keywordextraction,\n",
      "\n",
      "or\n",
      "\n",
      "topic\n",
      "\n",
      "modeling\n",
      "\n",
      "outputs.\n",
      "\n",
      "By\n",
      "Chunk 6: tputs.\n",
      "\n",
      "Byusing\n",
      "\n",
      "different\n",
      "\n",
      "colors\n",
      "\n",
      "or\n",
      "\n",
      "formats\n",
      "\n",
      "to\n",
      "Chunk 7: ormats\n",
      "\n",
      "todistinguish\n",
      "\n",
      "positive,\n",
      "\n",
      "negative,\n",
      "\n",
      "and\n",
      "\n",
      "neutral\n",
      "Chunk 8: d\n",
      "\n",
      "neutralsentiments,\n",
      "\n",
      "the\n",
      "\n",
      "analysis\n",
      "\n",
      "results\n",
      "\n",
      "become\n",
      "Chunk 9: ts\n",
      "\n",
      "becomeintuitive\n",
      "\n",
      "and\n",
      "\n",
      "easy\n",
      "\n",
      "to\n",
      "\n",
      "understand,\n",
      "Chunk 10: nderstand,facilitating\n",
      "\n",
      "team\n",
      "\n",
      "collaboration\n",
      "\n",
      "and\n",
      "Chunk 11: ation\n",
      "\n",
      "anddecision-making.\n",
      "\n",
      "In\n",
      "\n",
      "the\n",
      "\n",
      "education\n",
      "\n",
      "field,\n",
      "Chunk 12: on\n",
      "\n",
      "field,teachers\n",
      "\n",
      "can\n",
      "\n",
      "use\n",
      "\n",
      "this\n",
      "\n",
      "highlighting\n",
      "\n",
      "and\n",
      "Chunk 13: hting\n",
      "\n",
      "andchunking\n",
      "\n",
      "technique\n",
      "\n",
      "t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">.\n",
       "\n",
       "Additionally,\n",
       "\n",
       "this\n",
       "\n",
       "approach\n",
       "\n",
       "can\n",
       "\n",
       "be\n",
       "\n",
       "applied</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">e\n",
       "\n",
       "appliedin\n",
       "\n",
       "natural\n",
       "\n",
       "language\n",
       "\n",
       "processing\n",
       "\n",
       "(NLP)\n",
       "\n",
       "tasks</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">LP)\n",
       "\n",
       "tasksfor\n",
       "\n",
       "text\n",
       "\n",
       "visualization,\n",
       "\n",
       "such\n",
       "\n",
       "as\n",
       "\n",
       "displaying</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">displayingsentiment\n",
       "\n",
       "analysis\n",
       "\n",
       "results,\n",
       "\n",
       "keyword</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">,\n",
       "\n",
       "keywordextraction,\n",
       "\n",
       "or\n",
       "\n",
       "topic\n",
       "\n",
       "modeling\n",
       "\n",
       "outputs.\n",
       "\n",
       "By</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tputs.\n",
       "\n",
       "Byusing\n",
       "\n",
       "different\n",
       "\n",
       "colors\n",
       "\n",
       "or\n",
       "\n",
       "formats\n",
       "\n",
       "to</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ormats\n",
       "\n",
       "todistinguish\n",
       "\n",
       "positive,\n",
       "\n",
       "negative,\n",
       "\n",
       "and\n",
       "\n",
       "neutral</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">d\n",
       "\n",
       "neutralsentiments,\n",
       "\n",
       "the\n",
       "\n",
       "analysis\n",
       "\n",
       "results\n",
       "\n",
       "become</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ts\n",
       "\n",
       "becomeintuitive\n",
       "\n",
       "and\n",
       "\n",
       "easy\n",
       "\n",
       "to\n",
       "\n",
       "understand,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">nderstand,facilitating\n",
       "\n",
       "team\n",
       "\n",
       "collaboration\n",
       "\n",
       "and</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ation\n",
       "\n",
       "anddecision-making.\n",
       "\n",
       "In\n",
       "\n",
       "the\n",
       "\n",
       "education\n",
       "\n",
       "field,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">on\n",
       "\n",
       "field,teachers\n",
       "\n",
       "can\n",
       "\n",
       "use\n",
       "\n",
       "this\n",
       "\n",
       "highlighting\n",
       "\n",
       "and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">hting\n",
       "\n",
       "andchunking\n",
       "\n",
       "technique\n",
       "\n",
       "t</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text_en, chunking_api=recursivechunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "长文本长度小于或等于max_length (500)，返回整个文本。\n",
      "选取的文本片段:\n",
      "['This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors. This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text. This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation. For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension. Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications. In summary, by combining text chunking and visualization techniques, we can process complex information more efficiently, providing stronger support for data-driven decision-making.']\n",
      "\n",
      "文本已分成 2 块。\n",
      "分块结果:\n",
      "Chunk 1: This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook.\n",
      "Chunk 2: This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors.\n",
      "Chunk 3: By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors. This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text.\n",
      "Chunk 4: This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text. This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation.\n",
      "Chunk 5: This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation. For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension.\n",
      "Chunk 6: For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension. Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs.\n",
      "Chunk 7: Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.\n",
      "Chunk 8: By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts.\n",
      "Chunk 9: In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes.\n",
      "Chunk 10: The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements.\n",
      "Chunk 11: To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance.\n",
      "Chunk 12: For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs.\n",
      "Chunk 13: At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications.\n",
      "Chunk 14: This approach not only improves the technical level of text processing but also brings new possibilities for practical applications. In summary, by combining text chunking and visualization techniques, we can process complex information more efficiently, providing stronger support for data-driven decision-making.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This is a sample text designed to demonstrate how to highlight text chunks in Jupyter Notebook. By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">By randomly selecting text fragments and using a chunking API to process the text into chunks, each chunk can be highlighted with different colors. This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This ensures that adjacent chunks are displayed in distinct colors, enhancing the readability and visual appeal of the text. This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This method is highly useful in industrial scenarios such as data analysis, text processing, and report generation. For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For example, in long reports, highlighting key content from different sections can help readers quickly locate important information, thereby improving reading efficiency and comprehension. Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Additionally, this approach can be applied in natural language processing (NLP) tasks for text visualization, such as displaying sentiment analysis results, keyword extraction, or topic modeling outputs. By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">By using different colors or formats to distinguish positive, negative, and neutral sentiments, the analysis results become intuitive and easy to understand, facilitating team collaboration and decision-making. In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">In the education field, teachers can use this highlighting and chunking technique to provide students with visual learning materials, such as emphasizing grammar points, key phrases, and paragraph structures in texts. The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The flexibility of this technique makes it suitable for a wide range of scenarios, offering great convenience for both teaching and research purposes. To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">To achieve this functionality, the chunking API needs to be equipped with efficient algorithms and flexible parameter configurations, to adapt to different types of text and application requirements. For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For instance, the chunking process can dynamically adjust chunk sizes based on text length, paragraph structure, or semantic relevance. At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">At the same time, the choice of colors can be customized based on user preferences, thereby meeting different aesthetic and usability needs. This approach not only improves the technical level of text processing but also brings new possibilities for practical applications.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This approach not only improves the technical level of text processing but also brings new possibilities for practical applications. In summary, by combining text chunking and visualization techniques, we can process complex information more efficiently, providing stronger support for data-driven decision-making.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlighter = TextHighlighter(\n",
    "    long_text=[sample_text_en], chunking_api=recursive_sentence_chunker, max_length=max_len\n",
    ")\n",
    "highlighter.display_highlighted_text(wrapper_func=process_batch_chunk_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
