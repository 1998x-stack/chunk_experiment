{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "from langchain.text_splitter import (\n",
    "    HTMLHeaderTextSplitter,\n",
    "    PythonCodeTextSplitter,\n",
    "    MarkdownTextSplitter,\n",
    "    LatexTextSplitter,\n",
    ")\n",
    "from chunk_experiment.util.chunk_highlight import TextHighlighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_files_path=\"chunk_experiment/data/html/arxiv\"\n",
    "latex_files_path=\"chunk_experiment/data/latex/arxiv\"\n",
    "md_files_path=\"chunk_experiment/data/markdown/markdown-documentation-transformers\"\n",
    "python_files_path=\"chunk_experiment/data/python\"\n",
    "\n",
    "html_splitter = HTMLSectionSplitter(headers_to_split_on=[(\"h1\", \"Header 1\"),(\"h2\", \"Header 2\"),(\"h3\", \"Header 3\"),(\"h4\", \"Header 4\"),(\"h5\", \"Header 5\"),(\"h6\", \"Header 6\")])\n",
    "python_splitter = PythonCodeTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "md_splitter = MarkdownTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "tex_splitter = LatexTextSplitter(chunk_size=50, chunk_overlap=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_type(type):\n",
    "    if type==\".html\":\n",
    "        return html_files_path,html_splitter\n",
    "    elif type==\".tex\":\n",
    "        return latex_files_path,tex_splitter\n",
    "    elif type==\".md\":\n",
    "        return md_files_path,md_splitter\n",
    "    elif type==\".py\":\n",
    "        return python_files_path,python_splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/340.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/205.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/74.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/439.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/252.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/481.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/23.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/194.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/301.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/244.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/35.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/497.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/182.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/478.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/356.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/213.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/62.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/9.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/268.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/287.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/454.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/141.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/19.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/395.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/403.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/116.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/383.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/229.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/415.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/100.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/58.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/291.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/442.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/157.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/120.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/78.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/97.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/435.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/209.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/177.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/198.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/462.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/161.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/39.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/474.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/248.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/136.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/423.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/81.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/5.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/458.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/15.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/264.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/321.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/42.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/399.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/233.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/376.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/419.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/54.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/225.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/360.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/272.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/337.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/273.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/336.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/224.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/361.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/418.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/55.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/398.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/232.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/377.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/43.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/265.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/320.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/459.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/14.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/137.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/422.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/4.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/80.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/249.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/160.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/38.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/475.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/176.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/199.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/463.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/208.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/121.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/79.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/96.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/434.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/443.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/156.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/290.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/414.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/101.html\n",
      "\n",
      "测试文件: chunk_experiment/data/html/arxiv/59.html\n",
      "100个文档平均运行时间:0.5939秒\n"
     ]
    }
   ],
   "source": [
    "type=\".html\"\n",
    "paths,splitter = choose_type(type)\n",
    "\n",
    "file_paths = [os.path.join(paths, f) for f in os.listdir(paths) if f.endswith(type)]\n",
    "file_paths = file_paths[:100]\n",
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "\n",
    "    # html需要移除xml声明\n",
    "    sample_text = sample_text.replace('<?xml version=\"1.0\" encoding=\"UTF-8\"?>', '')\n",
    "    print(f\"\\n测试文件: {file_path}\")\n",
    "    start_time = time.time()\n",
    "    splitter.split_text(sample_text)\n",
    "    end_time = time.time()\n",
    "    total_time += end_time - start_time\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高亮展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 1057671, 长度: 200000\n",
      "选取的文本片段:\n",
      "</apply><apply id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1\"><times id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.2\"></times><apply id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply><apply id=\"S4.E1.m1.1.1.1.1.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2\"><apply id=\"S4.E1.m1.1.1.1.1.2.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.2.2.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2\">superscript</csymbol><apply id=\"S4.E1.m1.1.1.1.1.2.2.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.2.2.2.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2\">subscript</csymbol><sum id=\"S4.E1.m1.1.1.1.1.2.2.2.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2.2.2\"></sum><apply id=\"S4.E1.m1.1.1.1.1.2.2.2.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2.2.3\"><eq id=\"S4.E1.m1.1.1.1.1.2.2.2.3.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2.2.3.1\"></eq><ci id=\"S4.E1.m1.1.1.1.1.2.2.2.3.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.E1.m1.1.1.1.1.2.2.2.3.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.E1.m1.1.1.1.1.2.2.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.2.3\">𝑛</ci></apply><apply id=\"S4.E1.m1.1.1.1.1.2.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1\"><times id=\"S4.E1.m1.1.1.1.1.2.1.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.2\"></times><apply id=\"S4.E1.m1.1.1.1.1.2.1.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.2.1.3.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.3\">subscript</csymbol><ci id=\"S4.E1.m1.1.1.1.1.2.1.3.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.3.2\">𝑤</ci><ci id=\"S4.E1.m1.1.1.1.1.2.1.3.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.3.3\">𝑖</ci></apply><apply id=\"S4.E1.m1.1.1.1.1.2.1.4.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.2.1.4.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.4\">subscript</csymbol><ci id=\"S4.E1.m1.1.1.1.1.2.1.4.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.4.2\">Φ</ci><ci id=\"S4.E1.m1.1.1.1.1.2.1.4.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.4.3\">𝑖</ci></apply><apply id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1\"><times id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.2\"></times><ci id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.3\">𝑓</ci><apply id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E1.m1.1.1.1.1.2.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.E1.m1.1c\">f\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)},</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "</table>\n",
      "<p id=\"S4.p2.10\" class=\"ltx_p\">for operator convex function <math id=\"S4.p2.1.m1.1\" class=\"ltx_Math\" alttext=\"f\" display=\"inline\"><semantics id=\"S4.p2.1.m1.1a\"><mi id=\"S4.p2.1.m1.1.1\" xref=\"S4.p2.1.m1.1.1.cmml\">f</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.1.m1.1b\"><ci id=\"S4.p2.1.m1.1.1.cmml\" xref=\"S4.p2.1.m1.1.1\">𝑓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.1.m1.1c\">f</annotation></semantics></math> defined on an interval <math id=\"S4.p2.2.m2.1\" class=\"ltx_Math\" alttext=\"I\" display=\"inline\"><semantics id=\"S4.p2.2.m2.1a\"><mi id=\"S4.p2.2.m2.1.1\" xref=\"S4.p2.2.m2.1.1.cmml\">I</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.2.m2.1b\"><ci id=\"S4.p2.2.m2.1.1.cmml\" xref=\"S4.p2.2.m2.1.1\">𝐼</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.2.m2.1c\">I</annotation></semantics></math>, where <math id=\"S4.p2.3.m3.1\" class=\"ltx_Math\" alttext=\"{{\\Phi}_{i}}\" display=\"inline\"><semantics id=\"S4.p2.3.m3.1a\"><msub id=\"S4.p2.3.m3.1.1\" xref=\"S4.p2.3.m3.1.1.cmml\"><mi mathvariant=\"normal\" id=\"S4.p2.3.m3.1.1.2\" xref=\"S4.p2.3.m3.1.1.2.cmml\">Φ</mi><mi id=\"S4.p2.3.m3.1.1.3\" xref=\"S4.p2.3.m3.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.3.m3.1b\"><apply id=\"S4.p2.3.m3.1.1.cmml\" xref=\"S4.p2.3.m3.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.p2.3.m3.1.1.1.cmml\" xref=\"S4.p2.3.m3.1.1\">subscript</csymbol><ci id=\"S4.p2.3.m3.1.1.2.cmml\" xref=\"S4.p2.3.m3.1.1.2\">Φ</ci><ci id=\"S4.p2.3.m3.1.1.3.cmml\" xref=\"S4.p2.3.m3.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.3.m3.1c\">{{\\Phi}_{i}}</annotation></semantics></math> (<math id=\"S4.p2.4.m4.3\" class=\"ltx_Math\" alttext=\"i=1,\\ldots,n\" display=\"inline\"><semantics id=\"S4.p2.4.m4.3a\"><mrow id=\"S4.p2.4.m4.3.4\" xref=\"S4.p2.4.m4.3.4.cmml\"><mi id=\"S4.p2.4.m4.3.4.2\" xref=\"S4.p2.4.m4.3.4.2.cmml\">i</mi><mo id=\"S4.p2.4.m4.3.4.1\" xref=\"S4.p2.4.m4.3.4.1.cmml\">=</mo><mrow id=\"S4.p2.4.m4.3.4.3.2\" xref=\"S4.p2.4.m4.3.4.3.1.cmml\"><mn id=\"S4.p2.4.m4.1.1\" xref=\"S4.p2.4.m4.1.1.cmml\">1</mn><mo id=\"S4.p2.4.m4.3.4.3.2.1\" xref=\"S4.p2.4.m4.3.4.3.1.cmml\">,</mo><mi mathvariant=\"normal\" id=\"S4.p2.4.m4.2.2\" xref=\"S4.p2.4.m4.2.2.cmml\">…</mi><mo id=\"S4.p2.4.m4.3.4.3.2.2\" xref=\"S4.p2.4.m4.3.4.3.1.cmml\">,</mo><mi id=\"S4.p2.4.m4.3.3\" xref=\"S4.p2.4.m4.3.3.cmml\">n</mi></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.4.m4.3b\"><apply id=\"S4.p2.4.m4.3.4.cmml\" xref=\"S4.p2.4.m4.3.4\"><eq id=\"S4.p2.4.m4.3.4.1.cmml\" xref=\"S4.p2.4.m4.3.4.1\"></eq><ci id=\"S4.p2.4.m4.3.4.2.cmml\" xref=\"S4.p2.4.m4.3.4.2\">𝑖</ci><list id=\"S4.p2.4.m4.3.4.3.1.cmml\" xref=\"S4.p2.4.m4.3.4.3.2\"><cn type=\"integer\" id=\"S4.p2.4.m4.1.1.cmml\" xref=\"S4.p2.4.m4.1.1\">1</cn><ci id=\"S4.p2.4.m4.2.2.cmml\" xref=\"S4.p2.4.m4.2.2\">…</ci><ci id=\"S4.p2.4.m4.3.3.cmml\" xref=\"S4.p2.4.m4.3.3\">𝑛</ci></list></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.4.m4.3c\">i=1,\\ldots,n</annotation></semantics></math>) are normalized positive linear mappings from <math id=\"S4.p2.5.m5.1\" class=\"ltx_Math\" alttext=\"\\mathbb{B}\\left(\\mathcal{H}\\right)\" display=\"inline\"><semantics id=\"S4.p2.5.m5.1a\"><mrow id=\"S4.p2.5.m5.1.2\" xref=\"S4.p2.5.m5.1.2.cmml\"><mi id=\"S4.p2.5.m5.1.2.2\" xref=\"S4.p2.5.m5.1.2.2.cmml\">𝔹</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.p2.5.m5.1.2.1\" xref=\"S4.p2.5.m5.1.2.1.cmml\">​</mo><mrow id=\"S4.p2.5.m5.1.2.3.2\" xref=\"S4.p2.5.m5.1.2.cmml\"><mo id=\"S4.p2.5.m5.1.2.3.2.1\" xref=\"S4.p2.5.m5.1.2.cmml\">(</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.p2.5.m5.1.1\" xref=\"S4.p2.5.m5.1.1.cmml\">ℋ</mi><mo id=\"S4.p2.5.m5.1.2.3.2.2\" xref=\"S4.p2.5.m5.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.5.m5.1b\"><apply id=\"S4.p2.5.m5.1.2.cmml\" xref=\"S4.p2.5.m5.1.2\"><times id=\"S4.p2.5.m5.1.2.1.cmml\" xref=\"S4.p2.5.m5.1.2.1\"></times><ci id=\"S4.p2.5.m5.1.2.2.cmml\" xref=\"S4.p2.5.m5.1.2.2\">𝔹</ci><ci id=\"S4.p2.5.m5.1.1.cmml\" xref=\"S4.p2.5.m5.1.1\">ℋ</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.5.m5.1c\">\\mathbb{B}\\left(\\mathcal{H}\\right)</annotation></semantics></math> to <math id=\"S4.p2.6.m6.1\" class=\"ltx_Math\" alttext=\"\\mathbb{B}\\left(\\mathcal{K}\\right)\" display=\"inline\"><semantics id=\"S4.p2.6.m6.1a\"><mrow id=\"S4.p2.6.m6.1.2\" xref=\"S4.p2.6.m6.1.2.cmml\"><mi id=\"S4.p2.6.m6.1.2.2\" xref=\"S4.p2.6.m6.1.2.2.cmml\">𝔹</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.p2.6.m6.1.2.1\" xref=\"S4.p2.6.m6.1.2.1.cmml\">​</mo><mrow id=\"S4.p2.6.m6.1.2.3.2\" xref=\"S4.p2.6.m6.1.2.cmml\"><mo id=\"S4.p2.6.m6.1.2.3.2.1\" xref=\"S4.p2.6.m6.1.2.cmml\">(</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.p2.6.m6.1.1\" xref=\"S4.p2.6.m6.1.1.cmml\">𝒦</mi><mo id=\"S4.p2.6.m6.1.2.3.2.2\" xref=\"S4.p2.6.m6.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.6.m6.1b\"><apply id=\"S4.p2.6.m6.1.2.cmml\" xref=\"S4.p2.6.m6.1.2\"><times id=\"S4.p2.6.m6.1.2.1.cmml\" xref=\"S4.p2.6.m6.1.2.1\"></times><ci id=\"S4.p2.6.m6.1.2.2.cmml\" xref=\"S4.p2.6.m6.1.2.2\">𝔹</ci><ci id=\"S4.p2.6.m6.1.1.cmml\" xref=\"S4.p2.6.m6.1.1\">𝒦</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.6.m6.1c\">\\mathbb{B}\\left(\\mathcal{K}\\right)</annotation></semantics></math>, <math id=\"S4.p2.7.m7.3\" class=\"ltx_Math\" alttext=\"{{A}_{1}},\\ldots,{{A}_{n}}\" display=\"inline\"><semantics id=\"S4.p2.7.m7.3a\"><mrow id=\"S4.p2.7.m7.3.3.2\" xref=\"S4.p2.7.m7.3.3.3.cmml\"><msub id=\"S4.p2.7.m7.2.2.1.1\" xref=\"S4.p2.7.m7.2.2.1.1.cmml\"><mi id=\"S4.p2.7.m7.2.2.1.1.2\" xref=\"S4.p2.7.m7.2.2.1.1.2.cmml\">A</mi><mn id=\"S4.p2.7.m7.2.2.1.1.3\" xref=\"S4.p2.7.m7.2.2.1.1.3.cmml\">1</mn></msub><mo id=\"S4.p2.7.m7.3.3.2.3\" xref=\"S4.p2.7.m7.3.3.3.cmml\">,</mo><mi mathvariant=\"normal\" id=\"S4.p2.7.m7.1.1\" xref=\"S4.p2.7.m7.1.1.cmml\">…</mi><mo id=\"S4.p2.7.m7.3.3.2.4\" xref=\"S4.p2.7.m7.3.3.3.cmml\">,</mo><msub id=\"S4.p2.7.m7.3.3.2.2\" xref=\"S4.p2.7.m7.3.3.2.2.cmml\"><mi id=\"S4.p2.7.m7.3.3.2.2.2\" xref=\"S4.p2.7.m7.3.3.2.2.2.cmml\">A</mi><mi id=\"S4.p2.7.m7.3.3.2.2.3\" xref=\"S4.p2.7.m7.3.3.2.2.3.cmml\">n</mi></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.7.m7.3b\"><list id=\"S4.p2.7.m7.3.3.3.cmml\" xref=\"S4.p2.7.m7.3.3.2\"><apply id=\"S4.p2.7.m7.2.2.1.1.cmml\" xref=\"S4.p2.7.m7.2.2.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.p2.7.m7.2.2.1.1.1.cmml\" xref=\"S4.p2.7.m7.2.2.1.1\">subscript</csymbol><ci id=\"S4.p2.7.m7.2.2.1.1.2.cmml\" xref=\"S4.p2.7.m7.2.2.1.1.2\">𝐴</ci><cn type=\"integer\" id=\"S4.p2.7.m7.2.2.1.1.3.cmml\" xref=\"S4.p2.7.m7.2.2.1.1.3\">1</cn></apply><ci id=\"S4.p2.7.m7.1.1.cmml\" xref=\"S4.p2.7.m7.1.1\">…</ci><apply id=\"S4.p2.7.m7.3.3.2.2.cmml\" xref=\"S4.p2.7.m7.3.3.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.p2.7.m7.3.3.2.2.1.cmml\" xref=\"S4.p2.7.m7.3.3.2.2\">subscript</csymbol><ci id=\"S4.p2.7.m7.3.3.2.2.2.cmml\" xref=\"S4.p2.7.m7.3.3.2.2.2\">𝐴</ci><ci id=\"S4.p2.7.m7.3.3.2.2.3.cmml\" xref=\"S4.p2.7.m7.3.3.2.2.3\">𝑛</ci></apply></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.7.m7.3c\">{{A}_{1}},\\ldots,{{A}_{n}}</annotation></semantics></math> are self-adjoint operators with spectra in <math id=\"S4.p2.8.m8.1\" class=\"ltx_Math\" alttext=\"I\" display=\"inline\"><semantics id=\"S4.p2.8.m8.1a\"><mi id=\"S4.p2.8.m8.1.1\" xref=\"S4.p2.8.m8.1.1.cmml\">I</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.8.m8.1b\"><ci id=\"S4.p2.8.m8.1.1.cmml\" xref=\"S4.p2.8.m8.1.1\">𝐼</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.8.m8.1c\">I</annotation></semantics></math> and <math id=\"S4.p2.9.m9.3\" class=\"ltx_Math\" alttext=\"{{w}_{1}},\\ldots,{{w}_{n}}\" display=\"inline\"><semantics id=\"S4.p2.9.m9.3a\"><mrow id=\"S4.p2.9.m9.3.3.2\" xref=\"S4.p2.9.m9.3.3.3.cmml\"><msub id=\"S4.p2.9.m9.2.2.1.1\" xref=\"S4.p2.9.m9.2.2.1.1.cmml\"><mi id=\"S4.p2.9.m9.2.2.1.1.2\" xref=\"S4.p2.9.m9.2.2.1.1.2.cmml\">w</mi><mn id=\"S4.p2.9.m9.2.2.1.1.3\" xref=\"S4.p2.9.m9.2.2.1.1.3.cmml\">1</mn></msub><mo id=\"S4.p2.9.m9.3.3.2.3\" xref=\"S4.p2.9.m9.3.3.3.cmml\">,</mo><mi mathvariant=\"normal\" id=\"S4.p2.9.m9.1.1\" xref=\"S4.p2.9.m9.1.1.cmml\">…</mi><mo id=\"S4.p2.9.m9.3.3.2.4\" xref=\"S4.p2.9.m9.3.3.3.cmml\">,</mo><msub id=\"S4.p2.9.m9.3.3.2.2\" xref=\"S4.p2.9.m9.3.3.2.2.cmml\"><mi id=\"S4.p2.9.m9.3.3.2.2.2\" xref=\"S4.p2.9.m9.3.3.2.2.2.cmml\">w</mi><mi id=\"S4.p2.9.m9.3.3.2.2.3\" xref=\"S4.p2.9.m9.3.3.2.2.3.cmml\">n</mi></msub></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.9.m9.3b\"><list id=\"S4.p2.9.m9.3.3.3.cmml\" xref=\"S4.p2.9.m9.3.3.2\"><apply id=\"S4.p2.9.m9.2.2.1.1.cmml\" xref=\"S4.p2.9.m9.2.2.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.p2.9.m9.2.2.1.1.1.cmml\" xref=\"S4.p2.9.m9.2.2.1.1\">subscript</csymbol><ci id=\"S4.p2.9.m9.2.2.1.1.2.cmml\" xref=\"S4.p2.9.m9.2.2.1.1.2\">𝑤</ci><cn type=\"integer\" id=\"S4.p2.9.m9.2.2.1.1.3.cmml\" xref=\"S4.p2.9.m9.2.2.1.1.3\">1</cn></apply><ci id=\"S4.p2.9.m9.1.1.cmml\" xref=\"S4.p2.9.m9.1.1\">…</ci><apply id=\"S4.p2.9.m9.3.3.2.2.cmml\" xref=\"S4.p2.9.m9.3.3.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.p2.9.m9.3.3.2.2.1.cmml\" xref=\"S4.p2.9.m9.3.3.2.2\">subscript</csymbol><ci id=\"S4.p2.9.m9.3.3.2.2.2.cmml\" xref=\"S4.p2.9.m9.3.3.2.2.2\">𝑤</ci><ci id=\"S4.p2.9.m9.3.3.2.2.3.cmml\" xref=\"S4.p2.9.m9.3.3.2.2.3\">𝑛</ci></apply></list></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.9.m9.3c\">{{w}_{1}},\\ldots,{{w}_{n}}</annotation></semantics></math> are non-negative real numbers with <math id=\"S4.p2.10.m10.1\" class=\"ltx_Math\" alttext=\"\\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1\" display=\"inline\"><semantics id=\"S4.p2.10.m10.1a\"><mrow id=\"S4.p2.10.m10.1.1\" xref=\"S4.p2.10.m10.1.1.cmml\"><mrow id=\"S4.p2.10.m10.1.1.2\" xref=\"S4.p2.10.m10.1.1.2.cmml\"><msubsup id=\"S4.p2.10.m10.1.1.2.1\" xref=\"S4.p2.10.m10.1.1.2.1.cmml\"><mo id=\"S4.p2.10.m10.1.1.2.1.2.2\" xref=\"S4.p2.10.m10.1.1.2.1.2.2.cmml\">∑</mo><mrow id=\"S4.p2.10.m10.1.1.2.1.2.3\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.cmml\"><mi id=\"S4.p2.10.m10.1.1.2.1.2.3.2\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.2.cmml\">i</mi><mo id=\"S4.p2.10.m10.1.1.2.1.2.3.1\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.1.cmml\">=</mo><mn id=\"S4.p2.10.m10.1.1.2.1.2.3.3\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.p2.10.m10.1.1.2.1.3\" xref=\"S4.p2.10.m10.1.1.2.1.3.cmml\">n</mi></msubsup><msub id=\"S4.p2.10.m10.1.1.2.2\" xref=\"S4.p2.10.m10.1.1.2.2.cmml\"><mi id=\"S4.p2.10.m10.1.1.2.2.2\" xref=\"S4.p2.10.m10.1.1.2.2.2.cmml\">w</mi><mi id=\"S4.p2.10.m10.1.1.2.2.3\" xref=\"S4.p2.10.m10.1.1.2.2.3.cmml\">i</mi></msub></mrow><mo id=\"S4.p2.10.m10.1.1.1\" xref=\"S4.p2.10.m10.1.1.1.cmml\">=</mo><mn id=\"S4.p2.10.m10.1.1.3\" xref=\"S4.p2.10.m10.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.p2.10.m10.1b\"><apply id=\"S4.p2.10.m10.1.1.cmml\" xref=\"S4.p2.10.m10.1.1\"><eq id=\"S4.p2.10.m10.1.1.1.cmml\" xref=\"S4.p2.10.m10.1.1.1\"></eq><apply id=\"S4.p2.10.m10.1.1.2.cmml\" xref=\"S4.p2.10.m10.1.1.2\"><apply id=\"S4.p2.10.m10.1.1.2.1.cmml\" xref=\"S4.p2.10.m10.1.1.2.1\"><csymbol cd=\"ambiguous\" id=\"S4.p2.10.m10.1.1.2.1.1.cmml\" xref=\"S4.p2.10.m10.1.1.2.1\">superscript</csymbol><apply id=\"S4.p2.10.m10.1.1.2.1.2.cmml\" xref=\"S4.p2.10.m10.1.1.2.1\"><csymbol cd=\"ambiguous\" id=\"S4.p2.10.m10.1.1.2.1.2.1.cmml\" xref=\"S4.p2.10.m10.1.1.2.1\">subscript</csymbol><sum id=\"S4.p2.10.m10.1.1.2.1.2.2.cmml\" xref=\"S4.p2.10.m10.1.1.2.1.2.2\"></sum><apply id=\"S4.p2.10.m10.1.1.2.1.2.3.cmml\" xref=\"S4.p2.10.m10.1.1.2.1.2.3\"><eq id=\"S4.p2.10.m10.1.1.2.1.2.3.1.cmml\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.1\"></eq><ci id=\"S4.p2.10.m10.1.1.2.1.2.3.2.cmml\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.p2.10.m10.1.1.2.1.2.3.3.cmml\" xref=\"S4.p2.10.m10.1.1.2.1.2.3.3\">1</cn></apply></apply><ci id=\"S4.p2.10.m10.1.1.2.1.3.cmml\" xref=\"S4.p2.10.m10.1.1.2.1.3\">𝑛</ci></apply><apply id=\"S4.p2.10.m10.1.1.2.2.cmml\" xref=\"S4.p2.10.m10.1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.p2.10.m10.1.1.2.2.1.cmml\" xref=\"S4.p2.10.m10.1.1.2.2\">subscript</csymbol><ci id=\"S4.p2.10.m10.1.1.2.2.2.cmml\" xref=\"S4.p2.10.m10.1.1.2.2.2\">𝑤</ci><ci id=\"S4.p2.10.m10.1.1.2.2.3.cmml\" xref=\"S4.p2.10.m10.1.1.2.2.3\">𝑖</ci></apply></apply><cn type=\"integer\" id=\"S4.p2.10.m10.1.1.3.cmml\" xref=\"S4.p2.10.m10.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.p2.10.m10.1c\">\\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1</annotation></semantics></math>.</p>\n",
      "</div>\n",
      "<div id=\"S4.p3\" class=\"ltx_para\">\n",
      "<p id=\"S4.p3.1\" class=\"ltx_p\">In a reverse direction to that of inequality (<a href=\"#S4.E1\" title=\"In 4. Miscellanea ‣ New Kantorovich type inequalities for negative parameters\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">4.1</span></a>) we have the following:</p>\n",
      "</div>\n",
      "<div id=\"S4.Thmtheorem1\" class=\"ltx_theorem ltx_theorem_theorem\">\n",
      "<h6 class=\"ltx_title ltx_runin ltx_title_theorem\">\n",
      "<span class=\"ltx_tag ltx_tag_theorem\"><span id=\"S4.Thmtheorem1.1.1.1\" class=\"ltx_text ltx_font_bold\">Theorem 4.1</span></span><span id=\"S4.Thmtheorem1.2.2\" class=\"ltx_text ltx_font_bold\">.</span>\n",
      "</h6>\n",
      "<div id=\"S4.Thmtheorem1.p1\" class=\"ltx_para\">\n",
      "<p id=\"S4.Thmtheorem1.p1.12\" class=\"ltx_p\"><span id=\"S4.Thmtheorem1.p1.12.12\" class=\"ltx_text ltx_font_italic\">Let <math id=\"S4.Thmtheorem1.p1.1.1.m1.1\" class=\"ltx_Math\" alttext=\"{{\\Phi}_{i}}\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.1.1.m1.1a\"><msub id=\"S4.Thmtheorem1.p1.1.1.m1.1.1\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1.cmml\"><mi mathvariant=\"normal\" id=\"S4.Thmtheorem1.p1.1.1.m1.1.1.2\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1.2.cmml\">Φ</mi><mi id=\"S4.Thmtheorem1.p1.1.1.m1.1.1.3\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.1.1.m1.1b\"><apply id=\"S4.Thmtheorem1.p1.1.1.m1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.1.1.m1.1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.Thmtheorem1.p1.1.1.m1.1.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1.2\">Φ</ci><ci id=\"S4.Thmtheorem1.p1.1.1.m1.1.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.1.1.m1.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.1.1.m1.1c\">{{\\Phi}_{i}}</annotation></semantics></math> be normalized positive linear maps from <math id=\"S4.Thmtheorem1.p1.2.2.m2.1\" class=\"ltx_Math\" alttext=\"\\mathbb{B}\\left(\\mathcal{H}\\right)\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.2.2.m2.1a\"><mrow id=\"S4.Thmtheorem1.p1.2.2.m2.1.2\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.cmml\"><mi id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.2\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.2.cmml\">𝔹</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.1\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.1.cmml\">​</mo><mrow id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.3.2\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.cmml\"><mo id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.3.2.1\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.cmml\">(</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Thmtheorem1.p1.2.2.m2.1.1\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.1.cmml\">ℋ</mi><mo id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.3.2.2\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.2.2.m2.1b\"><apply id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2\"><times id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.1\"></times><ci id=\"S4.Thmtheorem1.p1.2.2.m2.1.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.2.2\">𝔹</ci><ci id=\"S4.Thmtheorem1.p1.2.2.m2.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.2.2.m2.1.1\">ℋ</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.2.2.m2.1c\">\\mathbb{B}\\left(\\mathcal{H}\\right)</annotation></semantics></math> to <math id=\"S4.Thmtheorem1.p1.3.3.m3.1\" class=\"ltx_Math\" alttext=\"\\mathbb{B}\\left(\\mathcal{K}\\right)\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.3.3.m3.1a\"><mrow id=\"S4.Thmtheorem1.p1.3.3.m3.1.2\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.cmml\"><mi id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.2\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.2.cmml\">𝔹</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.1\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.1.cmml\">​</mo><mrow id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.3.2\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.cmml\"><mo id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.3.2.1\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.cmml\">(</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Thmtheorem1.p1.3.3.m3.1.1\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.1.cmml\">𝒦</mi><mo id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.3.2.2\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.cmml\">)</mo></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.3.3.m3.1b\"><apply id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2\"><times id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.1\"></times><ci id=\"S4.Thmtheorem1.p1.3.3.m3.1.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.2.2\">𝔹</ci><ci id=\"S4.Thmtheorem1.p1.3.3.m3.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.3.3.m3.1.1\">𝒦</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.3.3.m3.1c\">\\mathbb{B}\\left(\\mathcal{K}\\right)</annotation></semantics></math>, <math id=\"S4.Thmtheorem1.p1.4.4.m4.1\" class=\"ltx_Math\" alttext=\"{{A}_{i}}\\in\\mathbb{B}\\left(\\mathcal{H}\\right)\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.4.4.m4.1a\"><mrow id=\"S4.Thmtheorem1.p1.4.4.m4.1.2\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.cmml\"><msub id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.cmml\"><mi id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.2\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.2.cmml\">A</mi><mi id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.3\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.3.cmml\">i</mi></msub><mo id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.1\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.1.cmml\">∈</mo><mrow id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.cmml\"><mi id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.2\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.2.cmml\">𝔹</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.1\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.1.cmml\">​</mo><mrow id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.3.2\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.cmml\"><mo id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.3.2.1\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.cmml\">(</mo><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Thmtheorem1.p1.4.4.m4.1.1\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.1.cmml\">ℋ</mi><mo id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.3.2.2\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.4.4.m4.1b\"><apply id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2\"><in id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.1\"></in><apply id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2\">subscript</csymbol><ci id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.2\">𝐴</ci><ci id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.3.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.2.3\">𝑖</ci></apply><apply id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3\"><times id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.1.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.1\"></times><ci id=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.2.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.2.3.2\">𝔹</ci><ci id=\"S4.Thmtheorem1.p1.4.4.m4.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.4.4.m4.1.1\">ℋ</ci></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.4.4.m4.1c\">{{A}_{i}}\\in\\mathbb{B}\\left(\\mathcal{H}\\right)</annotation></semantics></math> be self-adjoint operators with <math id=\"S4.Thmtheorem1.p1.5.5.m5.1\" class=\"ltx_Math\" alttext=\"m{{\\mathbf{1}}_{\\mathcal{H}}}\\leq{{A}_{i}}\\leq M{{\\mathbf{1}}_{\\mathcal{H}}}\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.5.5.m5.1a\"><mrow id=\"S4.Thmtheorem1.p1.5.5.m5.1.1\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.cmml\"><mrow id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.cmml\"><mi id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.2\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.1\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.1.cmml\">​</mo><msub id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.cmml\"><mn id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.2\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.3\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.3.cmml\">ℋ</mi></msub></mrow><mo id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.3\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.3.cmml\">≤</mo><msub id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.cmml\"><mi id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.2\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.2.cmml\">A</mi><mi id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.3\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.3.cmml\">i</mi></msub><mo id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.5\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.5.cmml\">≤</mo><mrow id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.cmml\"><mi id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.2\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.1\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.1.cmml\">​</mo><msub id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.cmml\"><mn id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.2\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.3\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.3.cmml\">ℋ</mi></msub></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.5.5.m5.1b\"><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1\"><and id=\"S4.Thmtheorem1.p1.5.5.m5.1.1a.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1\"></and><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1b.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1\"><leq id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.3\"></leq><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2\"><times id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.1\"></times><ci id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.2\">𝑚</ci><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.1.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.2.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.2\">1</cn><ci id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.3.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.2.3.3\">ℋ</ci></apply></apply><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.1.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4\">subscript</csymbol><ci id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.2.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.2\">𝐴</ci><ci id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.3.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.4.3\">𝑖</ci></apply></apply><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1c.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1\"><leq id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.5.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.5\"></leq><share href=\"#S4.Thmtheorem1.p1.5.5.m5.1.1.4.cmml\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1d.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1\"></share><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6\"><times id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.1.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.1\"></times><ci id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.2.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.2\">𝑀</ci><apply id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.1.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.2.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.2\">1</cn><ci id=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.3.cmml\" xref=\"S4.Thmtheorem1.p1.5.5.m5.1.1.6.3.3\">ℋ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.5.5.m5.1c\">m{{\\mathbf{1}}_{\\mathcal{H}}}\\leq{{A}_{i}}\\leq M{{\\mathbf{1}}_{\\mathcal{H}}}</annotation></semantics></math> for some scalars <math id=\"S4.Thmtheorem1.p1.6.6.m6.1\" class=\"ltx_Math\" alttext=\"m&lt;M\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.6.6.m6.1a\"><mrow id=\"S4.Thmtheorem1.p1.6.6.m6.1.1\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.cmml\"><mi id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.2\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.2.cmml\">m</mi><mo id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.1\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.1.cmml\">&lt;</mo><mi id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.3\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.3.cmml\">M</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.6.6.m6.1b\"><apply id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1\"><lt id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.1\"></lt><ci id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.2\">𝑚</ci><ci id=\"S4.Thmtheorem1.p1.6.6.m6.1.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.6.6.m6.1.1.3\">𝑀</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.6.6.m6.1c\">m&lt;M</annotation></semantics></math> and <math id=\"S4.Thmtheorem1.p1.7.7.m7.1\" class=\"ltx_Math\" alttext=\"{{w}_{i}}\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.7.7.m7.1a\"><msub id=\"S4.Thmtheorem1.p1.7.7.m7.1.1\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1.cmml\"><mi id=\"S4.Thmtheorem1.p1.7.7.m7.1.1.2\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1.2.cmml\">w</mi><mi id=\"S4.Thmtheorem1.p1.7.7.m7.1.1.3\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.7.7.m7.1b\"><apply id=\"S4.Thmtheorem1.p1.7.7.m7.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.7.7.m7.1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1\">subscript</csymbol><ci id=\"S4.Thmtheorem1.p1.7.7.m7.1.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1.2\">𝑤</ci><ci id=\"S4.Thmtheorem1.p1.7.7.m7.1.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.7.7.m7.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.7.7.m7.1c\">{{w}_{i}}</annotation></semantics></math> be positive numbers such that <math id=\"S4.Thmtheorem1.p1.8.8.m8.1\" class=\"ltx_Math\" alttext=\"\\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.8.8.m8.1a\"><mrow id=\"S4.Thmtheorem1.p1.8.8.m8.1.1\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.cmml\"><mrow id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.cmml\"><msubsup id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.cmml\"><mo id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.2\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.2.cmml\">∑</mo><mrow id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.cmml\"><mi id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.2\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.2.cmml\">i</mi><mo id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.1\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.1.cmml\">=</mo><mn id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.3\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.3\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.3.cmml\">n</mi></msubsup><msub id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.cmml\"><mi id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.2\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.2.cmml\">w</mi><mi id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.3\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.3.cmml\">i</mi></msub></mrow><mo id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.1\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.1.cmml\">=</mo><mn id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.3\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.3.cmml\">1</mn></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.8.8.m8.1b\"><apply id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1\"><eq id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.1\"></eq><apply id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2\"><apply id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1\">superscript</csymbol><apply id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1\">subscript</csymbol><sum id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.2\"></sum><apply id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3\"><eq id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.1\"></eq><ci id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.2.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.3.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.2.3.3\">1</cn></apply></apply><ci id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.1.3\">𝑛</ci></apply><apply id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.1.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2\">subscript</csymbol><ci id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.2\">𝑤</ci><ci id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.3.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.2.2.3\">𝑖</ci></apply></apply><cn type=\"integer\" id=\"S4.Thmtheorem1.p1.8.8.m8.1.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.8.8.m8.1.1.3\">1</cn></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.8.8.m8.1c\">\\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1</annotation></semantics></math>. If <math id=\"S4.Thmtheorem1.p1.9.9.m9.1\" class=\"ltx_Math\" alttext=\"f\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.9.9.m9.1a\"><mi id=\"S4.Thmtheorem1.p1.9.9.m9.1.1\" xref=\"S4.Thmtheorem1.p1.9.9.m9.1.1.cmml\">f</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.9.9.m9.1b\"><ci id=\"S4.Thmtheorem1.p1.9.9.m9.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.9.9.m9.1.1\">𝑓</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.9.9.m9.1c\">f</annotation></semantics></math> is a log-convex function and <math id=\"S4.Thmtheorem1.p1.10.10.m10.1\" class=\"ltx_Math\" alttext=\"g\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.10.10.m10.1a\"><mi id=\"S4.Thmtheorem1.p1.10.10.m10.1.1\" xref=\"S4.Thmtheorem1.p1.10.10.m10.1.1.cmml\">g</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.10.10.m10.1b\"><ci id=\"S4.Thmtheorem1.p1.10.10.m10.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.10.10.m10.1.1\">𝑔</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.10.10.m10.1c\">g</annotation></semantics></math> is a continuous function on <math id=\"S4.Thmtheorem1.p1.11.11.m11.2\" class=\"ltx_Math\" alttext=\"\\left[m,M\\right]\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.11.11.m11.2a\"><mrow id=\"S4.Thmtheorem1.p1.11.11.m11.2.3.2\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.3.1.cmml\"><mo id=\"S4.Thmtheorem1.p1.11.11.m11.2.3.2.1\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.3.1.cmml\">[</mo><mi id=\"S4.Thmtheorem1.p1.11.11.m11.1.1\" xref=\"S4.Thmtheorem1.p1.11.11.m11.1.1.cmml\">m</mi><mo id=\"S4.Thmtheorem1.p1.11.11.m11.2.3.2.2\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.3.1.cmml\">,</mo><mi id=\"S4.Thmtheorem1.p1.11.11.m11.2.2\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.2.cmml\">M</mi><mo id=\"S4.Thmtheorem1.p1.11.11.m11.2.3.2.3\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.3.1.cmml\">]</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.11.11.m11.2b\"><interval closure=\"closed\" id=\"S4.Thmtheorem1.p1.11.11.m11.2.3.1.cmml\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.3.2\"><ci id=\"S4.Thmtheorem1.p1.11.11.m11.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.11.11.m11.1.1\">𝑚</ci><ci id=\"S4.Thmtheorem1.p1.11.11.m11.2.2.cmml\" xref=\"S4.Thmtheorem1.p1.11.11.m11.2.2\">𝑀</ci></interval></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.11.11.m11.2c\">\\left[m,M\\right]</annotation></semantics></math>, then for a given <math id=\"S4.Thmtheorem1.p1.12.12.m12.1\" class=\"ltx_Math\" alttext=\"\\alpha\\in\\mathbb{R}\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.12.12.m12.1a\"><mrow id=\"S4.Thmtheorem1.p1.12.12.m12.1.1\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.cmml\"><mi id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.2\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.2.cmml\">α</mi><mo id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.1\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.1.cmml\">∈</mo><mi id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.3\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.3.cmml\">ℝ</mi></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.12.12.m12.1b\"><apply id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1\"><in id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.1\"></in><ci id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.2.cmml\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.2\">𝛼</ci><ci id=\"S4.Thmtheorem1.p1.12.12.m12.1.1.3.cmml\" xref=\"S4.Thmtheorem1.p1.12.12.m12.1.1.3\">ℝ</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.12.12.m12.1c\">\\alpha\\in\\mathbb{R}</annotation></semantics></math></span></p>\n",
      "<table id=\"S4.E2\" class=\"ltx_equationgroup ltx_eqn_table\">\n",
      "<tbody>\n",
      "<tr id=\"S4.E2X\" class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td rowspan=\"2\" class=\"ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left\"><span class=\"ltx_tag ltx_tag_equationgroup ltx_align_left\">(4.2)</span></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math id=\"S4.E2X.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)}\" display=\"inline\"><semantics id=\"S4.E2X.2.1.1.m1.1a\"><mrow id=\"S4.E2X.2.1.1.m1.1.1\" xref=\"S4.E2X.2.1.1.m1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.E2X.2.1.1.m1.1.1.2\" xref=\"S4.E2X.2.1.1.m1.1.1.2.cmml\"><munderover id=\"S4.E2X.2.1.1.m1.1.1.2a\" xref=\"S4.E2X.2.1.1.m1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.E2X.2.1.1.m1.1.1.2.2.2\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.E2X.2.1.1.m1.1.1.2.2.3\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.cmml\"><mi id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.2\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.1\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.3\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.E2X.2.1.1.m1.1.1.2.3\" xref=\"S4.E2X.2.1.1.m1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.E2X.2.1.1.m1.1.1.1\" xref=\"S4.E2X.2.1.1.m1.1.1.1.cmml\"><msub id=\"S4.E2X.2.1.1.m1.1.1.1.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3.cmml\"><mi id=\"S4.E2X.2.1.1.m1.1.1.1.3.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.E2X.2.1.1.m1.1.1.1.3.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.2.1.1.m1.1.1.1.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.2.cmml\">​</mo><msub id=\"S4.E2X.2.1.1.m1.1.1.1.4\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.E2X.2.1.1.m1.1.1.1.4.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.E2X.2.1.1.m1.1.1.1.4.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.2.1.1.m1.1.1.1.2a\" xref=\"S4.E2X.2.1.1.m1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.E2X.2.1.1.m1.1.1.1.1.1\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.cmml\"><mo id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.cmml\"><mi id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.3.cmml\">f</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.3\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.E2X.2.1.1.m1.1b\"><apply id=\"S4.E2X.2.1.1.m1.1.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1\"><apply id=\"S4.E2X.2.1.1.m1.1.1.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.2.1.1.m1.1.1.2.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2\">superscript</csymbol><apply id=\"S4.E2X.2.1.1.m1.1.1.2.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.2.1.1.m1.1.1.2.2.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2\">subscript</csymbol><sum id=\"S4.E2X.2.1.1.m1.1.1.2.2.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.2\"></sum><apply id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3\"><eq id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.1\"></eq><ci id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.E2X.2.1.1.m1.1.1.2.2.3.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.E2X.2.1.1.m1.1.1.2.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.E2X.2.1.1.m1.1.1.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1\"><times id=\"S4.E2X.2.1.1.m1.1.1.1.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.2\"></times><apply id=\"S4.E2X.2.1.1.m1.1.1.1.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.2.1.1.m1.1.1.1.3.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3\">subscript</csymbol><ci id=\"S4.E2X.2.1.1.m1.1.1.1.3.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.E2X.2.1.1.m1.1.1.1.3.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.E2X.2.1.1.m1.1.1.1.4.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.2.1.1.m1.1.1.1.4.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4\">subscript</csymbol><ci id=\"S4.E2X.2.1.1.m1.1.1.1.4.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4.2\">Φ</ci><ci id=\"S4.E2X.2.1.1.m1.1.1.1.4.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1\"><times id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.2\"></times><ci id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.3\">𝑓</ci><apply id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.E2X.2.1.1.m1.1c\">\\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)}</annotation></semantics></math></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.E2X.3.2.2.m1.4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}\" display=\"inline\"><semantics id=\"S4.E2X.3.2.2.m1.4a\"><mrow id=\"S4.E2X.3.2.2.m1.4.4\" xref=\"S4.E2X.3.2.2.m1.4.4.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.3\" xref=\"S4.E2X.3.2.2.m1.4.4.3.cmml\"></mi><mo id=\"S4.E2X.3.2.2.m1.4.4.2\" xref=\"S4.E2X.3.2.2.m1.4.4.2.cmml\">≤</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.E2X.3.2.2.m1.4.4.1.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.cmml\"><munderover id=\"S4.E2X.3.2.2.m1.4.4.1.2a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.E2X.3.2.2.m1.4.4.1.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.cmml\"><msub id=\"S4.E2X.3.2.2.m1.4.4.1.1.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3.2.cmml\">w</mi><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.2.cmml\">​</mo><msub id=\"S4.E2X.3.2.2.m1.4.4.1.1.4\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.4.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.4.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.2a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.2.cmml\">​</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.cmml\"><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.cmml\">(</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\"><mi id=\"S4.E2X.3.2.2.m1.3.3\" xref=\"S4.E2X.3.2.2.m1.3.3.cmml\">exp</mi><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\">⁡</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\"><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\">(</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.cmml\"><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\"><mstyle displaystyle=\"true\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml\"><mfrac id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml\"><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.cmml\"><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml\">​</mo><msub id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml\"><mn id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml\">ℋ</mi></msub></mrow><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1.cmml\">−</mo><msub id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml\">A</mi><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml\">i</mi></msub></mrow><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2.cmml\">M</mi><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1.cmml\">−</mo><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3.cmml\">m</mi></mrow></mfrac></mstyle><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml\">⁡</mo><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.4.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\"><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.4.2.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\">(</mo><mi id=\"S4.E2X.3.2.2.m1.1.1\" xref=\"S4.E2X.3.2.2.m1.1.1.cmml\">m</mi><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.4.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml\">+</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\"><mstyle displaystyle=\"true\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.cmml\"><mfrac id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.cmml\"><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.cmml\"><msub id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2.cmml\">A</mi><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3.cmml\">i</mi></msub><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1.cmml\">−</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml\">​</mo><msub id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml\"><mn id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3.cmml\">ℋ</mi></msub></mrow></mrow><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2.cmml\">M</mi><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1.cmml\">−</mo><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3.cmml\">m</mi></mrow></mfrac></mstyle><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.cmml\"><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.cmml\">⁡</mo><mi id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1a\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.4.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\"><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.4.2.1\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\">(</mo><mi id=\"S4.E2X.3.2.2.m1.2.2\" xref=\"S4.E2X.3.2.2.m1.2.2.cmml\">M</mi><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.4.2.2\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.3\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.cmml\">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.E2X.3.2.2.m1.4b\"><apply id=\"S4.E2X.3.2.2.m1.4.4.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4\"><leq id=\"S4.E2X.3.2.2.m1.4.4.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.2\"></leq><csymbol cd=\"latexml\" id=\"S4.E2X.3.2.2.m1.4.4.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.3\">absent</csymbol><apply id=\"S4.E2X.3.2.2.m1.4.4.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1\"><apply id=\"S4.E2X.3.2.2.m1.4.4.1.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2\">superscript</csymbol><apply id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2\">subscript</csymbol><sum id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.2\"></sum><apply id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3\"><eq id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.1\"></eq><ci id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.E2X.3.2.2.m1.4.4.1.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.2.3\">𝑛</ci></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1\"><times id=\"S4.E2X.3.2.2.m1.4.4.1.1.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.2\"></times><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3\">subscript</csymbol><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3.2\">𝑤</ci><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.4.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.4.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4\">subscript</csymbol><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.4.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4.2\">Φ</ci><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.4.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1\"><exp id=\"S4.E2X.3.2.2.m1.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.3.3\"></exp><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1\"><plus id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1\"></plus><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2\"><times id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1\"></times><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2\"><divide id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2\"></divide><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2\"><minus id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1\"></minus><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2\"><times id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1\"></times><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2\">𝑀</ci><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2\">1</cn><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3\">ℋ</ci></apply></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3\">subscript</csymbol><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2\">𝐴</ci><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3\">𝑖</ci></apply></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3\"><minus id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1\"></minus><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2\">𝑀</ci><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3\"><ln id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1\"></ln><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2\">𝑓</ci></apply><ci id=\"S4.E2X.3.2.2.m1.1.1.cmml\" xref=\"S4.E2X.3.2.2.m1.1.1\">𝑚</ci></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3\"><times id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1\"></times><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2\"><divide id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2\"></divide><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2\"><minus id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1\"></minus><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2\">subscript</csymbol><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2\">𝐴</ci><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3\">𝑖</ci></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3\"><times id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1\"></times><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2\">𝑚</ci><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2\">1</cn><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3\">ℋ</ci></apply></apply></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3\"><minus id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1\"></minus><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2\">𝑀</ci><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3\"><ln id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1\"></ln><ci id=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2.cmml\" xref=\"S4.E2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2\">𝑓</ci></apply><ci id=\"S4.E2X.3.2.2.m1.2.2.cmml\" xref=\"S4.E2X.3.2.2.m1.2.2\">𝑀</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.E2X.3.2.2.m1.4c\">\\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr>\n",
      "<tr id=\"S4.E2Xa\" class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_eqn_cell\"></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.E2Xa.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)+\\beta{{\\mathbf{1}}_{\\mathcal{K}}},\" display=\"inline\"><semantics id=\"S4.E2Xa.2.1.1.m1.1a\"><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.cmml\"><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.cmml\"><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.3.cmml\"></mi><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.2.cmml\">≤</mo><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.cmml\"><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.cmml\"><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.3.cmml\">α</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.2.cmml\">​</mo><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.4\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.4.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.2a\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\"><munderover id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2a\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml\"><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\"><msub id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml\"><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2a\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.2.cmml\">+</mo><mrow id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.cmml\"><mi id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.2.cmml\">β</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.1\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.1.cmml\">​</mo><msub id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.cmml\"><mn id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.3\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.3.cmml\">𝒦</mi></msub></mrow></mrow></mrow><mo id=\"S4.E2Xa.2.1.1.m1.1.1.1.2\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.cmml\">,</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.E2Xa.2.1.1.m1.1b\"><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1\"><leq id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.2\"></leq><csymbol cd=\"latexml\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.3\">absent</csymbol><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1\"><plus id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.2\"></plus><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1\"><times id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.2\"></times><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.3\">𝛼</ci><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.4.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.4\">𝑔</ci><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1\"><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\">superscript</csymbol><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\">subscript</csymbol><sum id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.2\"></sum><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3\"><eq id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.1\"></eq><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\"><times id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\"></times><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3\"><times id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.1\"></times><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.2\">𝛽</ci><apply id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.1.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.2.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.2\">1</cn><ci id=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.3.cmml\" xref=\"S4.E2Xa.2.1.1.m1.1.1.1.1.1.3.3.3\">𝒦</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.E2Xa.2.1.1.m1.1c\">\\displaystyle\\leq\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)+\\beta{{\\mathbf{1}}_{\\mathcal{K}}},</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr>\n",
      "</tbody>\n",
      "</table>\n",
      "<p id=\"S4.Thmtheorem1.p1.13\" class=\"ltx_p\"><span id=\"S4.Thmtheorem1.p1.13.1\" class=\"ltx_text ltx_font_italic\">holds with <math id=\"S4.Thmtheorem1.p1.13.1.m1.1\" class=\"ltx_Math\" alttext=\"\\beta\" display=\"inline\"><semantics id=\"S4.Thmtheorem1.p1.13.1.m1.1a\"><mi id=\"S4.Thmtheorem1.p1.13.1.m1.1.1\" xref=\"S4.Thmtheorem1.p1.13.1.m1.1.1.cmml\">β</mi><annotation-xml encoding=\"MathML-Content\" id=\"S4.Thmtheorem1.p1.13.1.m1.1b\"><ci id=\"S4.Thmtheorem1.p1.13.1.m1.1.1.cmml\" xref=\"S4.Thmtheorem1.p1.13.1.m1.1.1\">𝛽</ci></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Thmtheorem1.p1.13.1.m1.1c\">\\beta</annotation></semantics></math> as in (<a href=\"#S1.E3\" title=\"In Theorem 1.2. ‣ 1. Introduction and Preliminaries ‣ New Kantorovich type inequalities for negative parameters\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">1.3</span></a>).</span></p>\n",
      "</div>\n",
      "</div>\n",
      "<div id=\"S4.1\" class=\"ltx_proof\">\n",
      "<h6 class=\"ltx_title ltx_runin ltx_font_italic ltx_title_proof\">Proof.</h6>\n",
      "<div id=\"S4.1.p1\" class=\"ltx_para\">\n",
      "<p id=\"S4.1.p1.4\" class=\"ltx_p\">Thanks to (<a href=\"#S2.E2\" title=\"In Proof. ‣ 2. Functions reversing operator order ‣ New Kantorovich type inequalities for negative parameters\" class=\"ltx_ref\"><span class=\"ltx_text ltx_ref_tag\">2.2</span></a>), we get</p>\n",
      "<table id=\"S4.Ex1\" class=\"ltx_equation ltx_eqn_table\">\n",
      "\n",
      "<tbody><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_eqn_cell ltx_align_center\"><math id=\"S4.Ex1.m1.4\" class=\"ltx_Math\" alttext=\"f\\left({{A}_{i}}\\right)\\leq\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\leq{{a}_{f}}{{A}_{i}}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{H}}}.\" display=\"block\"><semantics id=\"S4.Ex1.m1.4a\"><mrow id=\"S4.Ex1.m1.4.4.1\" xref=\"S4.Ex1.m1.4.4.1.1.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.1.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.1.3\" xref=\"S4.Ex1.m1.4.4.1.1.1.3.cmml\">f</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.1.2\" xref=\"S4.Ex1.m1.4.4.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.1.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex1.m1.4.4.1.1.1.1.1.2\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.2\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.3\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex1.m1.4.4.1.1.1.1.1.3\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex1.m1.4.4.1.1.4\" xref=\"S4.Ex1.m1.4.4.1.1.4.cmml\">≤</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.2.cmml\"><mi id=\"S4.Ex1.m1.3.3\" xref=\"S4.Ex1.m1.3.3.cmml\">exp</mi><mo id=\"S4.Ex1.m1.4.4.1.1.2.1a\" xref=\"S4.Ex1.m1.4.4.1.1.2.2.cmml\">⁡</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.2.cmml\"><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.2.cmml\">(</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.cmml\"><mfrac id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.1.cmml\">​</mo><msub id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.cmml\"><mn id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.3.cmml\">ℋ</mi></msub></mrow><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.1.cmml\">−</mo><msub id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.2.cmml\">A</mi><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.3.cmml\">i</mi></msub></mrow><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.2.cmml\">M</mi><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.1.cmml\">−</mo><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.3.cmml\">m</mi></mrow></mfrac><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3a\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.cmml\">⁡</mo><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.1a\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.4.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.cmml\"><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.4.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.cmml\">(</mo><mi id=\"S4.Ex1.m1.1.1\" xref=\"S4.Ex1.m1.1.1.cmml\">m</mi><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.4.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml\">+</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.cmml\"><mfrac id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.cmml\"><msub id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.2.cmml\">A</mi><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.3.cmml\">i</mi></msub><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.1.cmml\">−</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.1.cmml\">​</mo><msub id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.cmml\"><mn id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.3.cmml\">ℋ</mi></msub></mrow></mrow><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.2.cmml\">M</mi><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.1.cmml\">−</mo><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.3.cmml\">m</mi></mrow></mfrac><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3a\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.cmml\">⁡</mo><mi id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.1a\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.4.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.cmml\"><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.4.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.cmml\">(</mo><mi id=\"S4.Ex1.m1.2.2\" xref=\"S4.Ex1.m1.2.2.cmml\">M</mi><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.4.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex1.m1.4.4.1.1.2.1.1.3\" xref=\"S4.Ex1.m1.4.4.1.1.2.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex1.m1.4.4.1.1.5\" xref=\"S4.Ex1.m1.4.4.1.1.5.cmml\">≤</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.6\" xref=\"S4.Ex1.m1.4.4.1.1.6.cmml\"><mrow id=\"S4.Ex1.m1.4.4.1.1.6.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.cmml\"><msub id=\"S4.Ex1.m1.4.4.1.1.6.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.6.2.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2.2.cmml\">a</mi><mi id=\"S4.Ex1.m1.4.4.1.1.6.2.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.6.2.1\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.1.cmml\">​</mo><msub id=\"S4.Ex1.m1.4.4.1.1.6.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.6.2.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3.2.cmml\">A</mi><mi id=\"S4.Ex1.m1.4.4.1.1.6.2.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3.3.cmml\">i</mi></msub></mrow><mo id=\"S4.Ex1.m1.4.4.1.1.6.1\" xref=\"S4.Ex1.m1.4.4.1.1.6.1.cmml\">+</mo><mrow id=\"S4.Ex1.m1.4.4.1.1.6.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.cmml\"><msub id=\"S4.Ex1.m1.4.4.1.1.6.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2.cmml\"><mi id=\"S4.Ex1.m1.4.4.1.1.6.3.2.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2.2.cmml\">b</mi><mi id=\"S4.Ex1.m1.4.4.1.1.6.3.2.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.1.6.3.1\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.1.cmml\">​</mo><msub id=\"S4.Ex1.m1.4.4.1.1.6.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3.cmml\"><mn id=\"S4.Ex1.m1.4.4.1.1.6.3.3.2\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex1.m1.4.4.1.1.6.3.3.3\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3.3.cmml\">ℋ</mi></msub></mrow></mrow></mrow><mo lspace=\"0em\" id=\"S4.Ex1.m1.4.4.1.2\" xref=\"S4.Ex1.m1.4.4.1.1.cmml\">.</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex1.m1.4b\"><apply id=\"S4.Ex1.m1.4.4.1.1.cmml\" xref=\"S4.Ex1.m1.4.4.1\"><and id=\"S4.Ex1.m1.4.4.1.1a.cmml\" xref=\"S4.Ex1.m1.4.4.1\"></and><apply id=\"S4.Ex1.m1.4.4.1.1b.cmml\" xref=\"S4.Ex1.m1.4.4.1\"><leq id=\"S4.Ex1.m1.4.4.1.1.4.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.4\"></leq><apply id=\"S4.Ex1.m1.4.4.1.1.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1\"><times id=\"S4.Ex1.m1.4.4.1.1.1.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1.2\"></times><ci id=\"S4.Ex1.m1.4.4.1.1.1.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1.3\">𝑓</ci><apply id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.1.1.1.1.3\">𝑖</ci></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1\"><exp id=\"S4.Ex1.m1.3.3.cmml\" xref=\"S4.Ex1.m1.3.3\"></exp><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1\"><plus id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.1\"></plus><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2\"><times id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.1\"></times><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2\"><divide id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2\"></divide><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2\"><minus id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.1\"></minus><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2\"><times id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.1\"></times><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.2\">𝑀</ci><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.2\">1</cn><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.2.3.3\">ℋ</ci></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3\">subscript</csymbol><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.2\">𝐴</ci><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.2.3.3\">𝑖</ci></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3\"><minus id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.1\"></minus><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.2\">𝑀</ci><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3\"><ln id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.1\"></ln><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.2.3.2\">𝑓</ci></apply><ci id=\"S4.Ex1.m1.1.1.cmml\" xref=\"S4.Ex1.m1.1.1\">𝑚</ci></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3\"><times id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.1\"></times><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2\"><divide id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2\"></divide><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2\"><minus id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.1\"></minus><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2\">subscript</csymbol><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.2\">𝐴</ci><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.2.3\">𝑖</ci></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3\"><times id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.1\"></times><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.2\">𝑚</ci><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.2\">1</cn><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.2.3.3.3\">ℋ</ci></apply></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3\"><minus id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.1\"></minus><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.2\">𝑀</ci><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3\"><ln id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.1\"></ln><ci id=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.2.1.1.1.3.3.2\">𝑓</ci></apply><ci id=\"S4.Ex1.m1.2.2.cmml\" xref=\"S4.Ex1.m1.2.2\">𝑀</ci></apply></apply></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1c.cmml\" xref=\"S4.Ex1.m1.4.4.1\"><leq id=\"S4.Ex1.m1.4.4.1.1.5.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.5\"></leq><share href=\"#S4.Ex1.m1.4.4.1.1.2.cmml\" id=\"S4.Ex1.m1.4.4.1.1d.cmml\" xref=\"S4.Ex1.m1.4.4.1\"></share><apply id=\"S4.Ex1.m1.4.4.1.1.6.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6\"><plus id=\"S4.Ex1.m1.4.4.1.1.6.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.1\"></plus><apply id=\"S4.Ex1.m1.4.4.1.1.6.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2\"><times id=\"S4.Ex1.m1.4.4.1.1.6.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.1\"></times><apply id=\"S4.Ex1.m1.4.4.1.1.6.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.6.2.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2\">subscript</csymbol><ci id=\"S4.Ex1.m1.4.4.1.1.6.2.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2.2\">𝑎</ci><ci id=\"S4.Ex1.m1.4.4.1.1.6.2.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.2.3\">𝑓</ci></apply><apply id=\"S4.Ex1.m1.4.4.1.1.6.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.6.2.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3\">subscript</csymbol><ci id=\"S4.Ex1.m1.4.4.1.1.6.2.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3.2\">𝐴</ci><ci id=\"S4.Ex1.m1.4.4.1.1.6.2.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.2.3.3\">𝑖</ci></apply></apply><apply id=\"S4.Ex1.m1.4.4.1.1.6.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3\"><times id=\"S4.Ex1.m1.4.4.1.1.6.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.1\"></times><apply id=\"S4.Ex1.m1.4.4.1.1.6.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.6.3.2.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2\">subscript</csymbol><ci id=\"S4.Ex1.m1.4.4.1.1.6.3.2.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2.2\">𝑏</ci><ci id=\"S4.Ex1.m1.4.4.1.1.6.3.2.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.2.3\">𝑓</ci></apply><apply id=\"S4.Ex1.m1.4.4.1.1.6.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex1.m1.4.4.1.1.6.3.3.1.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex1.m1.4.4.1.1.6.3.3.2.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3.2\">1</cn><ci id=\"S4.Ex1.m1.4.4.1.1.6.3.3.3.cmml\" xref=\"S4.Ex1.m1.4.4.1.1.6.3.3.3\">ℋ</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex1.m1.4c\">f\\left({{A}_{i}}\\right)\\leq\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\leq{{a}_{f}}{{A}_{i}}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{H}}}.</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "</table>\n",
      "<p id=\"S4.1.p1.2\" class=\"ltx_p\">The hypotheses on <math id=\"S4.1.p1.1.m1.1\" class=\"ltx_Math\" alttext=\"{{\\Phi}_{i}}\" display=\"inline\"><semantics id=\"S4.1.p1.1.m1.1a\"><msub id=\"S4.1.p1.1.m1.1.1\" xref=\"S4.1.p1.1.m1.1.1.cmml\"><mi mathvariant=\"normal\" id=\"S4.1.p1.1.m1.1.1.2\" xref=\"S4.1.p1.1.m1.1.1.2.cmml\">Φ</mi><mi id=\"S4.1.p1.1.m1.1.1.3\" xref=\"S4.1.p1.1.m1.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.1.p1.1.m1.1b\"><apply id=\"S4.1.p1.1.m1.1.1.cmml\" xref=\"S4.1.p1.1.m1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.1.m1.1.1.1.cmml\" xref=\"S4.1.p1.1.m1.1.1\">subscript</csymbol><ci id=\"S4.1.p1.1.m1.1.1.2.cmml\" xref=\"S4.1.p1.1.m1.1.1.2\">Φ</ci><ci id=\"S4.1.p1.1.m1.1.1.3.cmml\" xref=\"S4.1.p1.1.m1.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.1.p1.1.m1.1c\">{{\\Phi}_{i}}</annotation></semantics></math> and <math id=\"S4.1.p1.2.m2.1\" class=\"ltx_Math\" alttext=\"{{w}_{i}}\" display=\"inline\"><semantics id=\"S4.1.p1.2.m2.1a\"><msub id=\"S4.1.p1.2.m2.1.1\" xref=\"S4.1.p1.2.m2.1.1.cmml\"><mi id=\"S4.1.p1.2.m2.1.1.2\" xref=\"S4.1.p1.2.m2.1.1.2.cmml\">w</mi><mi id=\"S4.1.p1.2.m2.1.1.3\" xref=\"S4.1.p1.2.m2.1.1.3.cmml\">i</mi></msub><annotation-xml encoding=\"MathML-Content\" id=\"S4.1.p1.2.m2.1b\"><apply id=\"S4.1.p1.2.m2.1.1.cmml\" xref=\"S4.1.p1.2.m2.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.2.m2.1.1.1.cmml\" xref=\"S4.1.p1.2.m2.1.1\">subscript</csymbol><ci id=\"S4.1.p1.2.m2.1.1.2.cmml\" xref=\"S4.1.p1.2.m2.1.1.2\">𝑤</ci><ci id=\"S4.1.p1.2.m2.1.1.3.cmml\" xref=\"S4.1.p1.2.m2.1.1.3\">𝑖</ci></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.1.p1.2.m2.1c\">{{w}_{i}}</annotation></semantics></math> ensure the following:</p>\n",
      "<table id=\"S4.Ex2\" class=\"ltx_equationgroup ltx_eqn_table\">\n",
      "\n",
      "<tbody id=\"S4.Ex2X\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_align_right ltx_eqn_cell\"><math id=\"S4.Ex2X.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)}\" display=\"inline\"><semantics id=\"S4.Ex2X.2.1.1.m1.1a\"><mrow id=\"S4.Ex2X.2.1.1.m1.1.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex2X.2.1.1.m1.1.1.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.cmml\"><munderover id=\"S4.Ex2X.2.1.1.m1.1.1.2a\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex2X.2.1.1.m1.1.1.2.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex2X.2.1.1.m1.1.1.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.cmml\"><msub id=\"S4.Ex2X.2.1.1.m1.1.1.1.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3.cmml\"><mi id=\"S4.Ex2X.2.1.1.m1.1.1.1.3.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex2X.2.1.1.m1.1.1.1.3.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex2X.2.1.1.m1.1.1.1.4\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.4.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex2X.2.1.1.m1.1.1.1.4.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.2a\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.3.cmml\">f</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.3\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex2X.2.1.1.m1.1b\"><apply id=\"S4.Ex2X.2.1.1.m1.1.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1\"><apply id=\"S4.Ex2X.2.1.1.m1.1.1.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.2.1.1.m1.1.1.2.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.2\"></sum><apply id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3\"><eq id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex2X.2.1.1.m1.1.1.2.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex2X.2.1.1.m1.1.1.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1\"><times id=\"S4.Ex2X.2.1.1.m1.1.1.1.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.2\"></times><apply id=\"S4.Ex2X.2.1.1.m1.1.1.1.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.3.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.3.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.3.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex2X.2.1.1.m1.1.1.1.4.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.4.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.4.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.4.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1\"><times id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.2\"></times><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.3\">𝑓</ci><apply id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex2X.2.1.1.m1.1c\">\\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)}</annotation></semantics></math></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.Ex2X.3.2.2.m1.4\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}\" display=\"inline\"><semantics id=\"S4.Ex2X.3.2.2.m1.4a\"><mrow id=\"S4.Ex2X.3.2.2.m1.4.4\" xref=\"S4.Ex2X.3.2.2.m1.4.4.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.3.cmml\"></mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.2.cmml\">≤</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.cmml\"><munderover id=\"S4.Ex2X.3.2.2.m1.4.4.1.2a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.cmml\"><msub id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.2.cmml\">​</mo><msub id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.2a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.cmml\"><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.cmml\">(</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.3.3\" xref=\"S4.Ex2X.3.2.2.m1.3.3.cmml\">exp</mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\">⁡</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\"><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\">(</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.cmml\"><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml\"><mfrac id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml\"><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.cmml\"><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml\">​</mo><msub id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml\"><mn id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml\">ℋ</mi></msub></mrow><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1.cmml\">−</mo><msub id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml\">A</mi><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml\">i</mi></msub></mrow><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2.cmml\">M</mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1.cmml\">−</mo><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3.cmml\">m</mi></mrow></mfrac></mstyle><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml\">⁡</mo><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.4.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\"><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.4.2.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\">(</mo><mi id=\"S4.Ex2X.3.2.2.m1.1.1\" xref=\"S4.Ex2X.3.2.2.m1.1.1.cmml\">m</mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.4.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml\">+</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.cmml\"><mfrac id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.cmml\"><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.cmml\"><msub id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2.cmml\">A</mi><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3.cmml\">i</mi></msub><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1.cmml\">−</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml\">​</mo><msub id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml\"><mn id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3.cmml\">ℋ</mi></msub></mrow></mrow><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2.cmml\">M</mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1.cmml\">−</mo><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3.cmml\">m</mi></mrow></mfrac></mstyle><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.cmml\"><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.cmml\">⁡</mo><mi id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1a\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.4.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\"><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.4.2.1\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\">(</mo><mi id=\"S4.Ex2X.3.2.2.m1.2.2\" xref=\"S4.Ex2X.3.2.2.m1.2.2.cmml\">M</mi><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.4.2.2\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.3\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.cmml\">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex2X.3.2.2.m1.4b\"><apply id=\"S4.Ex2X.3.2.2.m1.4.4.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4\"><leq id=\"S4.Ex2X.3.2.2.m1.4.4.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.2\"></leq><csymbol cd=\"latexml\" id=\"S4.Ex2X.3.2.2.m1.4.4.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.3\">absent</csymbol><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1\"><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2\">superscript</csymbol><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2\">subscript</csymbol><sum id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.2\"></sum><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3\"><eq id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.1\"></eq><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1\"><times id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.2\"></times><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3\">subscript</csymbol><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4\">subscript</csymbol><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.2\">Φ</ci><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1\"><exp id=\"S4.Ex2X.3.2.2.m1.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.3.3\"></exp><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1\"><plus id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.1\"></plus><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2\"><times id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.1\"></times><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2\"><divide id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2\"></divide><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2\"><minus id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.1\"></minus><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2\"><times id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.1\"></times><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.2\">𝑀</ci><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.2\">1</cn><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.2.3.3\">ℋ</ci></apply></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3\">subscript</csymbol><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.2\">𝐴</ci><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.2.3.3\">𝑖</ci></apply></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3\"><minus id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.1\"></minus><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.2\">𝑀</ci><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3\"><ln id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.1\"></ln><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.2.3.2\">𝑓</ci></apply><ci id=\"S4.Ex2X.3.2.2.m1.1.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.1.1\">𝑚</ci></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3\"><times id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.1\"></times><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2\"><divide id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2\"></divide><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2\"><minus id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.1\"></minus><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2\">subscript</csymbol><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.2\">𝐴</ci><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.2.3\">𝑖</ci></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3\"><times id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.1\"></times><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.2\">𝑚</ci><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.2\">1</cn><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.2.3.3.3\">ℋ</ci></apply></apply></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3\"><minus id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.1\"></minus><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.2\">𝑀</ci><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3\"><ln id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.1\"></ln><ci id=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.4.4.1.1.1.1.1.1.1.1.3.3.2\">𝑓</ci></apply><ci id=\"S4.Ex2X.3.2.2.m1.2.2.cmml\" xref=\"S4.Ex2X.3.2.2.m1.2.2\">𝑀</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex2X.3.2.2.m1.4c\">\\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "<tbody id=\"S4.Ex2Xa\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_eqn_cell\"></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.Ex2Xa.2.1.1.m1.1\" class=\"ltx_Math\" alttext=\"\\displaystyle\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}.\" display=\"inline\"><semantics id=\"S4.Ex2Xa.2.1.1.m1.1a\"><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.cmml\"><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.cmml\"><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.3.cmml\"></mi><mo id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.2.cmml\">≤</mo><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.cmml\"><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.cmml\"><msub id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.cmml\"><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.2.cmml\">a</mi><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\"><munderover id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2a\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml\"><msub id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml\"><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2a\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow></mrow><mo id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.2.cmml\">+</mo><mrow id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.cmml\"><msub id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.cmml\"><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.2.cmml\">b</mi><mi id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.1\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.1.cmml\">​</mo><msub id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.cmml\"><mn id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.3\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.3.cmml\">𝒦</mi></msub></mrow></mrow></mrow><mo lspace=\"0em\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.2\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.cmml\">.</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex2Xa.2.1.1.m1.1b\"><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1\"><leq id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.2\"></leq><csymbol cd=\"latexml\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.3\">absent</csymbol><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1\"><plus id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.2\"></plus><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1\"><times id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.2\"></times><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.2\">𝑎</ci><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.3.3\">𝑓</ci></apply><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1\"><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.2\"></sum><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3\"><eq id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1\"><times id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.2\"></times><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3\"><times id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.1\"></times><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2\">subscript</csymbol><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.2\">𝑏</ci><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.2.3\">𝑓</ci></apply><apply id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.1.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.2.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.2\">1</cn><ci id=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.3.cmml\" xref=\"S4.Ex2Xa.2.1.1.m1.1.1.1.1.1.3.3.3\">𝒦</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex2Xa.2.1.1.m1.1c\">\\displaystyle\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}.</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "</table>\n",
      "<p id=\"S4.1.p1.3\" class=\"ltx_p\">Using the fact that <math id=\"S4.1.p1.3.m1.1\" class=\"ltx_Math\" alttext=\"m{{\\mathbf{1}}_{\\mathcal{K}}}\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\leq M{{\\mathbf{1}}_{\\mathcal{K}}}\" display=\"inline\"><semantics id=\"S4.1.p1.3.m1.1a\"><mrow id=\"S4.1.p1.3.m1.1.1\" xref=\"S4.1.p1.3.m1.1.1.cmml\"><mrow id=\"S4.1.p1.3.m1.1.1.3\" xref=\"S4.1.p1.3.m1.1.1.3.cmml\"><mi id=\"S4.1.p1.3.m1.1.1.3.2\" xref=\"S4.1.p1.3.m1.1.1.3.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.1.p1.3.m1.1.1.3.1\" xref=\"S4.1.p1.3.m1.1.1.3.1.cmml\">​</mo><msub id=\"S4.1.p1.3.m1.1.1.3.3\" xref=\"S4.1.p1.3.m1.1.1.3.3.cmml\"><mn id=\"S4.1.p1.3.m1.1.1.3.3.2\" xref=\"S4.1.p1.3.m1.1.1.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.1.p1.3.m1.1.1.3.3.3\" xref=\"S4.1.p1.3.m1.1.1.3.3.3.cmml\">𝒦</mi></msub></mrow><mo rspace=\"0.111em\" id=\"S4.1.p1.3.m1.1.1.4\" xref=\"S4.1.p1.3.m1.1.1.4.cmml\">≤</mo><mrow id=\"S4.1.p1.3.m1.1.1.1\" xref=\"S4.1.p1.3.m1.1.1.1.cmml\"><munderover id=\"S4.1.p1.3.m1.1.1.1.2\" xref=\"S4.1.p1.3.m1.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.1.p1.3.m1.1.1.1.2.2.2\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.1.p1.3.m1.1.1.1.2.2.3\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.cmml\"><mi id=\"S4.1.p1.3.m1.1.1.1.2.2.3.2\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.1.p1.3.m1.1.1.1.2.2.3.1\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.1.p1.3.m1.1.1.1.2.2.3.3\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.1.p1.3.m1.1.1.1.2.3\" xref=\"S4.1.p1.3.m1.1.1.1.2.3.cmml\">n</mi></munderover><mrow id=\"S4.1.p1.3.m1.1.1.1.1\" xref=\"S4.1.p1.3.m1.1.1.1.1.cmml\"><msub id=\"S4.1.p1.3.m1.1.1.1.1.3\" xref=\"S4.1.p1.3.m1.1.1.1.1.3.cmml\"><mi id=\"S4.1.p1.3.m1.1.1.1.1.3.2\" xref=\"S4.1.p1.3.m1.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.1.p1.3.m1.1.1.1.1.3.3\" xref=\"S4.1.p1.3.m1.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.1.p1.3.m1.1.1.1.1.2\" xref=\"S4.1.p1.3.m1.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.1.p1.3.m1.1.1.1.1.4\" xref=\"S4.1.p1.3.m1.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.1.p1.3.m1.1.1.1.1.4.2\" xref=\"S4.1.p1.3.m1.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.1.p1.3.m1.1.1.1.1.4.3\" xref=\"S4.1.p1.3.m1.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.1.p1.3.m1.1.1.1.1.2a\" xref=\"S4.1.p1.3.m1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.1.p1.3.m1.1.1.1.1.1.1\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.1.p1.3.m1.1.1.1.1.1.1.2\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.2\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.3\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.1.p1.3.m1.1.1.1.1.1.1.3\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.1.p1.3.m1.1.1.5\" xref=\"S4.1.p1.3.m1.1.1.5.cmml\">≤</mo><mrow id=\"S4.1.p1.3.m1.1.1.6\" xref=\"S4.1.p1.3.m1.1.1.6.cmml\"><mi id=\"S4.1.p1.3.m1.1.1.6.2\" xref=\"S4.1.p1.3.m1.1.1.6.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.1.p1.3.m1.1.1.6.1\" xref=\"S4.1.p1.3.m1.1.1.6.1.cmml\">​</mo><msub id=\"S4.1.p1.3.m1.1.1.6.3\" xref=\"S4.1.p1.3.m1.1.1.6.3.cmml\"><mn id=\"S4.1.p1.3.m1.1.1.6.3.2\" xref=\"S4.1.p1.3.m1.1.1.6.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.1.p1.3.m1.1.1.6.3.3\" xref=\"S4.1.p1.3.m1.1.1.6.3.3.cmml\">𝒦</mi></msub></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.1.p1.3.m1.1b\"><apply id=\"S4.1.p1.3.m1.1.1.cmml\" xref=\"S4.1.p1.3.m1.1.1\"><and id=\"S4.1.p1.3.m1.1.1a.cmml\" xref=\"S4.1.p1.3.m1.1.1\"></and><apply id=\"S4.1.p1.3.m1.1.1b.cmml\" xref=\"S4.1.p1.3.m1.1.1\"><leq id=\"S4.1.p1.3.m1.1.1.4.cmml\" xref=\"S4.1.p1.3.m1.1.1.4\"></leq><apply id=\"S4.1.p1.3.m1.1.1.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.3\"><times id=\"S4.1.p1.3.m1.1.1.3.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.3.1\"></times><ci id=\"S4.1.p1.3.m1.1.1.3.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.3.2\">𝑚</ci><apply id=\"S4.1.p1.3.m1.1.1.3.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.3.3.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.1.p1.3.m1.1.1.3.3.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.3.3.2\">1</cn><ci id=\"S4.1.p1.3.m1.1.1.3.3.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.3.3.3\">𝒦</ci></apply></apply><apply id=\"S4.1.p1.3.m1.1.1.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1\"><apply id=\"S4.1.p1.3.m1.1.1.1.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.1.2.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2\">superscript</csymbol><apply id=\"S4.1.p1.3.m1.1.1.1.2.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.1.2.2.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2\">subscript</csymbol><sum id=\"S4.1.p1.3.m1.1.1.1.2.2.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.2\"></sum><apply id=\"S4.1.p1.3.m1.1.1.1.2.2.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3\"><eq id=\"S4.1.p1.3.m1.1.1.1.2.2.3.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.1\"></eq><ci id=\"S4.1.p1.3.m1.1.1.1.2.2.3.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.1.p1.3.m1.1.1.1.2.2.3.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.1.p1.3.m1.1.1.1.2.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.1.p1.3.m1.1.1.1.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1\"><times id=\"S4.1.p1.3.m1.1.1.1.1.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.2\"></times><apply id=\"S4.1.p1.3.m1.1.1.1.1.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.1.1.3.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.1.p1.3.m1.1.1.1.1.3.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.1.p1.3.m1.1.1.1.1.3.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.1.p1.3.m1.1.1.1.1.4.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.1.1.4.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.1.p1.3.m1.1.1.1.1.4.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.1.p1.3.m1.1.1.1.1.4.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply><apply id=\"S4.1.p1.3.m1.1.1c.cmml\" xref=\"S4.1.p1.3.m1.1.1\"><leq id=\"S4.1.p1.3.m1.1.1.5.cmml\" xref=\"S4.1.p1.3.m1.1.1.5\"></leq><share href=\"#S4.1.p1.3.m1.1.1.1.cmml\" id=\"S4.1.p1.3.m1.1.1d.cmml\" xref=\"S4.1.p1.3.m1.1.1\"></share><apply id=\"S4.1.p1.3.m1.1.1.6.cmml\" xref=\"S4.1.p1.3.m1.1.1.6\"><times id=\"S4.1.p1.3.m1.1.1.6.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.6.1\"></times><ci id=\"S4.1.p1.3.m1.1.1.6.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.6.2\">𝑀</ci><apply id=\"S4.1.p1.3.m1.1.1.6.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.6.3\"><csymbol cd=\"ambiguous\" id=\"S4.1.p1.3.m1.1.1.6.3.1.cmml\" xref=\"S4.1.p1.3.m1.1.1.6.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.1.p1.3.m1.1.1.6.3.2.cmml\" xref=\"S4.1.p1.3.m1.1.1.6.3.2\">1</cn><ci id=\"S4.1.p1.3.m1.1.1.6.3.3.cmml\" xref=\"S4.1.p1.3.m1.1.1.6.3.3\">𝒦</ci></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.1.p1.3.m1.1c\">m{{\\mathbf{1}}_{\\mathcal{K}}}\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\leq M{{\\mathbf{1}}_{\\mathcal{K}}}</annotation></semantics></math>, we can write</p>\n",
      "<table id=\"S4.Ex3\" class=\"ltx_equationgroup ltx_eqn_table\">\n",
      "\n",
      "<tbody id=\"S4.Ex3X\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_eqn_cell\"></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.Ex3X.2.1.1.m1.2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)}\" display=\"inline\"><semantics id=\"S4.Ex3X.2.1.1.m1.2a\"><mrow id=\"S4.Ex3X.2.1.1.m1.2.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.cmml\"><mrow id=\"S4.Ex3X.2.1.1.m1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.cmml\"><munderover id=\"S4.Ex3X.2.1.1.m1.1.1.1.2a\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex3X.2.1.1.m1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.cmml\"><msub id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.2a\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.cmml\">(</mo><mrow id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml\">f</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3X.2.1.1.m1.2.2.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.3.cmml\">−</mo><mrow id=\"S4.Ex3X.2.1.1.m1.2.2.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.3.cmml\">α</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.2.cmml\">​</mo><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.4\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.4.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.2a\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.2.cmml\">​</mo><mrow id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.cmml\"><mo id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.cmml\">(</mo><mrow id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.cmml\"><munderover id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2a\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.1\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.cmml\"><msub id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.2a\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.3\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.cmml\">)</mo></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex3X.2.1.1.m1.2b\"><apply id=\"S4.Ex3X.2.1.1.m1.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2\"><minus id=\"S4.Ex3X.2.1.1.m1.2.2.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.3\"></minus><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1\"><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.2\"></sum><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3\"><eq id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.2.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1\"><times id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.2\"></times><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1\"><times id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.2\"></times><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.3\">𝑓</ci><apply id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2\"><times id=\"S4.Ex3X.2.1.1.m1.2.2.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.2\"></times><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.3\">𝛼</ci><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.4.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.4\">𝑔</ci><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1\"><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.2\"></sum><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3\"><eq id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1\"><times id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.2\"></times><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3X.2.1.1.m1.2.2.2.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex3X.2.1.1.m1.2c\">\\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)}</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "<tbody id=\"S4.Ex3Xa\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_eqn_cell\"></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.Ex3Xa.2.1.1.m1.5\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)\" display=\"inline\"><semantics id=\"S4.Ex3Xa.2.1.1.m1.5a\"><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.4\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.4.cmml\"></mi><mo lspace=\"1.278em\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.3.cmml\">≤</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.cmml\"><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.cmml\"><munderover id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.cmml\"><msub id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.cmml\"><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.cmml\">(</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.2.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.3.3.cmml\">exp</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.2.cmml\">⁡</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.2.cmml\"><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.2.cmml\">(</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.cmml\"><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.cmml\"><mfrac id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.cmml\"><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml\"><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml\">M</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml\">​</mo><msub id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml\"><mn id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml\">ℋ</mi></msub></mrow><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml\">−</mo><msub id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml\">A</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml\">i</mi></msub></mrow><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml\">M</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml\">−</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml\">m</mi></mrow></mfrac></mstyle><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.cmml\">⁡</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.1a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.1.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.4.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml\"><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.4.2.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml\">(</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.1.1.cmml\">m</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.4.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml\">+</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml\"><mfrac id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml\"><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.cmml\"><msub id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.2.cmml\">A</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.3.cmml\">i</mi></msub><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml\">−</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml\">m</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml\">​</mo><msub id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml\"><mn id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.3.cmml\">ℋ</mi></msub></mrow></mrow><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.2.cmml\">M</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml\">−</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.3.cmml\">m</mi></mrow></mfrac></mstyle><mo lspace=\"0.167em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.1.cmml\">ln</mi><mo lspace=\"0.167em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.cmml\">⁡</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.2.cmml\">f</mi></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.1a\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml\"><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.2.1\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml\">(</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.2.2.cmml\">M</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.2.cmml\">)</mo></mrow></mrow><mo id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.3.cmml\">−</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.3.cmml\">α</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.2.cmml\">​</mo><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.4\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.4.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.2.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.cmml\"><mo id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.cmml\">(</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.cmml\"><munderover id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.1\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.cmml\"><msub id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2a\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.3\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.cmml\">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex3Xa.2.1.1.m1.5b\"><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5\"><leq id=\"S4.Ex3Xa.2.1.1.m1.5.5.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.3\"></leq><csymbol cd=\"latexml\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.4.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.4\">absent</csymbol><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2\"><minus id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.3\"></minus><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1\"><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2\">superscript</csymbol><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2\">subscript</csymbol><sum id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.2\"></sum><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3\"><eq id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1\"><times id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.2\"></times><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1\"><exp id=\"S4.Ex3Xa.2.1.1.m1.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.3.3\"></exp><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1\"><plus id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.1\"></plus><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2\"><times id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.1\"></times><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2\"><divide id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2\"></divide><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2\"><minus id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1\"></minus><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2\"><times id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.1\"></times><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.2\">𝑀</ci><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.2\">1</cn><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.3.3\">ℋ</ci></apply></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.2\">𝐴</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.3\">𝑖</ci></apply></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3\"><minus id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.1\"></minus><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.2\">𝑀</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3\"><ln id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.1\"></ln><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.2.3.2\">𝑓</ci></apply><ci id=\"S4.Ex3Xa.2.1.1.m1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.1.1\">𝑚</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3\"><times id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.1\"></times><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2\"><divide id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2\"></divide><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2\"><minus id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.1\"></minus><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.2\">𝐴</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.2.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3\"><times id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.1\"></times><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.2\">𝑚</ci><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.2\">1</cn><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.2.3.3.3\">ℋ</ci></apply></apply></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3\"><minus id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.1\"></minus><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.2\">𝑀</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.2.3.3\">𝑚</ci></apply></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3\"><ln id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.1\"></ln><ci id=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.2\">𝑓</ci></apply><ci id=\"S4.Ex3Xa.2.1.1.m1.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.2.2\">𝑀</ci></apply></apply></apply></apply></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2\"><times id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.2\"></times><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.3\">𝛼</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.4.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.4\">𝑔</ci><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1\"><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.2\"></sum><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3\"><eq id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1\"><times id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.2\"></times><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xa.2.1.1.m1.5.5.2.2.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex3Xa.2.1.1.m1.5c\">\\displaystyle\\quad\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "<tbody id=\"S4.Ex3Xb\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_eqn_cell\"></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.Ex3Xb.2.1.1.m1.2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)\" display=\"inline\"><semantics id=\"S4.Ex3Xb.2.1.1.m1.2a\"><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.4\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.4.cmml\"></mi><mo lspace=\"1.278em\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.3.cmml\">≤</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.cmml\"><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.cmml\"><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.cmml\"><msub id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.2.cmml\">a</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.cmml\"><munderover id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2a\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.cmml\"><msub id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.2a\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow></mrow><mo id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.2.cmml\">+</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.cmml\"><msub id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.2.cmml\">b</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.1\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.1.cmml\">​</mo><msub id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.cmml\"><mn id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.3.cmml\">𝒦</mi></msub></mrow></mrow><mo id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.3.cmml\">−</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.3.cmml\">α</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.2.cmml\">​</mo><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.4\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.4.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.2a\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.2.cmml\">​</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.cmml\"><mo id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.cmml\">(</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.cmml\"><mstyle displaystyle=\"true\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.cmml\"><munderover id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2a\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.cmml\"><mo movablelimits=\"false\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.2.cmml\">∑</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.2.cmml\">i</mi><mo id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.1\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.1.cmml\">=</mo><mn id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.3.cmml\">1</mn></mrow><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.3.cmml\">n</mi></munderover></mstyle><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.cmml\"><msub id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.2.cmml\">w</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.cmml\"><mi mathvariant=\"normal\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.2.cmml\">Φ</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.3.cmml\">i</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.2a\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml\"><mo id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml\">(</mo><msub id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml\"><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml\">A</mi><mi id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml\">i</mi></msub><mo id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.3\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.cmml\">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex3Xb.2.1.1.m1.2b\"><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2\"><leq id=\"S4.Ex3Xb.2.1.1.m1.2.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.3\"></leq><csymbol cd=\"latexml\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.4.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.4\">absent</csymbol><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2\"><minus id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.3\"></minus><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1\"><plus id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.2\"></plus><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1\"><times id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.2\"></times><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.2\">𝑎</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.3.3\">𝑓</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1\"><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.2\"></sum><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3\"><eq id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1\"><times id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.2\"></times><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3\"><times id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.1\"></times><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.2\">𝑏</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.2.3\">𝑓</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3\">subscript</csymbol><cn type=\"integer\" id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.2\">1</cn><ci id=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.1.1.1.1.3.3.3\">𝒦</ci></apply></apply></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2\"><times id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.2\"></times><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.3\">𝛼</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.4.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.4\">𝑔</ci><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1\"><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2\">superscript</csymbol><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2\">subscript</csymbol><sum id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.2\"></sum><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3\"><eq id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.1\"></eq><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.2\">𝑖</ci><cn type=\"integer\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.2.3.3\">1</cn></apply></apply><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.2.3\">𝑛</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1\"><times id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.2\"></times><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.2\">𝑤</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.3.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.2\">Φ</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.4.3\">𝑖</ci></apply><apply id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1\">subscript</csymbol><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.2\">𝐴</ci><ci id=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.3.cmml\" xref=\"S4.Ex3Xb.2.1.1.m1.2.2.2.2.1.1.1.1.1.1.1.3\">𝑖</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding=\"application/x-tex\" id=\"S4.Ex3Xb.2.1.1.m1.2c\">\\displaystyle\\quad\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)</annotation></semantics></math></td>\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padright\"></td>\n",
      "</tr></tbody>\n",
      "<tbody id=\"S4.Ex3Xc\"><tr class=\"ltx_equation ltx_eqn_row ltx_align_baseline\">\n",
      "<td class=\"ltx_eqn_cell ltx_eqn_center_padleft\"></td>\n",
      "<td class=\"ltx_td ltx_eqn_cell\"></td>\n",
      "<td class=\"ltx_td ltx_align_left ltx_eqn_cell\"><math id=\"S4.Ex3Xc.2.1.1.m1.2\" class=\"ltx_Math\" alttext=\"\\displaystyle\\quad\\leq\\underset{m\\leq t\\leq M}{\\mathop{\\max}}\\,\\left\\{{{a}_{f}}t+{{b}_{f}}-\\alpha g\\left(t\\right)\\right\\}{{\\mathbf{1}}_{\\mathcal{K}}},\" display=\"inline\"><semantics id=\"S4.Ex3Xc.2.1.1.m1.2a\"><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.cmml\"><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.cmml\"><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.3.cmml\"></mi><mo lspace=\"1.278em\" rspace=\"0.1389em\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.2.cmml\">≤</mo><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.cmml\"><munder accentunder=\"true\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.cmml\"><mo lspace=\"0.1389em\" movablelimits=\"false\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.2.cmml\">max</mo><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.cmml\"><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.2.cmml\">m</mi><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.3.cmml\">≤</mo><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.4\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.4.cmml\">t</mi><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.5\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.5.cmml\">≤</mo><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.6\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.6.cmml\">M</mi></mrow></munder><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.2.cmml\">​</mo><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.2.cmml\"><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.2.cmml\">{</mo><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.cmml\"><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.cmml\"><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.cmml\"><msub id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml\"><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.2.cmml\">a</mi><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml\">f</mi></msub><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.1.cmml\">​</mo><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.3.cmml\">t</mi></mrow><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.1.cmml\">+</mo><msub id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.3.cmml\"><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.3.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.3.2.cmml\">b</mi><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.3.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.3.3.cmml\">f</mi></msub></mrow><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml\">−</mo><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml\"><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.2.cmml\">α</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.1.cmml\">​</mo><mi id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.3.cmml\">g</mi><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.1a\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.1.cmml\">​</mo><mrow id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.4.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml\"><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.4.2.1\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml\">(</mo><mi id=\"S4.Ex3Xc.2.1.1.m1.1.1\" xref=\"S4.Ex3Xc.2.1.1.m1.1.1.cmml\">t</mi><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.4.2.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.3.cmml\">)</mo></mrow></mrow></mrow><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.2.cmml\">}</mo></mrow><mo lspace=\"0em\" rspace=\"0em\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.2a\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.2.cmml\">​</mo><msub id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.4\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.4.cmml\"><mn id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.4.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.4.2.cmml\">𝟏</mn><mi class=\"ltx_font_mathcaligraphic\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.4.3\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.4.3.cmml\">𝒦</mi></msub></mrow></mrow><mo id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.2\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.cmml\">,</mo></mrow><annotation-xml encoding=\"MathML-Content\" id=\"S4.Ex3Xc.2.1.1.m1.2b\"><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1\"><leq id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.2\"></leq><csymbol cd=\"latexml\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.3.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.3\">absent</csymbol><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1\"><times id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.2\"></times><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3\"><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1\"><and id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1a.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1\"></and><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1b.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1\"><leq id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.3.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.3\"></leq><ci id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.2\">𝑚</ci><ci id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.4.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.4\">𝑡</ci></apply><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1c.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1\"><leq id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.5.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.5\"></leq><share href=\"#S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.4.cmml\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1d.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1\"></share><ci id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.6.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.1.6\">𝑀</ci></apply></apply><max id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.3.2\"></max></apply><set id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1\"><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1\"><minus id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.1\"></minus><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2\"><plus id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.1\"></plus><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2\"><times id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.1\"></times><apply id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2\"><csymbol cd=\"ambiguous\" id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.1.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2\">subscript</csymbol><ci id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.2.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.2\">𝑎</ci><ci id=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.3.cmml\" xref=\"S4.Ex3Xc.2.1.1.m1.2.2.1.1.1.1.1.1.2.2.2.3\">𝑓</ci></apply><ci id=\"S4.Ex3X\n",
      "\n",
      "文本已分成 3 块。\n",
      "分块结果:\n",
      "Chunk 1: page_content='subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 f\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)}, \n",
      " \n",
      " for operator convex function  f 𝑓 f  defined on an interval  I 𝐼 I , where  Φ i subscript Φ 𝑖 {{\\Phi}_{i}}  ( i = 1 , … , n 𝑖 1 … 𝑛 i=1,\\ldots,n ) are normalized positive linear mappings from  𝔹 ​ ( ℋ ) 𝔹 ℋ \\mathbb{B}\\left(\\mathcal{H}\\right)  to  𝔹 ​ ( 𝒦 ) 𝔹 𝒦 \\mathbb{B}\\left(\\mathcal{K}\\right) ,  A 1 , … , A n subscript 𝐴 1 … subscript 𝐴 𝑛 {{A}_{1}},\\ldots,{{A}_{n}}  are self-adjoint operators with spectra in  I 𝐼 I  and  w 1 , … , w n subscript 𝑤 1 … subscript 𝑤 𝑛 {{w}_{1}},\\ldots,{{w}_{n}}  are non-negative real numbers with  ∑ i = 1 n w i = 1 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 1 \\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1 . \n",
      " \n",
      " In a reverse direction to that of inequality ( 4.1 ) we have the following:' metadata={'Header 1': '#TITLE#'}\n",
      "Chunk 2: page_content='Theorem 4.1 . \n",
      " \n",
      " \n",
      " Let  Φ i subscript Φ 𝑖 {{\\Phi}_{i}}  be normalized positive linear maps from  𝔹 ​ ( ℋ ) 𝔹 ℋ \\mathbb{B}\\left(\\mathcal{H}\\right)  to  𝔹 ​ ( 𝒦 ) 𝔹 𝒦 \\mathbb{B}\\left(\\mathcal{K}\\right) ,  A i ∈ 𝔹 ​ ( ℋ ) subscript 𝐴 𝑖 𝔹 ℋ {{A}_{i}}\\in\\mathbb{B}\\left(\\mathcal{H}\\right)  be self-adjoint operators with  m ​ 𝟏 ℋ ≤ A i ≤ M ​ 𝟏 ℋ 𝑚 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 subscript 1 ℋ m{{\\mathbf{1}}_{\\mathcal{H}}}\\leq{{A}_{i}}\\leq M{{\\mathbf{1}}_{\\mathcal{H}}}  for some scalars  m < M 𝑚 𝑀 m<M  and  w i subscript 𝑤 𝑖 {{w}_{i}}  be positive numbers such that  ∑ i = 1 n w i = 1 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 1 \\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1 . If  f 𝑓 f  is a log-convex function and  g 𝑔 g  is a continuous function on  [ m , M ] 𝑚 𝑀 \\left[m,M\\right] , then for a given  α ∈ ℝ 𝛼 ℝ \\alpha\\in\\mathbb{R} \n",
      " \n",
      " \n",
      " \n",
      " (4.2) \n",
      " \n",
      " ∑ i = 1 n w i ​ Φ i ​ ( f ​ ( A i ) ) superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 \\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)} \n",
      " ≤ ∑ i = 1 n w i ​ Φ i ​ ( exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ) absent superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 \\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)} \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " ≤ α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) + β ​ 𝟏 𝒦 , absent 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 𝛽 subscript 1 𝒦 \\displaystyle\\leq\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)+\\beta{{\\mathbf{1}}_{\\mathcal{K}}}, \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " holds with  β 𝛽 \\beta  as in ( 1.3 ).' metadata={'Header 6': 'Theorem 4.1.'}\n",
      "Chunk 3: page_content='Proof. \n",
      " \n",
      " Thanks to ( 2.2 ), we get \n",
      " \n",
      " \n",
      " \n",
      " f ​ ( A i ) ≤ exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ≤ a f ​ A i + b f ​ 𝟏 ℋ . 𝑓 subscript 𝐴 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 subscript 𝑎 𝑓 subscript 𝐴 𝑖 subscript 𝑏 𝑓 subscript 1 ℋ f\\left({{A}_{i}}\\right)\\leq\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\leq{{a}_{f}}{{A}_{i}}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{H}}}. \n",
      " \n",
      " \n",
      " \n",
      " The hypotheses on  Φ i subscript Φ 𝑖 {{\\Phi}_{i}}  and  w i subscript 𝑤 𝑖 {{w}_{i}}  ensure the following: \n",
      " \n",
      " \n",
      " \n",
      " ∑ i = 1 n w i ​ Φ i ​ ( f ​ ( A i ) ) superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 \\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)} \n",
      " ≤ ∑ i = 1 n w i ​ Φ i ​ ( exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ) absent superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 \\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)} \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " ≤ a f ​ ∑ i = 1 n w i ​ Φ i ​ ( A i ) + b f ​ 𝟏 𝒦 . absent subscript 𝑎 𝑓 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 subscript 𝑏 𝑓 subscript 1 𝒦 \\displaystyle\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}. \n",
      " \n",
      " \n",
      " \n",
      " Using the fact that  m ​ 𝟏 𝒦 ≤ ∑ i = 1 n w i ​ Φ i ​ ( A i ) ≤ M ​ 𝟏 𝒦 𝑚 subscript 1 𝒦 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 𝑀 subscript 1 𝒦 m{{\\mathbf{1}}_{\\mathcal{K}}}\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\leq M{{\\mathbf{1}}_{\\mathcal{K}}} , we can write \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " ∑ i = 1 n w i ​ Φ i ​ ( f ​ ( A i ) ) − α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 \\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)} \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " ≤ ∑ i = 1 n w i ​ Φ i ​ ( exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ) − α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) absent superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 \\displaystyle\\quad\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " ≤ a f ​ ∑ i = 1 n w i ​ Φ i ​ ( A i ) + b f ​ 𝟏 𝒦 − α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) absent subscript 𝑎 𝑓 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 subscript 𝑏 𝑓 subscript 1 𝒦 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 \\displaystyle\\quad\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " ≤ max m ≤ t ≤ M ​ { a f ​ t + b f − α ​ g ​ ( t ) } ​ 𝟏 𝒦 , absent 𝑚 𝑡 𝑀 subscript 𝑎 𝑓' metadata={'Header 6': 'Proof.'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">page_content='subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 f\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)}, \n",
       " \n",
       " for operator convex function  f 𝑓 f  defined on an interval  I 𝐼 I , where  Φ i subscript Φ 𝑖 {{\\Phi}_{i}}  ( i = 1 , … , n 𝑖 1 … 𝑛 i=1,\\ldots,n ) are normalized positive linear mappings from  𝔹 ​ ( ℋ ) 𝔹 ℋ \\mathbb{B}\\left(\\mathcal{H}\\right)  to  𝔹 ​ ( 𝒦 ) 𝔹 𝒦 \\mathbb{B}\\left(\\mathcal{K}\\right) ,  A 1 , … , A n subscript 𝐴 1 … subscript 𝐴 𝑛 {{A}_{1}},\\ldots,{{A}_{n}}  are self-adjoint operators with spectra in  I 𝐼 I  and  w 1 , … , w n subscript 𝑤 1 … subscript 𝑤 𝑛 {{w}_{1}},\\ldots,{{w}_{n}}  are non-negative real numbers with  ∑ i = 1 n w i = 1 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 1 \\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1 . \n",
       " \n",
       " In a reverse direction to that of inequality ( 4.1 ) we have the following:' metadata={'Header 1': '#TITLE#'}</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">page_content='Theorem 4.1 . \n",
       " \n",
       " \n",
       " Let  Φ i subscript Φ 𝑖 {{\\Phi}_{i}}  be normalized positive linear maps from  𝔹 ​ ( ℋ ) 𝔹 ℋ \\mathbb{B}\\left(\\mathcal{H}\\right)  to  𝔹 ​ ( 𝒦 ) 𝔹 𝒦 \\mathbb{B}\\left(\\mathcal{K}\\right) ,  A i ∈ 𝔹 ​ ( ℋ ) subscript 𝐴 𝑖 𝔹 ℋ {{A}_{i}}\\in\\mathbb{B}\\left(\\mathcal{H}\\right)  be self-adjoint operators with  m ​ 𝟏 ℋ ≤ A i ≤ M ​ 𝟏 ℋ 𝑚 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 subscript 1 ℋ m{{\\mathbf{1}}_{\\mathcal{H}}}\\leq{{A}_{i}}\\leq M{{\\mathbf{1}}_{\\mathcal{H}}}  for some scalars  m < M 𝑚 𝑀 m<M  and  w i subscript 𝑤 𝑖 {{w}_{i}}  be positive numbers such that  ∑ i = 1 n w i = 1 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 1 \\sum\\nolimits_{i=1}^{n}{{{w}_{i}}}=1 . If  f 𝑓 f  is a log-convex function and  g 𝑔 g  is a continuous function on  [ m , M ] 𝑚 𝑀 \\left[m,M\\right] , then for a given  α ∈ ℝ 𝛼 ℝ \\alpha\\in\\mathbb{R} \n",
       " \n",
       " \n",
       " \n",
       " (4.2) \n",
       " \n",
       " ∑ i = 1 n w i ​ Φ i ​ ( f ​ ( A i ) ) superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 \\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)} \n",
       " ≤ ∑ i = 1 n w i ​ Φ i ​ ( exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ) absent superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 \\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)} \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ≤ α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) + β ​ 𝟏 𝒦 , absent 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 𝛽 subscript 1 𝒦 \\displaystyle\\leq\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)+\\beta{{\\mathbf{1}}_{\\mathcal{K}}}, \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " holds with  β 𝛽 \\beta  as in ( 1.3 ).' metadata={'Header 6': 'Theorem 4.1.'}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">page_content='Proof. \n",
       " \n",
       " Thanks to ( 2.2 ), we get \n",
       " \n",
       " \n",
       " \n",
       " f ​ ( A i ) ≤ exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ≤ a f ​ A i + b f ​ 𝟏 ℋ . 𝑓 subscript 𝐴 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 subscript 𝑎 𝑓 subscript 𝐴 𝑖 subscript 𝑏 𝑓 subscript 1 ℋ f\\left({{A}_{i}}\\right)\\leq\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\leq{{a}_{f}}{{A}_{i}}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{H}}}. \n",
       " \n",
       " \n",
       " \n",
       " The hypotheses on  Φ i subscript Φ 𝑖 {{\\Phi}_{i}}  and  w i subscript 𝑤 𝑖 {{w}_{i}}  ensure the following: \n",
       " \n",
       " \n",
       " \n",
       " ∑ i = 1 n w i ​ Φ i ​ ( f ​ ( A i ) ) superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 \\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)} \n",
       " ≤ ∑ i = 1 n w i ​ Φ i ​ ( exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ) absent superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 \\displaystyle\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)} \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ≤ a f ​ ∑ i = 1 n w i ​ Φ i ​ ( A i ) + b f ​ 𝟏 𝒦 . absent subscript 𝑎 𝑓 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 subscript 𝑏 𝑓 subscript 1 𝒦 \\displaystyle\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}. \n",
       " \n",
       " \n",
       " \n",
       " Using the fact that  m ​ 𝟏 𝒦 ≤ ∑ i = 1 n w i ​ Φ i ​ ( A i ) ≤ M ​ 𝟏 𝒦 𝑚 subscript 1 𝒦 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 𝑀 subscript 1 𝒦 m{{\\mathbf{1}}_{\\mathcal{K}}}\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\leq M{{\\mathbf{1}}_{\\mathcal{K}}} , we can write \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ∑ i = 1 n w i ​ Φ i ​ ( f ​ ( A i ) ) − α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑓 subscript 𝐴 𝑖 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 \\displaystyle\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(f\\left({{A}_{i}}\\right)\\right)-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right)} \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ≤ ∑ i = 1 n w i ​ Φ i ​ ( exp ⁡ ( M ​ 𝟏 ℋ − A i M − m ​ ln ⁡ f ​ ( m ) + A i − m ​ 𝟏 ℋ M − m ​ ln ⁡ f ​ ( M ) ) ) − α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) absent superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 𝑀 subscript 1 ℋ subscript 𝐴 𝑖 𝑀 𝑚 𝑓 𝑚 subscript 𝐴 𝑖 𝑚 subscript 1 ℋ 𝑀 𝑚 𝑓 𝑀 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 \\displaystyle\\quad\\leq\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left(\\exp\\left(\\frac{M{{\\mathbf{1}}_{\\mathcal{H}}}-{{A}_{i}}}{M-m}\\ln f\\left(m\\right)+\\frac{{{A}_{i}}-m{{\\mathbf{1}}_{\\mathcal{H}}}}{M-m}\\ln f\\left(M\\right)\\right)\\right)}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right) \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ≤ a f ​ ∑ i = 1 n w i ​ Φ i ​ ( A i ) + b f ​ 𝟏 𝒦 − α ​ g ​ ( ∑ i = 1 n w i ​ Φ i ​ ( A i ) ) absent subscript 𝑎 𝑓 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 subscript 𝑏 𝑓 subscript 1 𝒦 𝛼 𝑔 superscript subscript 𝑖 1 𝑛 subscript 𝑤 𝑖 subscript Φ 𝑖 subscript 𝐴 𝑖 \\displaystyle\\quad\\leq{{a}_{f}}\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}+{{b}_{f}}{{\\mathbf{1}}_{\\mathcal{K}}}-\\alpha g\\left(\\sum\\limits_{i=1}^{n}{{{w}_{i}}{{\\Phi}_{i}}\\left({{A}_{i}}\\right)}\\right) \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " \n",
       " ≤ max m ≤ t ≤ M ​ { a f ​ t + b f − α ​ g ​ ( t ) } ​ 𝟏 𝒦 , absent 𝑚 𝑡 𝑀 subscript 𝑎 𝑓' metadata={'Header 6': 'Proof.'}</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 200000\n",
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text,\n",
    "    chunking_api=splitter.split_text,\n",
    "    max_length=max_len\n",
    ")\n",
    "\n",
    "# 显示高亮文本\n",
    "highlighter.display_highlighted_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/113.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/107.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/12.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/339.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/477.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/311.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/305.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/463.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/488.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/259.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/503.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/265.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/271.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/270.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/502.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/264.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/258.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/489.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/304.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/462.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/476.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/310.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/338.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/13.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/106.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/112.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/138.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/104.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/110.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/11.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/39.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/448.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/460.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/306.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/312.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/474.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/272.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/266.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/500.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/299.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/298.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/267.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/501.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/273.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/313.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/475.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/461.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/307.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/449.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/38.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/10.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/111.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/105.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/139.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/101.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/115.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/129.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/28.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/14.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/303.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/465.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/471.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/317.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/459.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/277.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/505.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/263.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/288.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/289.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/504.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/262.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/276.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/458.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/470.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/316.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/302.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/464.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/15.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/29.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/128.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/114.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/100.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/116.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/102.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/17.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/314.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/472.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/466.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/300.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/328.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/499.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/260.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/506.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/274.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/248.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/249.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/275.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/261.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/507.tex\n",
      "\n",
      "测试文件: chunk_experiment/data/latex/arxiv/498.tex\n",
      "100个文档平均运行时间:0.0065秒\n"
     ]
    }
   ],
   "source": [
    "type=\".tex\"\n",
    "paths,splitter = choose_type(type)\n",
    "file_paths = [os.path.join(paths, f) for f in os.listdir(paths) if f.endswith(type)]\n",
    "file_paths = file_paths[:100]\n",
    "\n",
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"latin1\") as f:\n",
    "        sample_text = f.read()\n",
    "\n",
    "    print(f\"\\n测试文件: {file_path}\")\n",
    "    start_time = time.time()\n",
    "    chunks = splitter.split_text(sample_text)\n",
    "    end_time = time.time()\n",
    "    total_time += end_time - start_time\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高亮展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 76840, 长度: 20000\n",
      "选取的文本片段:\n",
      "(3)}(t) \\le d_i (t), \\forall t=1,2,\\ldots,e, i=1,2,\\ldots,n \\\\\\nonumber\n",
      "%\\prod_{t=1}^{e}[d_{i}(t)-(\\lambda_p^i+D^{(p)}(t))]=0,\\forall p=1,2,3, i=1,2,\\ldots,n.\\\\\\nonumber\n",
      "%\\end{eqnarray}\n",
      "%After this reformulation, we're very possibly able to use sequential quadratic programming(SQL) to solve this optimization problem.\n",
      "%\\end{corollary}\n",
      "\n",
      "\n",
      "\n",
      "%%%%%  We will discuss them in DIscussion\n",
      "% Then we can ask the following questions:\n",
      "% \\begin{problem}\n",
      "% Suppose we have a random sample $S \\subset \\Tn$ of saze $n$.  Then how\n",
      "% often can we get a unique solution?\n",
      "% \\end{problem}\n",
      "% \\begin{problem}\n",
      "% Comparing with tropical Fermat-Weber points.  Does an (the?) optimal\n",
      "% solution for Problem \\ref{optimization} contains a tropical\n",
      "% Fermat-Weber point of the sample $S$?  How does it relate to?\n",
      "% Tropical Fermat-Weber points can be found at \\url{https://arxiv.org/abs/1604.04674}.\n",
      "% \\end{problem}\n",
      "\n",
      "% \\begin{proposition}\n",
      "% With given a sample $\\{d_1,\\cdots,d_n\\}$, suppose $\\bm{y}$ is a tropical\n",
      "% Fermat-Weber point of the sample.  If $\\bm{y}(k) \\leq d_i(k)$ for $k = 1,\n",
      "% \\ldots , e$ for all $i = 1, \\ldots , n$, then the convex hull of $D^{(1)},\n",
      "% D^{(2)}, D^{(3)} \\in \\Tn$ obtained from the optimization problem in\n",
      "% Problem \\ref{optimization} contains the tropical Fermat-Weber point $y$.\n",
      "% \\end{proposition}\n",
      "% \\begin{proof}\n",
      "% For a Fermat-Weber points of $\\{d_1,\\ldots,d_n\\}$, it's the solution $\\bm{y}$ of \n",
      "% $$\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; \\bm{y}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i$$\n",
      "% $$\\text{subject to }\\Delta_i \\ge d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l),\\forall i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e$$\n",
      "% $$\\Delta_i \\ge -[d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l)],\\forall\n",
      "% i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e.$$\n",
      "\n",
      "% Suppose we have $\\bm{y}(k) \\leq d_i(k)$ for $k = 1,\n",
      "% \\ldots , e$ for all $i = 1, \\ldots , n$.  Then we have the system:\n",
      "% $$\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; \\bm{y}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i$$\n",
      "% $$\\text{subject to }\\Delta_i \\ge d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l),\\forall i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e$$\n",
      "% $$\\Delta_i \\ge -[d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l)],\\forall\n",
      "% i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e.$$\n",
      "% $$\\bm{y}(k) \\leq d_i(k), \\, \\forall i 1, 2, \\cdots , n \\text{ and } k\n",
      "% = 1, 2, \\cdots , e.\n",
      "% $$\n",
      "% This is equivalent to the system in \\eqref{trop:polytope}.\n",
      "% here, for different $\\Delta_i$ in the constraints, the target vector $\\bm{y}$ isn't changing with i.\\\\\n",
      "% \\\\\n",
      "% For the same sample $\\{d_1,\\cdots,d_n\\}$, we look at the solution \\{$d_1^{'},d_2^{'},\\cdots,d_n^{'}$\\} of the formula (4),\n",
      "% $$\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; d^{'}_{1},\\ldots,d^{'}_{n}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i$$\n",
      "% $$\\text{subject to }\\Delta_i \\ge d_{i}(k)-d^{'}_{i}(k)-d_{i}(l)+d^{'}_{i}(l),\\forall i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e$$\n",
      "% $$\\Delta_i \\ge -[d_{i}(k)-d^{'}_{i}(k)-d_{i}(l)+d^{'}_{i}(l)],\\forall i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e$$\n",
      "% (there're no extra constraints on $d_i^{'}$'s)\n",
      "% which is very similar to the optimiaztion problem of Fermat-Weber points.\n",
      "% But here, for different $\\Delta_i$, the constraining vector $d_i^{'}$ can be different.\\\\\n",
      "% Then if we choose $n$ $\\bm{y}$'s from the space of Fermant-Weber points (repeats allowed), they must be one solution of formula (4). But conversely, for one solution \\{$d_1^{'},\\ldots,d_n^{'}$\\} of formula (4), possibly not every $d_i^{'}$ is Fermat-Weber point of $d_1,\\ldots,d_n$. \n",
      "%\\end{proof}\n",
      "\n",
      "\\subsection{Heuristic approximation}\n",
      "As noted above, the number of variables in the mixed integer linear programming problem in Proposition \\ref{polytope_projection} increases quickly with the number of leaves and data points. Because solving mixed linear integer\n",
      "programming is NP-hard \\cite{Lenstra},\n",
      "this problem is difficult to solve in practice. In analogy with Algorithm \\ref{tropical-linear-space-algorithm}, therefore, we develop a heuristic method for approximating the optimal solution for the problem in Proposition \n",
      "\\ref{polytope_projection}.  \n",
      "\\begin{algorithm}[Approximation for the second order PCA as a tropical polytope]\\label{al1} %\\qquad\n",
      "\\begin{algorithmic}\n",
      "\\State Stochastic optimization algorithm to fit $\\mathcal P$ to $D^{(i)}$.\n",
      "\\State Fix an ordered set $V = (D^{(1)}, D^{(2)}, D^{(3)})$ and compute $\\mathcal P = \\text{tconv}(V)$. \n",
      "\\Repeat:\n",
      "\t\\State Sample three datapoints $D^{(j_1)}, D^{(j_2)}, D^{(j_3)}$ randomly from the set of all datapoints.\n",
      "\t\\State Let $V' = \\{D^{(j_1)}, D^{(j_2)}, D^{(j_3)}\\}$.\n",
      "\t\\State Compute $d(\\mathcal P') = d(\\text{tconv}(V'))$.\n",
      "\t\\State if $d(\\mathcal P)>d(\\mathcal P'),$ set $V \\gets V'$.\n",
      "\\Until convergence.\n",
      "\\end{algorithmic}\n",
      "\\end{algorithm}\n",
      "\n",
      "As before, convergence can be assessed by considering whether a new choice of $V$ has been found over a fixed number of previous iterations. If computational time is limited, another approach might simply be to prespecify a total number $t$ of samples. And of course, when the computational cost is reasonable one could enumerate through all $\\binom n 3$ different choices for the generating points of $\\mathcal P$ instead of sampling.\n",
      "\n",
      "\\begin{remark}\n",
      "Three data points $D^{(j_1)}, D^{(j_2)},$ and $D^{(j_3)}$ define both a Stiefel tropical linear space $L_p$ and a tropical polytope $\\mathcal P$. Because Stiefel tropical linear spaces are tropically convex, and each of the generating points is contained in $L_p$, we see that $\\mathcal P\\subseteq L_p$. In particular, given the same convergence criteria, we should expect Algorithm \\ref{tropical-linear-space-algorithm} to provide a somewhat better fit than Algorithm \\ref{al1}.\n",
      "\\end{remark}\n",
      "\n",
      "\\begin{remark}\n",
      "Note that Algorithm \\ref{al1} is well-suited for applications to phylogenetics. Because $\\mathcal U_m$ is a tropical linear space (Theorem \\ref{ultrametrics}) and tropical linear spaces are tropically convex, the solution set $\\mathcal P = \\text{tconv}(D^{(1)},D^{(2)}, D^{(3)})$ obtained from Algorithm \\ref{al1} will be contained in the space of ultrametrics. In particular, projections of ultrametrics are also ultrametrics.\n",
      "\\end{remark}\n",
      "\n",
      "% \\begin{remark}\n",
      "% We found examples of best-fit tropical polytopes which do not contain all tropical Fermat-Weber points. When not constrained in the space of ultrametrics, suppose we have three points \n",
      "% $$(0,2,5),(0,0,0),(0,3,1)$$\n",
      "% and the Fermat-Weber points of these three points are shown in \\cite{LY} Figure 1, which is also shown below, the blue closed triangle with vertices \n",
      "% $$(0,1,1),(0,2,1),(0,2,2).$$ We want to find the best-fit tropocal polytope $\\mathcal P = \\text{tconv}(D^{(1)}, D^{(2)})$ of these same three points. And from Proposition \\ref{polytope_projection}, we know that the minimized sum of projection distances should be 3. For one Fermet-Weber point $(0,2,1)$, we can have $\\mathcal P^{'} = \\text{tconv}((0,2,1), (0,2,5))$ which leads to the sum of projection distances to be 3, then point $(0,2,1)$ is within the best-fit tropical polytope. But for one Fermet-Weber point $(0,2,2)$, we can't have $\\mathcal P^{*} = \\text{tconv}((0,2,2), D^{(2)})$ which leads to the sum of projection distances to be 3, i.e. for any choice of $D^{(2)}$, the sum of projection distances onto $\\mathcal P^{*}$ is always greater than 3. Then we can see this Fermat-Weber point $(0,2,2)$ is not within the best-fit tropical polytope.\n",
      "% \\begin{figure}[!ht]\n",
      "% \\centering\n",
      "% \\includegraphics[width=0.4\\linewidth]{fw_exam.pdf}\n",
      "%   \\caption{Example where best-fit tropical polytopes do not contain all tropical Fermat-Weber points}\n",
      "%   %\\label{sim_topology}\n",
      "% \\end{figure}\n",
      "\n",
      "% \\end{remark}------Wrong example.\n",
      "\n",
      "\\section{Simulations}\\label{sim}\n",
      "\n",
      "In this section, we apply the previous results to simulated datasets coming from phylogenetics. \n",
      "\n",
      "\\subsection{Exact methods}\n",
      "\n",
      "We begin by identifying the exact best-fit tropical polytope with three vertices closest to a small dataset of equidistant trees using Proposition \\ref{polytope_projection}. We implemented this proposition mainly based on a {\\tt R} interface to the popular optimization software {\\tt IBM ILOG CPLEX}, called {\\tt cplexAPI}.\n",
      "\n",
      "\\begin{example}\\label{polytope_example}\n",
      "We randomly generated 6 equidistant trees with 3 leaves and computed their vectorized distance matrices in Figure \\ref{figure 1} and Table \\ref{table 1}. \n",
      "\n",
      "\\begin{figure}[!ht]\n",
      "\\begin{floatrow}\n",
      "\\ffigbox{%\n",
      "  \\includegraphics[width=0.9\\linewidth]{Rplot1.pdf}\n",
      "}{%\n",
      "  \\caption{Random Sample of Trees}%\n",
      "  \\label{figure 1}\n",
      "}\n",
      "\\capbtabbox{%\n",
      "  \\begin{tabular}[b]{cccc}\n",
      "\t\\hline\\hline\n",
      "     tree1 & 0.69089925 & 7.022836 & 7.022836\\\\\n",
      "     \\hline\n",
      "     tree2 & 0.53495974 & 1.641369 & 1.641369\\\\\n",
      "     \\hline\n",
      "     tree3 & 0.02082164 & 3.101557 & 3.101557\\\\\n",
      "     \\hline\n",
      "     tree4 & 0.23519336 & 3.968678 & 3.968678\\\\\n",
      "     \\hline\n",
      "     tree5 & 0.19730562 & 5.960980 & 5.960980\\\\\n",
      "     \\hline\n",
      "     tree6 & 0.73804678 & 1.090399 & 1.090399\\\\\n",
      "     \\hline\\hline\n",
      "     \\end{tabular}\n",
      "}{%\n",
      "  \\caption{Vectorized Distance Matrices}%\n",
      "  \\label{table 1}\n",
      "}\n",
      "\\end{floatrow}\n",
      "\\end{figure}\n",
      "\n",
      "\\begin{figure}[!ht]\n",
      "\\begin{floatrow}\n",
      "\\ffigbox{%\n",
      "  \\includegraphics[width=0.9\\linewidth]{simtr3.pdf}\n",
      "}{%\n",
      "  \\caption{$D^{(1)},D^{(2)},D^{(3)}$}%\n",
      "  \\label{figure 2}\n",
      "}\n",
      "\\capbtabbox{%\n",
      "  \\begin{tabular}[b]{cccc}\n",
      "\t\\hline\\hline\n",
      "     $D^{(1)}$ & 1 & 1.352352 & 1.352352\\\\\n",
      "     \\hline\n",
      "     $D^{(2)}$ & 1 & 2.106409 & 2.106409\\\\\n",
      "     \\hline\n",
      "     $D^{(3)}$ & 1 & 7.331937 & 7.331937\\\\\n",
      "     \\hline\\hline\n",
      "     \\end{tabular}\n",
      "}{%\n",
      "  \\caption{Vectorized Distance Matrices}%\n",
      "  \\label{table 2}\n",
      "}\n",
      "\\end{floatrow}\n",
      "\\end{figure}\n",
      "\n",
      "Using our optimization problem formulation from Proposition \\ref{polytope_projection}, we obtain $D^{(1)},D^{(2)},D^{(3)}$ for this example. These points are ultrametrics, and they are described in Figure \\ref{figure 2} and Table \\ref{table 2}. In fact, in this case the best-fit tropical polytope contains all the equidistant trees, so that the sum of distances is zero.\n",
      "\\end{example}\n",
      "\n",
      "\\subsection{Approximative algorithms}\n",
      "For larger datasets, we turn to the approximative Algorithms \\ref{tropical-linear-space-algorithm} and \\ref{al1}. We implemented both algorithms in {\\tt R}.\\footnote{Our software for all computations can be downloaded at \\url{http://polytopes.net/computations/tropicalPCA/}.} We then generated a random sample from {\\tt Mesquite} \\cite{Mesq} and applied our algorithms on this dataset. The sample was constructed as follows:\n",
      "\\begin{algorithm}[Generating the simulation dataset]\\label{sim_data} \n",
      "                                \\qquad  \\qquad \\qquad \n",
      "\n",
      "\\begin{enumerate}\n",
      "\\item Generate 250 gene trees with 8 leaves from the coalescent model under a fixed species tree with depth equal to 10 \n",
      "\\item Transform the gene trees to be ultrametrics.\n",
      "\\item Compute approximate second order tropical principal components via the Algorithms \\ref{tropical-linear-space-algorithm} and \\ref{al1}.\n",
      "\\end{enumerate}\n",
      "\\end{algorithm}\n",
      "\n",
      "We applied both methods of tropical principal component analysis to a set of random trees generated by Algorithm \\ref{sim_data}. In analogy with \\cite{NTWY}, we define summary statistics to describe the fit of a Stiefel tropical linear space\n",
      "or a tropical polytope to a given data\n",
      "set. If $L_p$ is a Stiefel tropical linear space, we define its distance to the datapoints $d(L_p)$ as\n",
      "\\[d(L_p) = \\sum_i d(D^{(i)}, L_p),\\]\n",
      "and a tropical proportion of variance statistic\n",
      "\\[r(L_p) = \\frac{\\sum_i d_{tr}(\\bar \\pi, \\pi_{L_p}(D^{(i)}))}{\\sum_i d_{tr}(D^{(i)}, \\pi_{L_p}(D^{(i)})+\\sum_i d_{tr}(\\bar \\pi, \\pi_{L_p}(D^{(i)}))}\\]\n",
      "where $\\bar \\pi$ denotes a Fermat-Weber point of the projections of the datapoints, as in \\cite{LY}. These statistics are defined analogously for a tropical polytope $\\mathcal P$. The statistic $r(L_p)$ can be interpreted as the proportion of variance explained by $L_p$; in order to remain consistent with the tropical metric, we sum distances rather than squared distances. \n",
      "\n",
      "For the polytopal approach, as noted above, the projections will remain ultrametrics. We therefore analyze the topologies of these projections, and compare them with the topology of the species tree.\n",
      "\n",
      "\\subsection{Approximation results}\n",
      "\n",
      "We applied Algorithm \\ref{tropical-linear-space-algorithm} to find an approximate 2-dimensional best-fit Stiefel tropical linear space with a convergence threshold of 100 iterations. The summary statistics for this run were: $d(L_p)=363.0378$ and $r(L_p) = 0.322$.\n",
      "\n",
      "We also applied a variant of Algorithm \\ref{al1} to find an approximate best-fit tropical polytope with three vertices, in which we enumerated through all $\\binom{250}{3}$ different choices. The summary statistics were: $d(\\mathcal P) = 360.6831$ and \n",
      "$r(\\mathcal P) = 0.265$. We note that the overall sum of distances is similar between the two methods, but that the best-fit Stiefel tropical linear space explains a slightly higher proportion of variance. \n",
      "\n",
      "For the tropical polytope method, we recall that projections of equidistant trees will remain ultrametrics. We present common topologies of the projections as well as the species tree topology\n",
      "in Figure \\ref{sim_topology}.\\footnote{Tree topologies of all projected\n",
      "points can be found in the supplement \n",
      "at \\url{http://polytopes.net/computations/tropicalPCA/}.}\n",
      "We observe that these topologies of\n",
      "projected trees are broadly consistent with the topology of the species tree\n",
      "under which these gene trees were generated: taxa $g$ and $c$ group\n",
      "together, as do taxa $h$ and $f$, and the four taxa $a$, $b$, $d$, $e$ also group together. We can view our best-fit tropical polytope as preserving these features of the species tree, meaning that this tropical polytope retains information after projection.\n",
      "\\begin{figure}[!ht]\n",
      "\\centering\n",
      "\\includegraphics[width=0.6\\linewidth]{proj_sim_250_8_topology.pdf}\n",
      "  \\caption{Topology frequencies after projections: the parenthesized numbers are frequencies, and the last tree gives the species tree topology.}\n",
      "  \\label{sim_topology}\n",
      "\\end{figure}\n",
      "\n",
      "\\section{Apicomplexa genome}\\label{apicomplexa}\n",
      "\n",
      "We also applied our tropical principal component algorithms to a set of trees constructed from 252\n",
      "orthologous sequences on eight species of protozoa in the\n",
      "Apicomplexa phylum by \\cite{KWK}.   \n",
      "This dataset was also analyzed by Weyenberg et.~al; one can find\n",
      "more details, such as the gene sequences, in \\cite{KDETrees}.\n",
      "Because ordinary PCA is sensitive to outliers, we removed 16 outlier gene trees identified by \\cite{KDETrees} before fitting the tropical principal components.\n",
      "\n",
      "To find an approximate best-fit 2-dimensional Stiefel tropical linear space, we applied Algorithm \\ref{tropical-linear-space-algorithm} with a convergence threshold of 100 iterations. Due to the stochastic nature of the algorithm, we executed the algorithm three times. %Tree topologies from a representative execution are presented in Table \\ref{apicomplexa-tropical-linear-space}. We note the close similarity between the most common tree topology with the generally-accepted phylogeny of these eight taxa \\cite[Figure 1]{KWK}. \n",
      "The summary statistics remained consistent between these runs. For one representative execution, these statistics were: $d(L_p) = 145.38$ and $r(L_p)=0.616$. % In general, furthermore, projected topologies were largely congruent with the generally accepted phylogeny: the two Plasmodium species (Pv and Pf) group together, as do Ta and Bb; and Tt is isolated on a deep branch.\n",
      "\n",
      "\\begin{comment}\\begin{table}\n",
      "\\centering\n",
      "\\caption{Tree topologies and frequency counts for  apicomplexa gene tree projections}\n",
      "\\label{apicomplexa-tropical-linear-space}\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "Count & Topology & Count & Topology\\\\\\hline\n",
      "112 & \\includegraphics[height=1.65in]{apicomplexa-tree3.png} & 31 & \\includegraphics[height=1.65in]{apicomplexa-tree13.png}\\\\ \\hline\n",
      "30 & \\includegraphics[height=1.65in]{apicomplexa-tree9.png} & 26 & \\includegraphics[height=1.65in]{apicomplexa-tree1.png}\\\\ \\hline\n",
      "20 & \\includegraphics[height=1.65in]{apicomplexa-tree4.png} & 17 & \\includegraphics[height=1.65in]{apicomplexa-tree24.png}\\\\ \\hline\n",
      "8 & \\includegraphics[height=1.65in]{apicomplexa-tree14.png} & 7 & \\includegraphics[height=1.65in]{apicomplexa-tree43.png}\\\\ \\hline\n",
      "1 & \\includegraphics[height=1.65in]{apicomplexa-tree202.png} & \\ & \\ \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "Comparing the tropical PC's on tropical topology and tropical linear space, we can see that the most three frequent topologies of the projected trees for the apicomplexa data (which totally covered more than two thirds of all trees) are the same for these two methods.\n",
      "\\end{comment}\n",
      "\n",
      "% \\subsection{African coelacanths genome and transcriptome data}\n",
      "% We also have applied tropical PCAs to the dataset consisting of 1,290\n",
      "% nuclear genes encoding 690,838 amino acid residues obtained from\n",
      "% genome and transcriptome data in \\cite{LSZ}. \n",
      "% It has been much work on the phylogenetic relations between\n",
      "% coelacanths, lungfishes and tetrapods, but still it is not clear\n",
      "% despite several studies \\cite{Hedges2009}. \n",
      "\n",
      "% Most morphological and paleontological studies support the hypothesis that lungfishes are closer to tetrapods than they are to coelacanths \\cite[Fig. 1, Tree 1]{LSZ}.\n",
      "% However, some research supports the hypothesis that coelacanths are\n",
      "% closer to tetrapods \\cite[Fig. 1, Tree 2]{LSZ}. \n",
      "% Others support the hypothesis that coelacanths and lungfishes form a\n",
      "% sister clade \\cite[Fig. 1, Tree 3]{LSZ}, or that tetrapods,\n",
      "% lungfishes, and coelacanths cannot be resolved \\cite[Fig.1, Tree\n",
      "% 4]{LSZ}. \n",
      "\n",
      "% We have used the gene trees used for the PCA under the BHV metric over\n",
      "% the tree space by Nye.~et.~al and detailed information such as tree\n",
      "% reconstruction method used as well as species names can be found in \\cite{NTWY}.\n",
      "% %\\begin{small}\n",
      "\n",
      "\n",
      "\n",
      "We also applied a variant of Algorithm \\ref{al1} to find a well-fitted tropical polytope with three vertices, enumerating through all ${\\binom{252}{3}}$ possibilities. The summary statistics for this run were: $d(\\mathcal P)= 147.0568$ and $r(\\mathcal P) = 0.612$. We note that these summary statistics are relatively consistent with the summary statistics obtained from the Stiefel tropical linear space algorithm. \n",
      "\n",
      "The tree topologies are presented in Figure \\ref{api_topology}. In general, the projected topologies were largely congruent with the generally accepted phylogeny: the two Plasmodium species (Pv and Pf) group together, as do the four species Ta, Bb, Tg, and Et, and Tt is isolated on a deep branch. \n",
      "\n",
      "\\cite[Theorem 23]{DS} tells us the tropical convex hull of the rows and columns of a matrix are equal. This allows us to visualize our best-fit tropical polytope in the two-dimensional plane $\\mathbb R^3/\\RR {\\bf 1}$ as the tropical convex hull of 28 points. These 28 points divide the polytope into different cells, as described in \\cite[Example 9]{JSY}. We plot this polytope, along with its cells and the projections of our data points, in Figure \\ref{api_triangle}.  We note that the different topologies seem to divide the tropical polytope PCA into several regions of positive area. \n",
      "\n",
      "% \\begin{figure}[!ht]\n",
      "% \\centering\n",
      "% \\includegraphics[width=0.5\\linewidth]{proj_api_topology.pdf}\n",
      "%   \\caption{Projected topology frequencies from the Apicomplexa dataset: parenthesized numbers give the frequencies of each topology.}\n",
      "%   \\label{api_topology}\n",
      "% \\end{figure}\n",
      "\n",
      "% \\begin{figure}[!ht]\n",
      "% \\centering\n",
      "% \\includegraphics[width=0.5\\linewidth]{api_approx_visual.pdf}\n",
      "%   \\caption{Projected points onto the tropical triangle}\n",
      "%   \\label{api_triangle}\n",
      "% \\end{figure}\n",
      "\n",
      "\\begin{figure}[!ht]\n",
      "\\includegraphics[width=1\\linewidth]{proj_api_topology.png}\n",
      "\\caption{Projected topology frequencies from the Apicomplexa dataset: parenthesized numbers give the frequencies of each topology.}%\n",
      "\\label{api_topology}\n",
      "\\end{figure}\n",
      "\\begin{figure}[!ht]\n",
      "\n",
      "  \\includegraphics[width=0.6\\linewidth]{api_approx_visual.pdf}\n",
      "{%\n",
      "\\caption{Projected points in the tropical polytope PCA, colored as in Figure \\ref{api_topology}.}%\n",
      "\\label{api_triangle}\n",
      "}\n",
      "\\end{figure}\n",
      "\n",
      "\n",
      "\n",
      "\\section{Discussion}\\label{discuss}\n",
      "\n",
      "In recent decades, the field of phylogenetics has found\n",
      "applications in the analysis on g\n",
      "\n",
      "文本已分成 589 块。\n",
      "分块结果:\n",
      "Chunk 1: (3)}(t) \\le d_i (t), \\forall t=1,2,\\ldots,e,\n",
      "Chunk 2: i=1,2,\\ldots,n\n",
      "Chunk 3: \\\\\\nonumber\n",
      "%\\prod_{t=1}^{e}[d_{i}(t)-(\\lambda_p^\n",
      "Chunk 4: \\lambda_p^i+D^{(p)}(t))]=0,\\forall\n",
      "Chunk 5: p=1,2,3,\n",
      "Chunk 6: i=1,2,\\ldots,n.\\\\\\nonumber\n",
      "%\\end{eqnarray}\n",
      "%After\n",
      "Chunk 7: this reformulation, we're very possibly able to\n",
      "Chunk 8: able to use sequential quadratic programming(SQL)\n",
      "Chunk 9: to solve this optimization\n",
      "Chunk 10: problem.\n",
      "%\\end{corollary}\n",
      "\n",
      "\n",
      "\n",
      "%%%%%  We will\n",
      "Chunk 11: We will discuss them in DIscussion\n",
      "% Then we can\n",
      "Chunk 12: we can ask the following questions:\n",
      "%\n",
      "Chunk 13: \\begin{problem}\n",
      "% Suppose we have a random sample\n",
      "Chunk 14: sample\n",
      "Chunk 15: $S \\subset \\Tn$ of saze $n\n",
      "Chunk 16: $.  Then how\n",
      "% often can we get a unique\n",
      "Chunk 17: a unique solution?\n",
      "% \\end{problem}\n",
      "%\n",
      "Chunk 18: \\begin{problem}\n",
      "% Comparing with tropical\n",
      "Chunk 19: tropical Fermat-Weber points.  Does an (the?)\n",
      "Chunk 20: an (the?) optimal\n",
      "% solution for Problem\n",
      "Chunk 21: Problem \\ref{optimization} contains a tropical\n",
      "%\n",
      "Chunk 22: Fermat-Weber point of the sample\n",
      "Chunk 23: $S\n",
      "Chunk 24: $?  How does it relate to?\n",
      "% Tropical Fermat-Weber\n",
      "Chunk 25: points can be found at\n",
      "Chunk 26: at \\url{https://arxiv.org/abs/1604.04674}.\n",
      "%\n",
      "Chunk 27: \\end{problem}\n",
      "\n",
      "% \\begin{proposition}\n",
      "% With given\n",
      "Chunk 28: given a sample\n",
      "Chunk 29: $\\{d_1,\\cdots,d_n\\}$, suppose $\\bm{y}\n",
      "Chunk 30: $ is a tropical\n",
      "% Fermat-Weber point of the\n",
      "Chunk 31: of the sample.  If\n",
      "Chunk 32: $\\bm{y}(k) \\leq d_i(k)$ for $k = 1,\n",
      "% \\ldots , e\n",
      "Chunk 33: $ for all $i = 1, \\ldots , n\n",
      "Chunk 34: $, then the convex hull of\n",
      "Chunk 35: $D^{(1)},\n",
      "% D^{(2)}, D^{(3)} \\in \\Tn\n",
      "Chunk 36: $ obtained from the optimization problem in\n",
      "%\n",
      "Chunk 37: in\n",
      "% Problem \\ref{optimization} contains the\n",
      "Chunk 38: the tropical Fermat-Weber point\n",
      "Chunk 39: $y\n",
      "Chunk 40: $.\n",
      "% \\end{proposition}\n",
      "% \\begin{proof}\n",
      "% For a\n",
      "Chunk 41: For a Fermat-Weber points of\n",
      "Chunk 42: $\\{d_1,\\ldots,d_n\\}$, it's the solution $\\bm{y}\n",
      "Chunk 43: $\\bm{y}$ of \n",
      "%\n",
      "Chunk 44: $\n",
      "Chunk 45: $\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; \\bm{y}\\in\n",
      "Chunk 46: \\bm{y}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i\n",
      "Chunk 47: $$\n",
      "%\n",
      "Chunk 48: $\n",
      "Chunk 49: $\\text{subject to }\\Delta_i \\ge\n",
      "Chunk 50: \\ge d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l),\\forall\n",
      "Chunk 51: i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e\n",
      "Chunk 52: $$\n",
      "%\n",
      "Chunk 53: $\n",
      "Chunk 54: $\\Delta_i \\ge\n",
      "Chunk 55: -[d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l)],\\forall\n",
      "Chunk 56: ],\\forall\n",
      "%\n",
      "Chunk 57: i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e.\n",
      "Chunk 58: $$\n",
      "\n",
      "% Suppose we have $\\bm{y}(k) \\leq d_i(k)$ for\n",
      "Chunk 59: $ for $k = 1,\n",
      "% \\ldots , e$ for all\n",
      "Chunk 60: $ for all $i = 1, \\ldots , n\n",
      "Chunk 61: $.  Then we have the system:\n",
      "%\n",
      "Chunk 62: $\n",
      "Chunk 63: $\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; \\bm{y}\\in\n",
      "Chunk 64: \\bm{y}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i\n",
      "Chunk 65: $$\n",
      "%\n",
      "Chunk 66: $\n",
      "Chunk 67: $\\text{subject to }\\Delta_i \\ge\n",
      "Chunk 68: \\ge d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l),\\forall\n",
      "Chunk 69: i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e\n",
      "Chunk 70: $$\n",
      "%\n",
      "Chunk 71: $\n",
      "Chunk 72: $\\Delta_i \\ge\n",
      "Chunk 73: -[d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l)],\\forall\n",
      "Chunk 74: ],\\forall\n",
      "%\n",
      "Chunk 75: i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e.\n",
      "Chunk 76: $$\n",
      "%\n",
      "Chunk 77: $\n",
      "Chunk 78: $\\bm{y}(k) \\leq d_i(k), \\, \\forall i 1, 2, \\cdots\n",
      "Chunk 79: 2, \\cdots , n \\text{ and } k\n",
      "% = 1, 2, \\cdots ,\n",
      "Chunk 80: \\cdots , e.\n",
      "%\n",
      "Chunk 81: $\n",
      "Chunk 82: $\n",
      "% This is equivalent to the system in\n",
      "Chunk 83: system in \\eqref{trop:polytope}.\n",
      "% here, for\n",
      "Chunk 84: here, for different\n",
      "Chunk 85: $\\Delta_i$ in the constraints, the target vector\n",
      "Chunk 86: $\\bm{y}\n",
      "Chunk 87: $ isn't changing with i.\\\\\n",
      "% \\\\\n",
      "% For the same\n",
      "Chunk 88: the same sample\n",
      "Chunk 89: $\\{d_1,\\cdots,d_n\\}$, we look at the solution \\{\n",
      "Chunk 90: $d_1^{'},d_2^{'},\\cdots,d_n^{'}\n",
      "Chunk 91: $\\} of the formula (4),\n",
      "%\n",
      "Chunk 92: $\n",
      "Chunk 93: $\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR;\n",
      "Chunk 94: \\in \\RR; d^{'}_{1},\\ldots,d^{'}_{n}\\in\n",
      "Chunk 95: \\RR^e;}\\sum_{i=1}^{n}\\Delta_i\n",
      "Chunk 96: $$\n",
      "%\n",
      "Chunk 97: $\n",
      "Chunk 98: $\\text{subject to }\\Delta_i \\ge\n",
      "Chunk 99: d_{i}(k)-d^{'}_{i}(k)-d_{i}(l)+d^{'}_{i}(l),\\fora\n",
      "Chunk 100: }(l),\\forall\n",
      "Chunk 101: i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e\n",
      "Chunk 102: $$\n",
      "%\n",
      "Chunk 103: $\n",
      "Chunk 104: $\\Delta_i \\ge\n",
      "Chunk 105: -[d_{i}(k)-d^{'}_{i}(k)-d_{i}(l)+d^{'}_{i}(l)],\\f\n",
      "Chunk 106: {i}(l)],\\forall\n",
      "Chunk 107: i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e\n",
      "Chunk 108: $$\n",
      "% (there're no extra constraints on $d_i^{'}\n",
      "Chunk 109: $'s)\n",
      "% which is very similar to the optimiaztion\n",
      "Chunk 110: problem of Fermat-Weber points.\n",
      "% But here, for\n",
      "Chunk 111: here, for different\n",
      "Chunk 112: $\\Delta_i$, the constraining vector $d_i^{'}\n",
      "Chunk 113: $d_i^{'}$ can be different.\\\\\n",
      "% Then if we choose\n",
      "Chunk 114: $n$ $\\bm{y}\n",
      "Chunk 115: $'s from the space of Fermant-Weber points\n",
      "Chunk 116: points (repeats allowed), they must be one\n",
      "Chunk 117: be one solution of formula (4). But conversely,\n",
      "Chunk 118: for one solution \\{\n",
      "Chunk 119: $d_1^{'},\\ldots,d_n^{'}\n",
      "Chunk 120: $\\} of formula (4), possibly not every $d_i^{'}\n",
      "Chunk 121: $d_i^{'}$ is Fermat-Weber point of $d_1,\\ldots,d_n\n",
      "Chunk 122: $. \n",
      "%\\end{proof}\n",
      "\n",
      "\\subsection{Heuristic\n",
      "Chunk 123: approximation}\n",
      "As noted above, the number of\n",
      "Chunk 124: number of variables in the mixed integer linear\n",
      "Chunk 125: linear programming problem in Proposition\n",
      "Chunk 126: \\ref{polytope_projection} increases quickly with\n",
      "Chunk 127: with the number of leaves and data points.\n",
      "Chunk 128: points. Because solving mixed linear\n",
      "Chunk 129: linear integer\n",
      "programming is NP-hard\n",
      "Chunk 130: NP-hard \\cite{Lenstra},\n",
      "this problem is difficult\n",
      "Chunk 131: difficult to solve in practice. In analogy with\n",
      "Chunk 132: with Algorithm\n",
      "Chunk 133: Algorithm \\ref{tropical-linear-space-algorithm},\n",
      "Chunk 134: therefore, we develop a heuristic method for\n",
      "Chunk 135: for approximating the optimal solution for the\n",
      "Chunk 136: for the problem in Proposition\n",
      "Chunk 137: \\ref{polytope_projection}.\n",
      "Chunk 138: \\begin{algorithm}[Approximation for the second\n",
      "Chunk 139: second order PCA as a tropical\n",
      "Chunk 140: tropical polytope]\\label{al1}\n",
      "Chunk 141: %\\qquad\n",
      "\\begin{algorithmic}\n",
      "\\State Stochastic\n",
      "Chunk 142: optimization algorithm to fit\n",
      "Chunk 143: $\\mathcal P$ to $D^{(i)}\n",
      "Chunk 144: $D^{(i)}$.\n",
      "\\State Fix an ordered set\n",
      "Chunk 145: $V = (D^{(1)}, D^{(2)}, D^{(3)})$ and compute\n",
      "Chunk 146: $\\mathcal P = \\text{tconv}(V)\n",
      "Chunk 147: $. \n",
      "\\Repeat:\n",
      "\t\\State Sample three datapoints\n",
      "Chunk 148: $D^{(j_1)}, D^{(j_2)}, D^{(j_3)}\n",
      "Chunk 149: $ randomly from the set of all datapoints.\n",
      "\t\\State\n",
      "Chunk 150: Let\n",
      "Chunk 151: $V' = \\{D^{(j_1)}, D^{(j_2)}, D^{(j_3)}\\}\n",
      "Chunk 152: $.\n",
      "\t\\State Compute\n",
      "Chunk 153: $d(\\mathcal P') = d(\\text{tconv}(V'))\n",
      "Chunk 154: $.\n",
      "\t\\State if $d(\\mathcal P)>d(\\mathcal P'),$ set\n",
      "Chunk 155: $ set $V \\gets V'\n",
      "Chunk 156: $.\n",
      "\\Until\n",
      "Chunk 157: convergence.\n",
      "\\end{algorithmic}\n",
      "\\end{algorithm}\n",
      "\n",
      "A\n",
      "Chunk 158: orithm}\n",
      "\n",
      "As\n",
      "Chunk 159: before, convergence can be assessed by\n",
      "Chunk 160: by considering whether a new choice of\n",
      "Chunk 161: $V\n",
      "Chunk 162: $ has been found over a fixed number of previous\n",
      "Chunk 163: previous iterations. If computational time is\n",
      "Chunk 164: time is limited, another approach might simply be\n",
      "Chunk 165: simply be to prespecify a total number\n",
      "Chunk 166: $t\n",
      "Chunk 167: $ of samples. And of course, when the\n",
      "Chunk 168: when the computational cost is reasonable one\n",
      "Chunk 169: one could enumerate through all\n",
      "Chunk 170: $\\binom n 3\n",
      "Chunk 171: $ different choices for the generating points of\n",
      "Chunk 172: $\\mathcal P\n",
      "Chunk 173: $ instead of sampling.\n",
      "\n",
      "\\begin{remark}\n",
      "Three data\n",
      "Chunk 174: data points\n",
      "Chunk 175: $D^{(j_1)}, D^{(j_2)},$ and $D^{(j_3)}\n",
      "Chunk 176: $ define both a Stiefel tropical linear space $L_p\n",
      "Chunk 177: $L_p$ and a tropical polytope $\\mathcal P\n",
      "Chunk 178: $. Because Stiefel tropical linear spaces are\n",
      "Chunk 179: are tropically convex, and each of the generating\n",
      "Chunk 180: points is contained in\n",
      "Chunk 181: $L_p$, we see that $\\mathcal P\\subseteq L_p\n",
      "Chunk 182: $. In particular, given the same convergence\n",
      "Chunk 183: criteria, we should expect Algorithm\n",
      "Chunk 184: Algorithm \\ref{tropical-linear-space-algorithm}\n",
      "Chunk 185: to provide a somewhat better fit than Algorithm\n",
      "Chunk 186: \\ref{al1}.\n",
      "\\end{remark}\n",
      "\n",
      "\\begin{remark}\n",
      "Note that\n",
      "Chunk 187: that Algorithm \\ref{al1} is well-suited for\n",
      "Chunk 188: for applications to phylogenetics. Because\n",
      "Chunk 189: $\\mathcal U_m\n",
      "Chunk 190: $ is a tropical linear space (Theorem\n",
      "Chunk 191: (Theorem \\ref{ultrametrics}) and tropical linear\n",
      "Chunk 192: linear spaces are tropically convex, the solution\n",
      "Chunk 193: solution set\n",
      "Chunk 194: $\\mathcal P = \\text{tconv}(D^{(1)},D^{(2)},\n",
      "Chunk 195: D^{(3)})\n",
      "Chunk 196: $ obtained from Algorithm \\ref{al1} will be\n",
      "Chunk 197: will be contained in the space of ultrametrics.\n",
      "Chunk 198: In particular, projections of ultrametrics are\n",
      "Chunk 199: are also ultrametrics.\n",
      "\\end{remark}\n",
      "\n",
      "%\n",
      "Chunk 200: \\begin{remark}\n",
      "% We found examples of best-fit\n",
      "Chunk 201: best-fit tropical polytopes which do not contain\n",
      "Chunk 202: contain all tropical Fermat-Weber points. When\n",
      "Chunk 203: When not constrained in the space of\n",
      "Chunk 204: space of ultrametrics, suppose we have three\n",
      "Chunk 205: three points \n",
      "%\n",
      "Chunk 206: $$(0,2,5),(0,0,0),(0,3,1)\n",
      "Chunk 207: $\n",
      "Chunk 208: $\n",
      "% and the Fermat-Weber points of these three\n",
      "Chunk 209: three points are shown in \\cite{LY} Figure 1,\n",
      "Chunk 210: Figure 1, which is also shown below, the blue\n",
      "Chunk 211: the blue closed triangle with vertices \n",
      "%\n",
      "Chunk 212: $$(0,1,1),(0,2,1),(0,2,2).\n",
      "Chunk 213: $$ We want to find the best-fit tropocal polytope\n",
      "Chunk 214: $\\mathcal P = \\text{tconv}(D^{(1)}, D^{(2)})\n",
      "Chunk 215: $ of these same three points. And from Proposition\n",
      "Chunk 216: \\ref{polytope_projection}, we know that the\n",
      "Chunk 217: that the minimized sum of projection distances\n",
      "Chunk 218: distances should be 3. For one Fermet-Weber point\n",
      "Chunk 219: point\n",
      "Chunk 220: $(0,2,1)$, we can have\n",
      "Chunk 221: $\\mathcal P^{'} = \\text{tconv}((0,2,1), (0,2,5))\n",
      "Chunk 222: $ which leads to the sum of projection distances\n",
      "Chunk 223: distances to be 3, then point\n",
      "Chunk 224: $(0,2,1)\n",
      "Chunk 225: $ is within the best-fit tropical polytope. But\n",
      "Chunk 226: But for one Fermet-Weber point\n",
      "Chunk 227: $(0,2,2)$, we can't have\n",
      "Chunk 228: $\\mathcal P^{*} = \\text{tconv}((0,2,2), D^{(2)})\n",
      "Chunk 229: $ which leads to the sum of projection distances\n",
      "Chunk 230: distances to be 3, i.e. for any choice of\n",
      "Chunk 231: $D^{(2)}$, the sum of projection distances onto\n",
      "Chunk 232: $\\mathcal P^{*}\n",
      "Chunk 233: $ is always greater than 3. Then we can see this\n",
      "Chunk 234: see this Fermat-Weber point\n",
      "Chunk 235: $(0,2,2)\n",
      "Chunk 236: $ is not within the best-fit tropical polytope.\n",
      "%\n",
      "Chunk 237: \\begin{figure}[!ht]\n",
      "% \\centering\n",
      "%\n",
      "Chunk 238: \\includegraphics[width=0.4\\linewidth]{fw_exam.pdf\n",
      "Chunk 239: w_exam.pdf}\n",
      "%\n",
      "Chunk 240: \\caption{Example where best-fit tropical\n",
      "Chunk 241: tropical polytopes do not contain all tropical\n",
      "Chunk 242: tropical Fermat-Weber points}\n",
      "%\n",
      "Chunk 243: %\\label{sim_topology}\n",
      "% \\end{figure}\n",
      "\n",
      "%\n",
      "Chunk 244: \\end{remark}------Wrong\n",
      "Chunk 245: example.\n",
      "\n",
      "\\section{Simulations}\\label{sim}\n",
      "\n",
      "In\n",
      "Chunk 246: this section, we apply the previous results to\n",
      "Chunk 247: to simulated datasets coming from phylogenetics.\n",
      "Chunk 248: \\subsection{Exact methods}\n",
      "\n",
      "We begin by\n",
      "Chunk 249: begin by identifying the exact best-fit tropical\n",
      "Chunk 250: tropical polytope with three vertices closest to\n",
      "Chunk 251: to a small dataset of equidistant trees using\n",
      "Chunk 252: using Proposition \\ref{polytope_projection}. We\n",
      "Chunk 253: We implemented this proposition mainly based on a\n",
      "Chunk 254: on a {\\tt R} interface to the popular\n",
      "Chunk 255: popular optimization software {\\tt IBM ILOG\n",
      "Chunk 256: IBM ILOG CPLEX}, called {\\tt\n",
      "Chunk 257: cplexAPI}.\n",
      "\n",
      "\\begin{example}\\label{polytope_exampl\n",
      "Chunk 258: ope_example}\n",
      "We\n",
      "Chunk 259: randomly generated 6 equidistant trees with 3\n",
      "Chunk 260: with 3 leaves and computed their vectorized\n",
      "Chunk 261: distance matrices in Figure \\ref{figure 1} and\n",
      "Chunk 262: 1} and Table \\ref{table 1}.\n",
      "Chunk 263: \\begin{figure}[!ht]\n",
      "\\begin{floatrow}\n",
      "\\ffigbox{%\n",
      "Chunk 264: \\ffigbox{%\n",
      "Chunk 265: \\includegraphics[width=0.9\\linewidth]{Rplot1.pdf}\n",
      "Chunk 266: plot1.pdf}\n",
      "}{%\n",
      "Chunk 267: \\caption{Random Sample of Trees}%\n",
      "Chunk 268: Trees}%\n",
      "  \\label{figure 1}\n",
      "}\n",
      "\\capbtabbox{%\n",
      "Chunk 269: \\begin{tabular}[b]{cccc}\n",
      "\t\\hline\\hline\n",
      "Chunk 270: tree1 & 0.69089925 & 7.022836 & 7.022836\\\\\n",
      "Chunk 271: \\hline\n",
      "     tree2 & 0.53495974 & 1.641369 &\n",
      "Chunk 272: & 1.641369\\\\\n",
      "     \\hline\n",
      "     tree3 & 0.02082164\n",
      "Chunk 273: & 3.101557 & 3.101557\\\\\n",
      "     \\hline\n",
      "     tree4 &\n",
      "Chunk 274: tree4 & 0.23519336 & 3.968678 & 3.968678\\\\\n",
      "Chunk 275: \\hline\n",
      "     tree5 & 0.19730562 & 5.960980 &\n",
      "Chunk 276: & 5.960980\\\\\n",
      "     \\hline\n",
      "     tree6 & 0.73804678\n",
      "Chunk 277: & 1.090399 & 1.090399\\\\\n",
      "     \\hline\\hline\n",
      "Chunk 278: \\end{tabular}\n",
      "}{%\n",
      "  \\caption{Vectorized\n",
      "Chunk 279: Distance Matrices}%\n",
      "  \\label{table\n",
      "Chunk 280: 1}\n",
      "}\n",
      "\\end{floatrow}\n",
      "\\end{figure}\n",
      "\n",
      "\\begin{figure}[\n",
      "Chunk 281: n{figure}[!ht]\n",
      "\\begin{floatrow}\n",
      "\\ffigbox{%\n",
      "Chunk 282: \\includegraphics[width=0.9\\linewidth]{simtr3.pdf}\n",
      "Chunk 283: imtr3.pdf}\n",
      "}{%\n",
      "Chunk 284: \\caption{\n",
      "Chunk 285: $D^{(1)},D^{(2)},D^{(3)}\n",
      "Chunk 286: $}%\n",
      "  \\label{figure 2}\n",
      "}\n",
      "\\capbtabbox{%\n",
      "Chunk 287: \\begin{tabular}[b]{cccc}\n",
      "\t\\hline\\hline\n",
      "Chunk 288: $D^{(1)}\n",
      "Chunk 289: $ & 1 & 1.352352 & 1.352352\\\\\n",
      "     \\hline\n",
      "Chunk 290: $D^{(2)}\n",
      "Chunk 291: $ & 1 & 2.106409 & 2.106409\\\\\n",
      "     \\hline\n",
      "Chunk 292: $D^{(3)}\n",
      "Chunk 293: $ & 1 & 7.331937 & 7.331937\\\\\n",
      "     \\hline\\hline\n",
      "Chunk 294: \\end{tabular}\n",
      "}{%\n",
      "  \\caption{Vectorized\n",
      "Chunk 295: Distance Matrices}%\n",
      "  \\label{table\n",
      "Chunk 296: 2}\n",
      "}\n",
      "\\end{floatrow}\n",
      "\\end{figure}\n",
      "\n",
      "Using our\n",
      "Chunk 297: our optimization problem formulation from\n",
      "Chunk 298: from Proposition \\ref{polytope_projection}, we\n",
      "Chunk 299: we obtain\n",
      "Chunk 300: $D^{(1)},D^{(2)},D^{(3)}\n",
      "Chunk 301: $ for this example. These points are ultrametrics,\n",
      "Chunk 302: and they are described in Figure \\ref{figure 2}\n",
      "Chunk 303: 2} and Table \\ref{table 2}. In fact, in this case\n",
      "Chunk 304: this case the best-fit tropical polytope contains\n",
      "Chunk 305: contains all the equidistant trees, so that the\n",
      "Chunk 306: that the sum of distances is\n",
      "Chunk 307: is zero.\n",
      "\\end{example}\n",
      "\n",
      "\\subsection{Approximative\n",
      "Chunk 308: algorithms}\n",
      "For larger datasets, we turn to the\n",
      "Chunk 309: to the approximative Algorithms\n",
      "Chunk 310: \\ref{tropical-linear-space-algorithm} and\n",
      "Chunk 311: and \\ref{al1}. We implemented both algorithms in\n",
      "Chunk 312: in {\\tt R}.\\footnote{Our software for all\n",
      "Chunk 313: for all computations can be downloaded at\n",
      "Chunk 314: \\url{http://polytopes.net/computations/tropicalPC\n",
      "Chunk 315: tropicalPCA/}.}\n",
      "Chunk 316: We then generated a random sample from {\\tt\n",
      "Chunk 317: from {\\tt Mesquite} \\cite{Mesq} and applied our\n",
      "Chunk 318: our algorithms on this dataset. The sample was\n",
      "Chunk 319: was constructed as\n",
      "Chunk 320: as follows:\n",
      "\\begin{algorithm}[Generating the\n",
      "Chunk 321: the simulation dataset]\\label{sim_data}\n",
      "Chunk 322: \\qquad  \\qquad\n",
      "Chunk 323: \\qquad \\qquad \n",
      "\n",
      "\\begin{enumerate}\n",
      "\\item Generate\n",
      "Chunk 324: Generate 250 gene trees with 8 leaves from the\n",
      "Chunk 325: from the coalescent model under a fixed species\n",
      "Chunk 326: species tree with depth equal to 10 \n",
      "\\item\n",
      "Chunk 327: 10 \n",
      "\\item Transform the gene trees to be\n",
      "Chunk 328: to be ultrametrics.\n",
      "\\item Compute approximate\n",
      "Chunk 329: second order tropical principal components via\n",
      "Chunk 330: via the Algorithms\n",
      "Chunk 331: \\ref{tropical-linear-space-algorithm} and\n",
      "Chunk 332: \\ref{al1}.\n",
      "\\end{enumerate}\n",
      "\\end{algorithm}\n",
      "\n",
      "We\n",
      "Chunk 333: applied both methods of tropical principal\n",
      "Chunk 334: principal component analysis to a set of random\n",
      "Chunk 335: of random trees generated by Algorithm\n",
      "Chunk 336: Algorithm \\ref{sim_data}. In analogy with\n",
      "Chunk 337: with \\cite{NTWY}, we define summary statistics to\n",
      "Chunk 338: to describe the fit of a Stiefel tropical linear\n",
      "Chunk 339: linear space\n",
      "or a tropical polytope to a given\n",
      "Chunk 340: a given data\n",
      "set. If\n",
      "Chunk 341: $L_p\n",
      "Chunk 342: $ is a Stiefel tropical linear space, we define\n",
      "Chunk 343: we define its distance to the datapoints\n",
      "Chunk 344: $d(L_p)\n",
      "Chunk 345: $ as\n",
      "\\[d(L_p) = \\sum_i d(D^{(i)}, L_p),\\]\n",
      "and a\n",
      "Chunk 346: a tropical proportion of variance\n",
      "Chunk 347: variance statistic\n",
      "\\[r(L_p) = \\frac{\\sum_i\n",
      "Chunk 348: d_{tr}(\\bar \\pi, \\pi_{L_p}(D^{(i)}))}{\\sum_i\n",
      "Chunk 349: d_{tr}(D^{(i)}, \\pi_{L_p}(D^{(i)})+\\sum_i\n",
      "Chunk 350: d_{tr}(\\bar \\pi, \\pi_{L_p}(D^{(i)}))}\\]\n",
      "where\n",
      "Chunk 351: $\\bar \\pi\n",
      "Chunk 352: $ denotes a Fermat-Weber point of the projections\n",
      "Chunk 353: of the datapoints, as in \\cite{LY}. These\n",
      "Chunk 354: These statistics are defined analogously for a\n",
      "Chunk 355: for a tropical polytope\n",
      "Chunk 356: $\\mathcal P$. The statistic $r(L_p)\n",
      "Chunk 357: $ can be interpreted as the proportion of variance\n",
      "Chunk 358: variance explained by\n",
      "Chunk 359: $L_p\n",
      "Chunk 360: $; in order to remain consistent with the tropical\n",
      "Chunk 361: tropical metric, we sum distances rather than\n",
      "Chunk 362: than squared distances. \n",
      "\n",
      "For the polytopal\n",
      "Chunk 363: polytopal approach, as noted above, the\n",
      "Chunk 364: the projections will remain ultrametrics. We\n",
      "Chunk 365: We therefore analyze the topologies of these\n",
      "Chunk 366: of these projections, and compare them with the\n",
      "Chunk 367: with the topology of the species\n",
      "Chunk 368: species tree.\n",
      "\n",
      "\\subsection{Approximation\n",
      "Chunk 369: results}\n",
      "\n",
      "We applied Algorithm\n",
      "Chunk 370: Algorithm \\ref{tropical-linear-space-algorithm}\n",
      "Chunk 371: to find an approximate 2-dimensional best-fit\n",
      "Chunk 372: best-fit Stiefel tropical linear space with a\n",
      "Chunk 373: with a convergence threshold of 100 iterations.\n",
      "Chunk 374: The summary statistics for this run were:\n",
      "Chunk 375: $d(L_p)=363.0378$ and $r(L_p) = 0.322\n",
      "Chunk 376: $.\n",
      "\n",
      "We also applied a variant of Algorithm\n",
      "Chunk 377: Algorithm \\ref{al1} to find an approximate\n",
      "Chunk 378: best-fit tropical polytope with three vertices,\n",
      "Chunk 379: vertices, in which we enumerated through all\n",
      "Chunk 380: $\\binom{250}{3}\n",
      "Chunk 381: $ different choices. The summary statistics were:\n",
      "Chunk 382: $d(\\mathcal P) = 360.6831$ and\n",
      "Chunk 383: $ and \n",
      "$r(\\mathcal P) = 0.265\n",
      "Chunk 384: $. We note that the overall sum of distances is\n",
      "Chunk 385: is similar between the two methods, but that the\n",
      "Chunk 386: that the best-fit Stiefel tropical linear space\n",
      "Chunk 387: space explains a slightly higher proportion of\n",
      "Chunk 388: of variance. \n",
      "\n",
      "For the tropical polytope method,\n",
      "Chunk 389: method, we recall that projections of equidistant\n",
      "Chunk 390: trees will remain ultrametrics. We present common\n",
      "Chunk 391: common topologies of the projections as well as\n",
      "Chunk 392: well as the species tree topology\n",
      "in Figure\n",
      "Chunk 393: Figure \\ref{sim_topology}.\\footnote{Tree\n",
      "Chunk 394: topologies of all projected\n",
      "points can be found\n",
      "Chunk 395: be found in the supplement \n",
      "at\n",
      "Chunk 396: \\url{http://polytopes.net/computations/tropicalPC\n",
      "Chunk 397: tropicalPCA/}.}\n",
      "We\n",
      "Chunk 398: observe that these topologies of\n",
      "projected trees\n",
      "Chunk 399: trees are broadly consistent with the topology of\n",
      "Chunk 400: of the species tree\n",
      "under which these gene trees\n",
      "Chunk 401: trees were generated: taxa\n",
      "Chunk 402: $g$ and $c$ group\n",
      "together, as do taxa $h$ and $f\n",
      "Chunk 403: $h$ and $f$, and the four taxa $a$, $b$, $d$, $e\n",
      "Chunk 404: $ also group together. We can view our best-fit\n",
      "Chunk 405: best-fit tropical polytope as preserving these\n",
      "Chunk 406: these features of the species tree, meaning that\n",
      "Chunk 407: that this tropical polytope retains information\n",
      "Chunk 408: after\n",
      "Chunk 409: projection.\n",
      "\\begin{figure}[!ht]\n",
      "\\centering\n",
      "\\inclu\n",
      "Chunk 410: ing\n",
      "\\includegraphics[width=0.6\\linewidth]{proj_sim\n",
      "Chunk 411: ]{proj_sim_250_8_topology.pdf}\n",
      "Chunk 412: \\caption{Topology frequencies after projections:\n",
      "Chunk 413: the parenthesized numbers are frequencies, and\n",
      "Chunk 414: and the last tree gives the species tree\n",
      "Chunk 415: tree topology.}\n",
      "Chunk 416: \\label{sim_topology}\n",
      "\\end{figure}\n",
      "\n",
      "\\section{Apico\n",
      "Chunk 417: tion{Apicomplexa\n",
      "Chunk 418: genome}\\label{apicomplexa}\n",
      "\n",
      "We also applied our\n",
      "Chunk 419: our tropical principal component algorithms to a\n",
      "Chunk 420: to a set of trees constructed from\n",
      "Chunk 421: from 252\n",
      "orthologous sequences on eight species\n",
      "Chunk 422: species of protozoa in the\n",
      "Apicomplexa phylum by\n",
      "Chunk 423: phylum by \\cite{KWK}.   \n",
      "This dataset was also\n",
      "Chunk 424: was also analyzed by Weyenberg et.~al; one can\n",
      "Chunk 425: one can find\n",
      "more details, such as the gene\n",
      "Chunk 426: the gene sequences, in \\cite{KDETrees}.\n",
      "Because\n",
      "Chunk 427: ordinary PCA is sensitive to outliers, we removed\n",
      "Chunk 428: removed 16 outlier gene trees identified by\n",
      "Chunk 429: by \\cite{KDETrees} before fitting the tropical\n",
      "Chunk 430: tropical principal components.\n",
      "\n",
      "To find an\n",
      "Chunk 431: find an approximate best-fit 2-dimensional\n",
      "Chunk 432: Stiefel tropical linear space, we applied\n",
      "Chunk 433: applied Algorithm\n",
      "Chunk 434: Algorithm \\ref{tropical-linear-space-algorithm}\n",
      "Chunk 435: with a convergence threshold of 100 iterations.\n",
      "Chunk 436: Due to the stochastic nature of the algorithm, we\n",
      "Chunk 437: we executed the algorithm three times. %Tree\n",
      "Chunk 438: %Tree topologies from a representative execution\n",
      "Chunk 439: execution are presented in Table\n",
      "Chunk 440: in Table \\ref{apicomplexa-tropical-linear-space}.\n",
      "Chunk 441: We note the close similarity between the most\n",
      "Chunk 442: the most common tree topology with the\n",
      "Chunk 443: with the generally-accepted phylogeny of these\n",
      "Chunk 444: of these eight taxa \\cite[Figure 1]{KWK}. \n",
      "The\n",
      "Chunk 445: The summary statistics remained consistent\n",
      "Chunk 446: between these runs. For one representative\n",
      "Chunk 447: execution, these statistics were:\n",
      "Chunk 448: $d(L_p) = 145.38$ and $r(L_p)=0.616\n",
      "Chunk 449: $. % In general, furthermore, projected topologies\n",
      "Chunk 450: were largely congruent with the generally\n",
      "Chunk 451: generally accepted phylogeny: the two Plasmodium\n",
      "Chunk 452: species (Pv and Pf) group together, as do Ta and\n",
      "Chunk 453: do Ta and Bb; and Tt is isolated on a deep\n",
      "Chunk 454: branch.\n",
      "\n",
      "\\begin{comment}\\begin{table}\n",
      "\\centering\n",
      "Chunk 455: centering\n",
      "\\caption{Tree\n",
      "Chunk 456: topologies and frequency counts for  apicomplexa\n",
      "Chunk 457: gene tree\n",
      "Chunk 458: projections}\n",
      "\\label{apicomplexa-tropical-linear-s\n",
      "Chunk 459: l-linear-space}\n",
      "\\begin{tabular}{|c|c|c|c|}\n",
      "\\hline\n",
      "Chunk 460: |}\n",
      "\\hline\n",
      "Count\n",
      "Chunk 461: & Topology & Count & Topology\\\\\\hline\n",
      "112 &\n",
      "Chunk 462: \\includegraphics[height=1.65in]{apicomplexa-tree3\n",
      "Chunk 463: lexa-tree3.png}\n",
      "Chunk 464: & 31 &\n",
      "Chunk 465: \\includegraphics[height=1.65in]{apicomplexa-tree1\n",
      "Chunk 466: lexa-tree13.png}\\\\\n",
      "Chunk 467: \\hline\n",
      "30 &\n",
      "Chunk 468: \\includegraphics[height=1.65in]{apicomplexa-tree9\n",
      "Chunk 469: lexa-tree9.png}\n",
      "Chunk 470: & 26 &\n",
      "Chunk 471: \\includegraphics[height=1.65in]{apicomplexa-tree1\n",
      "Chunk 472: lexa-tree1.png}\\\\\n",
      "Chunk 473: \\hline\n",
      "20 &\n",
      "Chunk 474: \\includegraphics[height=1.65in]{apicomplexa-tree4\n",
      "Chunk 475: lexa-tree4.png}\n",
      "Chunk 476: & 17 &\n",
      "Chunk 477: \\includegraphics[height=1.65in]{apicomplexa-tree2\n",
      "Chunk 478: lexa-tree24.png}\\\\\n",
      "Chunk 479: \\hline\n",
      "8 &\n",
      "Chunk 480: \\includegraphics[height=1.65in]{apicomplexa-tree1\n",
      "Chunk 481: lexa-tree14.png}\n",
      "Chunk 482: & 7 &\n",
      "Chunk 483: \\includegraphics[height=1.65in]{apicomplexa-tree4\n",
      "Chunk 484: lexa-tree43.png}\\\\\n",
      "Chunk 485: \\hline\n",
      "1 &\n",
      "Chunk 486: \\includegraphics[height=1.65in]{apicomplexa-tree2\n",
      "Chunk 487: lexa-tree202.png}\n",
      "Chunk 488: & \\ & \\ \\\\\n",
      "Chunk 489: \\ \\\\ \\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "Comparing\n",
      "Chunk 490: the tropical PC's on tropical topology and\n",
      "Chunk 491: and tropical linear space, we can see that the\n",
      "Chunk 492: that the most three frequent topologies of the\n",
      "Chunk 493: of the projected trees for the apicomplexa data\n",
      "Chunk 494: data (which totally covered more than two thirds\n",
      "Chunk 495: thirds of all trees) are the same for these two\n",
      "Chunk 496: these two methods.\n",
      "\\end{comment}\n",
      "\n",
      "%\n",
      "Chunk 497: \\subsection{African coelacanths genome and\n",
      "Chunk 498: and transcriptome data}\n",
      "% We also have applied\n",
      "Chunk 499: applied tropical PCAs to the dataset consisting\n",
      "Chunk 500: of 1,290\n",
      "% nuclear genes encoding 690,838 amino\n",
      "Chunk 501: amino acid residues obtained from\n",
      "% genome and\n",
      "Chunk 502: and transcriptome data in \\cite{LSZ}. \n",
      "% It has\n",
      "Chunk 503: % It has been much work on the phylogenetic\n",
      "Chunk 504: relations between\n",
      "% coelacanths, lungfishes and\n",
      "Chunk 505: and tetrapods, but still it is not clear\n",
      "%\n",
      "Chunk 506: clear\n",
      "% despite several studies\n",
      "Chunk 507: studies \\cite{Hedges2009}. \n",
      "\n",
      "% Most morphological\n",
      "Chunk 508: and paleontological studies support the\n",
      "Chunk 509: the hypothesis that lungfishes are closer to\n",
      "Chunk 510: closer to tetrapods than they are to coelacanths\n",
      "Chunk 511: \\cite[Fig. 1, Tree 1]{LSZ}.\n",
      "% However, some\n",
      "Chunk 512: some research supports the hypothesis that\n",
      "Chunk 513: that coelacanths are\n",
      "% closer to tetrapods\n",
      "Chunk 514: tetrapods \\cite[Fig. 1, Tree 2]{LSZ}. \n",
      "% Others\n",
      "Chunk 515: % Others support the hypothesis that coelacanths\n",
      "Chunk 516: and lungfishes form a\n",
      "% sister clade \\cite[Fig.\n",
      "Chunk 517: 1, Tree 3]{LSZ}, or that tetrapods,\n",
      "% lungfishes,\n",
      "Chunk 518: and coelacanths cannot be resolved \\cite[Fig.1,\n",
      "Chunk 519: Tree\n",
      "% 4]{LSZ}. \n",
      "\n",
      "% We have used the gene trees\n",
      "Chunk 520: trees used for the PCA under the BHV metric\n",
      "Chunk 521: metric over\n",
      "% the tree space by Nye.~et.~al and\n",
      "Chunk 522: and detailed information such as tree\n",
      "%\n",
      "Chunk 523: as tree\n",
      "% reconstruction method used as well as\n",
      "Chunk 524: well as species names can be found in\n",
      "Chunk 525: found in \\cite{NTWY}.\n",
      "% %\\begin{small}\n",
      "\n",
      "\n",
      "\n",
      "We also\n",
      "Chunk 526: also applied a variant of Algorithm \\ref{al1} to\n",
      "Chunk 527: to find a well-fitted tropical polytope with\n",
      "Chunk 528: with three vertices, enumerating through all\n",
      "Chunk 529: ${\\binom{252}{3}}\n",
      "Chunk 530: $ possibilities. The summary statistics for this\n",
      "Chunk 531: for this run were:\n",
      "Chunk 532: $d(\\mathcal P)= 147.0568$ and\n",
      "Chunk 533: $ and $r(\\mathcal P) = 0.612\n",
      "Chunk 534: $. We note that these summary statistics are\n",
      "Chunk 535: are relatively consistent with the summary\n",
      "Chunk 536: summary statistics obtained from the Stiefel\n",
      "Chunk 537: Stiefel tropical linear space algorithm. \n",
      "\n",
      "The\n",
      "Chunk 538: The tree topologies are presented in Figure\n",
      "Chunk 539: in Figure \\ref{api_topology}. In general, the\n",
      "Chunk 540: the projected topologies were largely congruent\n",
      "Chunk 541: congruent with the generally accepted phylogeny:\n",
      "Chunk 542: the two Plasmodium species (Pv and Pf) group\n",
      "Chunk 543: Pf) group together, as do the four species Ta,\n",
      "Chunk 544: Ta, Bb, Tg, and Et, and Tt is isolated on a deep\n",
      "Chunk 545: on a deep branch. \n",
      "\n",
      "\\cite[Theorem 23]{DS} tells\n",
      "Chunk 546: tells us the tropical convex hull of the rows and\n",
      "Chunk 547: rows and columns of a matrix are equal. This\n",
      "Chunk 548: This allows us to visualize our best-fit tropical\n",
      "Chunk 549: tropical polytope in the two-dimensional plane\n",
      "Chunk 550: $\\mathbb R^3/\\RR {\\bf 1}\n",
      "Chunk 551: $ as the tropical convex hull of 28 points. These\n",
      "Chunk 552: These 28 points divide the polytope into\n",
      "Chunk 553: into different cells, as described in\n",
      "Chunk 554: in \\cite[Example 9]{JSY}. We plot this polytope,\n",
      "Chunk 555: polytope, along with its cells and the\n",
      "Chunk 556: and the projections of our data points, in Figure\n",
      "Chunk 557: in Figure \\ref{api_triangle}.  We note that the\n",
      "Chunk 558: that the different topologies seem to divide the\n",
      "Chunk 559: the tropical polytope PCA into several regions of\n",
      "Chunk 560: of positive area. \n",
      "\n",
      "% \\begin{figure}[!ht]\n",
      "%\n",
      "Chunk 561: \\centering\n",
      "%\n",
      "Chunk 562: \\includegraphics[width=0.5\\linewidth]{proj_api_to\n",
      "Chunk 563: roj_api_topology.pdf}\n",
      "%\n",
      "Chunk 564: \\caption{Projected topology frequencies from\n",
      "Chunk 565: from the Apicomplexa dataset: parenthesized\n",
      "Chunk 566: numbers give the frequencies of each topology.}\n",
      "%\n",
      "Chunk 567: \\label{api_topology}\n",
      "% \\end{figure}\n",
      "\n",
      "%\n",
      "Chunk 568: \\begin{figure}[!ht]\n",
      "% \\centering\n",
      "%\n",
      "Chunk 569: \\includegraphics[width=0.5\\linewidth]{api_approx_\n",
      "Chunk 570: pi_approx_visual.pdf}\n",
      "%\n",
      "Chunk 571: \\caption{Projected points onto the tropical\n",
      "Chunk 572: tropical triangle}\n",
      "%   \\label{api_triangle}\n",
      "%\n",
      "Chunk 573: \\end{figure}\n",
      "\n",
      "\\begin{figure}[!ht]\n",
      "\\includegraphic\n",
      "Chunk 574: udegraphics[width=1\\linewidth]{proj_api_topology.p\n",
      "Chunk 575: topology.png}\n",
      "\\caption{Projected\n",
      "Chunk 576: topology frequencies from the Apicomplexa\n",
      "Chunk 577: dataset: parenthesized numbers give the\n",
      "Chunk 578: give the frequencies of each\n",
      "Chunk 579: topology.}%\n",
      "\\label{api_topology}\n",
      "\\end{figure}\n",
      "\\be\n",
      "Chunk 580: igure}\n",
      "\\begin{figure}[!ht]\n",
      "Chunk 581: \\includegraphics[width=0.6\\linewidth]{api_approx_\n",
      "Chunk 582: pi_approx_visual.pdf}\n",
      "{%\n",
      "\\caption{Projected\n",
      "Chunk 583: points in the tropical polytope PCA, colored as\n",
      "Chunk 584: as in Figure\n",
      "Chunk 585: \\ref{api_topology}.}%\n",
      "\\label{api_triangle}\n",
      "}\n",
      "\\end\n",
      "Chunk 586: le}\n",
      "}\n",
      "\\end{figure}\n",
      "\n",
      "\n",
      "\n",
      "\\section{Discussion}\\label{d\n",
      "Chunk 587: n}\\label{discuss}\n",
      "\n",
      "In\n",
      "Chunk 588: recent decades, the field of phylogenetics has\n",
      "Chunk 589: has found\n",
      "applications in the analysis on g\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(3)}(t) \\le d_i (t), \\forall t=1,2,\\ldots,e,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\ldots,n</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\\\\\nonumber\n",
       "%\\prod_{t=1}^{e}[d_{i}(t)-(\\lambda_p^</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\lambda_p^i+D^{(p)}(t))]=0,\\forall</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">p=1,2,3,</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\ldots,n.\\\\\\nonumber\n",
       "%\\end{eqnarray}\n",
       "%After</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">this reformulation, we're very possibly able to</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">able to use sequential quadratic programming(SQL)</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to solve this optimization</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">problem.\n",
       "%\\end{corollary}\n",
       "\n",
       "\n",
       "\n",
       "%%%%%  We will</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">We will discuss them in DIscussion\n",
       "% Then we can</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">we can ask the following questions:\n",
       "%</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{problem}\n",
       "% Suppose we have a random sample</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sample</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$S \\subset \\Tn$ of saze $n</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.  Then how\n",
       "% often can we get a unique</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">a unique solution?\n",
       "% \\end{problem}\n",
       "%</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{problem}\n",
       "% Comparing with tropical</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical Fermat-Weber points.  Does an (the?)</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">an (the?) optimal\n",
       "% solution for Problem</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Problem \\ref{optimization} contains a tropical\n",
       "%</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Fermat-Weber point of the sample</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$S</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$?  How does it relate to?\n",
       "% Tropical Fermat-Weber</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">points can be found at</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">at \\url{https://arxiv.org/abs/1604.04674}.\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\end{problem}\n",
       "\n",
       "% \\begin{proposition}\n",
       "% With given</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">given a sample</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\{d_1,\\cdots,d_n\\}$, suppose $\\bm{y}</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ is a tropical\n",
       "% Fermat-Weber point of the</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of the sample.  If</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\bm{y}(k) \\leq d_i(k)$ for $k = 1,\n",
       "% \\ldots , e</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ for all $i = 1, \\ldots , n</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$, then the convex hull of</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(1)},\n",
       "% D^{(2)}, D^{(3)} \\in \\Tn</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ obtained from the optimization problem in\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in\n",
       "% Problem \\ref{optimization} contains the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the tropical Fermat-Weber point</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$y</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.\n",
       "% \\end{proposition}\n",
       "% \\begin{proof}\n",
       "% For a</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For a Fermat-Weber points of</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\{d_1,\\ldots,d_n\\}$, it's the solution $\\bm{y}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\bm{y}$ of \n",
       "%</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; \\bm{y}\\in</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\bm{y}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\text{subject to }\\Delta_i \\ge</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ge d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l),\\forall</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\Delta_i \\ge</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-[d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l)],\\forall</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">],\\forall\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "\n",
       "% Suppose we have $\\bm{y}(k) \\leq d_i(k)$ for</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ for $k = 1,\n",
       "% \\ldots , e$ for all</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ for all $i = 1, \\ldots , n</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.  Then we have the system:\n",
       "%</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR; \\bm{y}\\in</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\bm{y}\\in \\RR^e;}\\sum_{i=1}^{n}\\Delta_i</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\text{subject to }\\Delta_i \\ge</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ge d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l),\\forall</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\Delta_i \\ge</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-[d_{i}(k)-\\bm{y}(k)-d_{i}(l)+\\bm{y}(l)],\\forall</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">],\\forall\n",
       "%</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\bm{y}(k) \\leq d_i(k), \\, \\forall i 1, 2, \\cdots</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">2, \\cdots , n \\text{ and } k\n",
       "% = 1, 2, \\cdots ,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\cdots , e.\n",
       "%</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\n",
       "% This is equivalent to the system in</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">system in \\eqref{trop:polytope}.\n",
       "% here, for</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">here, for different</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\Delta_i$ in the constraints, the target vector</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\bm{y}</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ isn't changing with i.\\\\\n",
       "% \\\\\n",
       "% For the same</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the same sample</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\{d_1,\\cdots,d_n\\}$, we look at the solution \\{</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d_1^{'},d_2^{'},\\cdots,d_n^{'}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\} of the formula (4),\n",
       "%</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\min_{\\Delta_1,\\ldots,\\Delta_n \\in \\RR;</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\in \\RR; d^{'}_{1},\\ldots,d^{'}_{n}\\in</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\RR^e;}\\sum_{i=1}^{n}\\Delta_i</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\text{subject to }\\Delta_i \\ge</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">d_{i}(k)-d^{'}_{i}(k)-d_{i}(l)+d^{'}_{i}(l),\\fora</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">}(l),\\forall</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "%</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\Delta_i \\ge</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-[d_{i}(k)-d^{'}_{i}(k)-d_{i}(l)+d^{'}_{i}(l)],\\f</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">{i}(l)],\\forall</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i=1,2,\\cdots,n \\text{ and } 1\\le k < l \\le e</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$\n",
       "% (there're no extra constraints on $d_i^{'}</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$'s)\n",
       "% which is very similar to the optimiaztion</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">problem of Fermat-Weber points.\n",
       "% But here, for</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">here, for different</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\Delta_i$, the constraining vector $d_i^{'}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d_i^{'}$ can be different.\\\\\n",
       "% Then if we choose</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$n$ $\\bm{y}</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$'s from the space of Fermant-Weber points</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">points (repeats allowed), they must be one</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">be one solution of formula (4). But conversely,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for one solution \\{</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d_1^{'},\\ldots,d_n^{'}</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\} of formula (4), possibly not every $d_i^{'}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d_i^{'}$ is Fermat-Weber point of $d_1,\\ldots,d_n</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. \n",
       "%\\end{proof}\n",
       "\n",
       "\\subsection{Heuristic</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">approximation}\n",
       "As noted above, the number of</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">number of variables in the mixed integer linear</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">linear programming problem in Proposition</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{polytope_projection} increases quickly with</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with the number of leaves and data points.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">points. Because solving mixed linear</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">linear integer\n",
       "programming is NP-hard</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">NP-hard \\cite{Lenstra},\n",
       "this problem is difficult</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">difficult to solve in practice. In analogy with</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with Algorithm</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Algorithm \\ref{tropical-linear-space-algorithm},</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">therefore, we develop a heuristic method for</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for approximating the optimal solution for the</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for the problem in Proposition</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{polytope_projection}.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{algorithm}[Approximation for the second</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">second order PCA as a tropical</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical polytope]\\label{al1}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">%\\qquad\n",
       "\\begin{algorithmic}\n",
       "\\State Stochastic</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimization algorithm to fit</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P$ to $D^{(i)}</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(i)}$.\n",
       "\\State Fix an ordered set</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$V = (D^{(1)}, D^{(2)}, D^{(3)})$ and compute</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P = \\text{tconv}(V)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. \n",
       "\\Repeat:\n",
       "\t\\State Sample three datapoints</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(j_1)}, D^{(j_2)}, D^{(j_3)}</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ randomly from the set of all datapoints.\n",
       "\t\\State</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Let</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$V' = \\{D^{(j_1)}, D^{(j_2)}, D^{(j_3)}\\}</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.\n",
       "\t\\State Compute</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d(\\mathcal P') = d(\\text{tconv}(V'))</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.\n",
       "\t\\State if $d(\\mathcal P)>d(\\mathcal P'),$ set</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ set $V \\gets V'</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.\n",
       "\\Until</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">convergence.\n",
       "\\end{algorithmic}\n",
       "\\end{algorithm}\n",
       "\n",
       "A</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">orithm}\n",
       "\n",
       "As</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">before, convergence can be assessed by</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">by considering whether a new choice of</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$V</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ has been found over a fixed number of previous</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">previous iterations. If computational time is</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">time is limited, another approach might simply be</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">simply be to prespecify a total number</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$t</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ of samples. And of course, when the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">when the computational cost is reasonable one</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">one could enumerate through all</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\binom n 3</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ different choices for the generating points of</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ instead of sampling.\n",
       "\n",
       "\\begin{remark}\n",
       "Three data</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">data points</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(j_1)}, D^{(j_2)},$ and $D^{(j_3)}</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ define both a Stiefel tropical linear space $L_p</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$L_p$ and a tropical polytope $\\mathcal P</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. Because Stiefel tropical linear spaces are</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">are tropically convex, and each of the generating</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">points is contained in</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$L_p$, we see that $\\mathcal P\\subseteq L_p</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. In particular, given the same convergence</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">criteria, we should expect Algorithm</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Algorithm \\ref{tropical-linear-space-algorithm}</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to provide a somewhat better fit than Algorithm</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{al1}.\n",
       "\\end{remark}\n",
       "\n",
       "\\begin{remark}\n",
       "Note that</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that Algorithm \\ref{al1} is well-suited for</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for applications to phylogenetics. Because</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal U_m</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ is a tropical linear space (Theorem</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(Theorem \\ref{ultrametrics}) and tropical linear</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">linear spaces are tropically convex, the solution</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">solution set</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P = \\text{tconv}(D^{(1)},D^{(2)},</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">D^{(3)})</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ obtained from Algorithm \\ref{al1} will be</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">will be contained in the space of ultrametrics.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">In particular, projections of ultrametrics are</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">are also ultrametrics.\n",
       "\\end{remark}\n",
       "\n",
       "%</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{remark}\n",
       "% We found examples of best-fit</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">best-fit tropical polytopes which do not contain</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">contain all tropical Fermat-Weber points. When</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">When not constrained in the space of</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">space of ultrametrics, suppose we have three</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">three points \n",
       "%</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$(0,2,5),(0,0,0),(0,3,1)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\n",
       "% and the Fermat-Weber points of these three</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">three points are shown in \\cite{LY} Figure 1,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Figure 1, which is also shown below, the blue</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the blue closed triangle with vertices \n",
       "%</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$(0,1,1),(0,2,1),(0,2,2).</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$$ We want to find the best-fit tropocal polytope</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P = \\text{tconv}(D^{(1)}, D^{(2)})</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ of these same three points. And from Proposition</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{polytope_projection}, we know that the</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that the minimized sum of projection distances</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">distances should be 3. For one Fermet-Weber point</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">point</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$(0,2,1)$, we can have</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P^{'} = \\text{tconv}((0,2,1), (0,2,5))</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ which leads to the sum of projection distances</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">distances to be 3, then point</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$(0,2,1)</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ is within the best-fit tropical polytope. But</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">But for one Fermet-Weber point</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$(0,2,2)$, we can't have</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P^{*} = \\text{tconv}((0,2,2), D^{(2)})</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ which leads to the sum of projection distances</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">distances to be 3, i.e. for any choice of</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(2)}$, the sum of projection distances onto</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P^{*}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ is always greater than 3. Then we can see this</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">see this Fermat-Weber point</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$(0,2,2)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ is not within the best-fit tropical polytope.\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{figure}[!ht]\n",
       "% \\centering\n",
       "%</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[width=0.4\\linewidth]{fw_exam.pdf</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">w_exam.pdf}\n",
       "%</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\caption{Example where best-fit tropical</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical polytopes do not contain all tropical</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical Fermat-Weber points}\n",
       "%</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">%\\label{sim_topology}\n",
       "% \\end{figure}\n",
       "\n",
       "%</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\end{remark}------Wrong</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">example.\n",
       "\n",
       "\\section{Simulations}\\label{sim}\n",
       "\n",
       "In</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">this section, we apply the previous results to</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to simulated datasets coming from phylogenetics.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\subsection{Exact methods}\n",
       "\n",
       "We begin by</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">begin by identifying the exact best-fit tropical</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical polytope with three vertices closest to</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to a small dataset of equidistant trees using</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">using Proposition \\ref{polytope_projection}. We</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">We implemented this proposition mainly based on a</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">on a {\\tt R} interface to the popular</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">popular optimization software {\\tt IBM ILOG</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">IBM ILOG CPLEX}, called {\\tt</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">cplexAPI}.\n",
       "\n",
       "\\begin{example}\\label{polytope_exampl</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ope_example}\n",
       "We</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">randomly generated 6 equidistant trees with 3</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with 3 leaves and computed their vectorized</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">distance matrices in Figure \\ref{figure 1} and</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">1} and Table \\ref{table 1}.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{figure}[!ht]\n",
       "\\begin{floatrow}\n",
       "\\ffigbox{%</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ffigbox{%</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[width=0.9\\linewidth]{Rplot1.pdf}</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">plot1.pdf}\n",
       "}{%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\caption{Random Sample of Trees}%</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Trees}%\n",
       "  \\label{figure 1}\n",
       "}\n",
       "\\capbtabbox{%</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{tabular}[b]{cccc}\n",
       "\t\\hline\\hline</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tree1 & 0.69089925 & 7.022836 & 7.022836\\\\</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\hline\n",
       "     tree2 & 0.53495974 & 1.641369 &</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 1.641369\\\\\n",
       "     \\hline\n",
       "     tree3 & 0.02082164</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 3.101557 & 3.101557\\\\\n",
       "     \\hline\n",
       "     tree4 &</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tree4 & 0.23519336 & 3.968678 & 3.968678\\\\</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\hline\n",
       "     tree5 & 0.19730562 & 5.960980 &</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 5.960980\\\\\n",
       "     \\hline\n",
       "     tree6 & 0.73804678</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 1.090399 & 1.090399\\\\\n",
       "     \\hline\\hline</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\end{tabular}\n",
       "}{%\n",
       "  \\caption{Vectorized</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Distance Matrices}%\n",
       "  \\label{table</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">1}\n",
       "}\n",
       "\\end{floatrow}\n",
       "\\end{figure}\n",
       "\n",
       "\\begin{figure}[</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">n{figure}[!ht]\n",
       "\\begin{floatrow}\n",
       "\\ffigbox{%</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[width=0.9\\linewidth]{simtr3.pdf}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">imtr3.pdf}\n",
       "}{%</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\caption{</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(1)},D^{(2)},D^{(3)}</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$}%\n",
       "  \\label{figure 2}\n",
       "}\n",
       "\\capbtabbox{%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{tabular}[b]{cccc}\n",
       "\t\\hline\\hline</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(1)}</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ & 1 & 1.352352 & 1.352352\\\\\n",
       "     \\hline</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(2)}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ & 1 & 2.106409 & 2.106409\\\\\n",
       "     \\hline</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(3)}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ & 1 & 7.331937 & 7.331937\\\\\n",
       "     \\hline\\hline</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\end{tabular}\n",
       "}{%\n",
       "  \\caption{Vectorized</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Distance Matrices}%\n",
       "  \\label{table</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">2}\n",
       "}\n",
       "\\end{floatrow}\n",
       "\\end{figure}\n",
       "\n",
       "Using our</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">our optimization problem formulation from</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from Proposition \\ref{polytope_projection}, we</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">we obtain</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$D^{(1)},D^{(2)},D^{(3)}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ for this example. These points are ultrametrics,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and they are described in Figure \\ref{figure 2}</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">2} and Table \\ref{table 2}. In fact, in this case</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">this case the best-fit tropical polytope contains</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">contains all the equidistant trees, so that the</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that the sum of distances is</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is zero.\n",
       "\\end{example}\n",
       "\n",
       "\\subsection{Approximative</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">algorithms}\n",
       "For larger datasets, we turn to the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to the approximative Algorithms</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{tropical-linear-space-algorithm} and</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and \\ref{al1}. We implemented both algorithms in</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in {\\tt R}.\\footnote{Our software for all</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for all computations can be downloaded at</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\url{http://polytopes.net/computations/tropicalPC</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropicalPCA/}.}</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">We then generated a random sample from {\\tt</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from {\\tt Mesquite} \\cite{Mesq} and applied our</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">our algorithms on this dataset. The sample was</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">was constructed as</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">as follows:\n",
       "\\begin{algorithm}[Generating the</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the simulation dataset]\\label{sim_data}</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\qquad  \\qquad</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\qquad \\qquad \n",
       "\n",
       "\\begin{enumerate}\n",
       "\\item Generate</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Generate 250 gene trees with 8 leaves from the</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from the coalescent model under a fixed species</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">species tree with depth equal to 10 \n",
       "\\item</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">10 \n",
       "\\item Transform the gene trees to be</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to be ultrametrics.\n",
       "\\item Compute approximate</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">second order tropical principal components via</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">via the Algorithms</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{tropical-linear-space-algorithm} and</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{al1}.\n",
       "\\end{enumerate}\n",
       "\\end{algorithm}\n",
       "\n",
       "We</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">applied both methods of tropical principal</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">principal component analysis to a set of random</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of random trees generated by Algorithm</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Algorithm \\ref{sim_data}. In analogy with</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with \\cite{NTWY}, we define summary statistics to</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to describe the fit of a Stiefel tropical linear</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">linear space\n",
       "or a tropical polytope to a given</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">a given data\n",
       "set. If</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$L_p</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ is a Stiefel tropical linear space, we define</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">we define its distance to the datapoints</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d(L_p)</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ as\n",
       "\\[d(L_p) = \\sum_i d(D^{(i)}, L_p),\\]\n",
       "and a</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">a tropical proportion of variance</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">variance statistic\n",
       "\\[r(L_p) = \\frac{\\sum_i</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">d_{tr}(\\bar \\pi, \\pi_{L_p}(D^{(i)}))}{\\sum_i</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">d_{tr}(D^{(i)}, \\pi_{L_p}(D^{(i)})+\\sum_i</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">d_{tr}(\\bar \\pi, \\pi_{L_p}(D^{(i)}))}\\]\n",
       "where</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\bar \\pi</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ denotes a Fermat-Weber point of the projections</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of the datapoints, as in \\cite{LY}. These</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">These statistics are defined analogously for a</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for a tropical polytope</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathcal P$. The statistic $r(L_p)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ can be interpreted as the proportion of variance</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">variance explained by</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$L_p</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$; in order to remain consistent with the tropical</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical metric, we sum distances rather than</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">than squared distances. \n",
       "\n",
       "For the polytopal</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">polytopal approach, as noted above, the</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the projections will remain ultrametrics. We</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">We therefore analyze the topologies of these</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of these projections, and compare them with the</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with the topology of the species</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">species tree.\n",
       "\n",
       "\\subsection{Approximation</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">results}\n",
       "\n",
       "We applied Algorithm</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Algorithm \\ref{tropical-linear-space-algorithm}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to find an approximate 2-dimensional best-fit</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">best-fit Stiefel tropical linear space with a</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with a convergence threshold of 100 iterations.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The summary statistics for this run were:</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d(L_p)=363.0378$ and $r(L_p) = 0.322</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$.\n",
       "\n",
       "We also applied a variant of Algorithm</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Algorithm \\ref{al1} to find an approximate</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">best-fit tropical polytope with three vertices,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">vertices, in which we enumerated through all</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\binom{250}{3}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ different choices. The summary statistics were:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d(\\mathcal P) = 360.6831$ and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ and \n",
       "$r(\\mathcal P) = 0.265</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. We note that the overall sum of distances is</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is similar between the two methods, but that the</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that the best-fit Stiefel tropical linear space</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">space explains a slightly higher proportion of</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of variance. \n",
       "\n",
       "For the tropical polytope method,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">method, we recall that projections of equidistant</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">trees will remain ultrametrics. We present common</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">common topologies of the projections as well as</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">well as the species tree topology\n",
       "in Figure</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Figure \\ref{sim_topology}.\\footnote{Tree</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">topologies of all projected\n",
       "points can be found</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">be found in the supplement \n",
       "at</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\url{http://polytopes.net/computations/tropicalPC</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropicalPCA/}.}\n",
       "We</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">observe that these topologies of\n",
       "projected trees</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">trees are broadly consistent with the topology of</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of the species tree\n",
       "under which these gene trees</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">trees were generated: taxa</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$g$ and $c$ group\n",
       "together, as do taxa $h$ and $f</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$h$ and $f$, and the four taxa $a$, $b$, $d$, $e</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ also group together. We can view our best-fit</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">best-fit tropical polytope as preserving these</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">these features of the species tree, meaning that</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that this tropical polytope retains information</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">after</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">projection.\n",
       "\\begin{figure}[!ht]\n",
       "\\centering\n",
       "\\inclu</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ing\n",
       "\\includegraphics[width=0.6\\linewidth]{proj_sim</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">]{proj_sim_250_8_topology.pdf}</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\caption{Topology frequencies after projections:</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the parenthesized numbers are frequencies, and</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and the last tree gives the species tree</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tree topology.}</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\label{sim_topology}\n",
       "\\end{figure}\n",
       "\n",
       "\\section{Apico</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tion{Apicomplexa</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">genome}\\label{apicomplexa}\n",
       "\n",
       "We also applied our</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">our tropical principal component algorithms to a</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to a set of trees constructed from</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from 252\n",
       "orthologous sequences on eight species</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">species of protozoa in the\n",
       "Apicomplexa phylum by</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">phylum by \\cite{KWK}.   \n",
       "This dataset was also</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">was also analyzed by Weyenberg et.~al; one can</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">one can find\n",
       "more details, such as the gene</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the gene sequences, in \\cite{KDETrees}.\n",
       "Because</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ordinary PCA is sensitive to outliers, we removed</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">removed 16 outlier gene trees identified by</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">by \\cite{KDETrees} before fitting the tropical</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical principal components.\n",
       "\n",
       "To find an</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">find an approximate best-fit 2-dimensional</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Stiefel tropical linear space, we applied</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">applied Algorithm</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Algorithm \\ref{tropical-linear-space-algorithm}</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with a convergence threshold of 100 iterations.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Due to the stochastic nature of the algorithm, we</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">we executed the algorithm three times. %Tree</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">%Tree topologies from a representative execution</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">execution are presented in Table</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in Table \\ref{apicomplexa-tropical-linear-space}.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">We note the close similarity between the most</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the most common tree topology with the</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with the generally-accepted phylogeny of these</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of these eight taxa \\cite[Figure 1]{KWK}. \n",
       "The</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The summary statistics remained consistent</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">between these runs. For one representative</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">execution, these statistics were:</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d(L_p) = 145.38$ and $r(L_p)=0.616</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. % In general, furthermore, projected topologies</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">were largely congruent with the generally</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">generally accepted phylogeny: the two Plasmodium</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">species (Pv and Pf) group together, as do Ta and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">do Ta and Bb; and Tt is isolated on a deep</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">branch.\n",
       "\n",
       "\\begin{comment}\\begin{table}\n",
       "\\centering</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">centering\n",
       "\\caption{Tree</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">topologies and frequency counts for  apicomplexa</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gene tree</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">projections}\n",
       "\\label{apicomplexa-tropical-linear-s</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">l-linear-space}\n",
       "\\begin{tabular}{|c|c|c|c|}\n",
       "\\hline</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">|}\n",
       "\\hline\n",
       "Count</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& Topology & Count & Topology\\\\\\hline\n",
       "112 &</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree3</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree3.png}</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 31 &</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree1</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree13.png}\\\\</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\hline\n",
       "30 &</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree9</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree9.png}</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 26 &</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree1</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree1.png}\\\\</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\hline\n",
       "20 &</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree4</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree4.png}</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 17 &</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree2</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree24.png}\\\\</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\hline\n",
       "8 &</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree1</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree14.png}</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& 7 &</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree4</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree43.png}\\\\</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\hline\n",
       "1 &</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[height=1.65in]{apicomplexa-tree2</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lexa-tree202.png}</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">& \\ & \\ \\\\</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ \\\\ \\hline\n",
       "\\end{tabular}\n",
       "\\end{table}\n",
       "\n",
       "Comparing</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the tropical PC's on tropical topology and</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and tropical linear space, we can see that the</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that the most three frequent topologies of the</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of the projected trees for the apicomplexa data</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">data (which totally covered more than two thirds</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">thirds of all trees) are the same for these two</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">these two methods.\n",
       "\\end{comment}\n",
       "\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\subsection{African coelacanths genome and</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and transcriptome data}\n",
       "% We also have applied</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">applied tropical PCAs to the dataset consisting</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of 1,290\n",
       "% nuclear genes encoding 690,838 amino</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">amino acid residues obtained from\n",
       "% genome and</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and transcriptome data in \\cite{LSZ}. \n",
       "% It has</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">% It has been much work on the phylogenetic</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">relations between\n",
       "% coelacanths, lungfishes and</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and tetrapods, but still it is not clear\n",
       "%</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">clear\n",
       "% despite several studies</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">studies \\cite{Hedges2009}. \n",
       "\n",
       "% Most morphological</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and paleontological studies support the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the hypothesis that lungfishes are closer to</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">closer to tetrapods than they are to coelacanths</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\cite[Fig. 1, Tree 1]{LSZ}.\n",
       "% However, some</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">some research supports the hypothesis that</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that coelacanths are\n",
       "% closer to tetrapods</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tetrapods \\cite[Fig. 1, Tree 2]{LSZ}. \n",
       "% Others</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">% Others support the hypothesis that coelacanths</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and lungfishes form a\n",
       "% sister clade \\cite[Fig.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">1, Tree 3]{LSZ}, or that tetrapods,\n",
       "% lungfishes,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and coelacanths cannot be resolved \\cite[Fig.1,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Tree\n",
       "% 4]{LSZ}. \n",
       "\n",
       "% We have used the gene trees</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">trees used for the PCA under the BHV metric</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">metric over\n",
       "% the tree space by Nye.~et.~al and</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and detailed information such as tree\n",
       "%</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">as tree\n",
       "% reconstruction method used as well as</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">well as species names can be found in</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">found in \\cite{NTWY}.\n",
       "% %\\begin{small}\n",
       "\n",
       "\n",
       "\n",
       "We also</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">also applied a variant of Algorithm \\ref{al1} to</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to find a well-fitted tropical polytope with</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with three vertices, enumerating through all</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">${\\binom{252}{3}}</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ possibilities. The summary statistics for this</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for this run were:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$d(\\mathcal P)= 147.0568$ and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ and $r(\\mathcal P) = 0.612</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$. We note that these summary statistics are</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">are relatively consistent with the summary</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">summary statistics obtained from the Stiefel</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Stiefel tropical linear space algorithm. \n",
       "\n",
       "The</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The tree topologies are presented in Figure</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in Figure \\ref{api_topology}. In general, the</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the projected topologies were largely congruent</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">congruent with the generally accepted phylogeny:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the two Plasmodium species (Pv and Pf) group</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Pf) group together, as do the four species Ta,</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Ta, Bb, Tg, and Et, and Tt is isolated on a deep</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">on a deep branch. \n",
       "\n",
       "\\cite[Theorem 23]{DS} tells</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tells us the tropical convex hull of the rows and</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">rows and columns of a matrix are equal. This</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This allows us to visualize our best-fit tropical</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical polytope in the two-dimensional plane</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$\\mathbb R^3/\\RR {\\bf 1}</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">$ as the tropical convex hull of 28 points. These</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">These 28 points divide the polytope into</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">into different cells, as described in</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in \\cite[Example 9]{JSY}. We plot this polytope,</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">polytope, along with its cells and the</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and the projections of our data points, in Figure</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in Figure \\ref{api_triangle}.  We note that the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that the different topologies seem to divide the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the tropical polytope PCA into several regions of</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of positive area. \n",
       "\n",
       "% \\begin{figure}[!ht]\n",
       "%</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\centering\n",
       "%</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[width=0.5\\linewidth]{proj_api_to</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">roj_api_topology.pdf}\n",
       "%</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\caption{Projected topology frequencies from</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from the Apicomplexa dataset: parenthesized</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">numbers give the frequencies of each topology.}\n",
       "%</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\label{api_topology}\n",
       "% \\end{figure}\n",
       "\n",
       "%</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\begin{figure}[!ht]\n",
       "% \\centering\n",
       "%</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[width=0.5\\linewidth]{api_approx_</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">pi_approx_visual.pdf}\n",
       "%</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\caption{Projected points onto the tropical</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tropical triangle}\n",
       "%   \\label{api_triangle}\n",
       "%</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\end{figure}\n",
       "\n",
       "\\begin{figure}[!ht]\n",
       "\\includegraphic</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">udegraphics[width=1\\linewidth]{proj_api_topology.p</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">topology.png}\n",
       "\\caption{Projected</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">topology frequencies from the Apicomplexa</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">dataset: parenthesized numbers give the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">give the frequencies of each</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">topology.}%\n",
       "\\label{api_topology}\n",
       "\\end{figure}\n",
       "\\be</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">igure}\n",
       "\\begin{figure}[!ht]</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\includegraphics[width=0.6\\linewidth]{api_approx_</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">pi_approx_visual.pdf}\n",
       "{%\n",
       "\\caption{Projected</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">points in the tropical polytope PCA, colored as</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">as in Figure</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\\ref{api_topology}.}%\n",
       "\\label{api_triangle}\n",
       "}\n",
       "\\end</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">le}\n",
       "}\n",
       "\\end{figure}\n",
       "\n",
       "\n",
       "\n",
       "\\section{Discussion}\\label{d</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">n}\\label{discuss}\n",
       "\n",
       "In</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">recent decades, the field of phylogenetics has</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">has found\n",
       "applications in the analysis on g</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 20000\n",
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text,\n",
    "    chunking_api=splitter.split_text,\n",
    "    max_length=max_len\n",
    ")\n",
    "\n",
    "# 显示高亮文本\n",
    "highlighter.display_highlighted_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/28.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/79.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/124.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/175.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/186.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/217.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/357.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/246.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/306.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/141.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/110.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/281.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/332.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/272.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/363.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/223.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/233.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/373.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/262.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/322.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/291.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/100.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/151.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/380.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/316.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/256.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/347.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/207.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/196.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/165.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/134.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/5.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/69.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/38.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/18.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/49.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/285.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/114.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/145.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/367.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/227.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/336.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/276.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/171.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/120.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/242.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/302.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/213.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/182.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/353.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/343.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/192.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/203.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/312.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/252.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/130.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/161.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/266.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/326.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/237.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/377.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/155.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/384.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/104.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/295.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/59.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/1.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/19.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/48.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/115.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/284.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/144.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/366.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/226.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/337.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/277.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/170.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/121.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/243.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/303.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/183.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/212.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/352.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/342.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/202.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/193.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/313.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/253.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/131.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/160.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/267.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/327.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/236.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/376.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/154.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/385.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/294.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/105.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/58.md\n",
      "\n",
      "测试文件: chunk_experiment/data/markdown/markdown-documentation-transformers/29.md\n",
      "100个文档平均运行时间:0.0062秒\n"
     ]
    }
   ],
   "source": [
    "type=\".md\"\n",
    "paths,splitter = choose_type(type)\n",
    "\n",
    "file_paths = [os.path.join(paths, f) for f in os.listdir(paths) if f.endswith(type)]\n",
    "file_paths = file_paths[:100]\n",
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "\n",
    "    print(f\"\\n测试文件: {file_path}\")\n",
    "    start_time = time.time()\n",
    "    splitter.split_text(sample_text)\n",
    "    end_time = time.time()\n",
    "    total_time += end_time - start_time\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高亮展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 6097, 长度: 20000\n",
      "选取的文本片段:\n",
      ", a high number of gradient accumulation steps can result in a more pronounced training slowdown. Consider the following example. Let’s say, the `per_device_train_batch_size=4` without gradient accumulation hits the GPU’s limit. If you would like to train with batches of size 64, do not set the `per_device_train_batch_size` to 1 and `gradient_accumulation_steps` to 64. Instead, keep `per_device_train_batch_size=4` and set `gradient_accumulation_steps=16`. This results in the same effective batch size while making better use of the available GPU resources.\n",
      "\n",
      "For additional information, please refer to batch size and gradient accumulation benchmarks for [RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004392537) and [A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1005033957).\n",
      "\n",
      "## Gradient Checkpointing\n",
      "\n",
      "Some large models may still face memory issues even when the batch size is set to 1 and gradient accumulation is used. This is because there are other components that also require memory storage.\n",
      "\n",
      "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result in significant memory overhead. The alternative approach of discarding the activations and recalculating them when needed during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
      "\n",
      "**Gradient checkpointing** offers a compromise between these two approaches and saves strategically selected activations throughout the computational graph so only a fraction of the activations need to be re-computed for the gradients. For an in-depth explanation of gradient checkpointing, refer to [this great article](https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9).\n",
      "\n",
      "To enable gradient checkpointing in the [Trainer](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer), pass the corresponding a flag to [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments):\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(\n",
      "    per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args\n",
      ")\n",
      "```\n",
      "\n",
      "Alternatively, use 🤗 Accelerate - find the 🤗 Accelerate example [further in this guide](#using-accelerate).\n",
      "\n",
      "While gradient checkpointing may improve memory efficiency, it slows training by approximately 20%.\n",
      "\n",
      "## Mixed precision training\n",
      "\n",
      "**Mixed precision training** is a technique that aims to optimize the computational efficiency of training models by utilizing lower-precision numerical formats for certain variables. Traditionally, most models use 32-bit floating point precision (fp32 or float32) to represent and process variables. However, not all variables require this high precision level to achieve accurate results. By reducing the precision of certain variables to lower numerical formats like 16-bit floating point (fp16 or float16), we can speed up the computations. Because in this approach some computations are performed in half-precision, while some are still in full precision, the approach is called mixed precision training.\n",
      "\n",
      "Most commonly mixed precision training is achieved by using fp16 (float16) data types, however, some GPU architectures (such as the Ampere architecture) offer bf16 and tf32 (CUDA internal data type) data types. Check out the [NVIDIA Blog](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/) to learn more about the differences between these data types.\n",
      "\n",
      "### fp16\n",
      "\n",
      "The main advantage of mixed precision training comes from saving the activations in half precision (fp16). Although the gradients are also computed in half precision they are converted back to full precision for the optimization step so no memory is saved here. While mixed precision training results in faster computations, it can also lead to more GPU memory being utilized, especially for small batch sizes. This is because the model is now present on the GPU in both 16-bit and 32-bit precision (1.5x the original model on the GPU).\n",
      "\n",
      "To enable mixed precision training, set the `fp16` flag to `True`:\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(per_device_train_batch_size=4, fp16=True, **default_args)\n",
      "```\n",
      "\n",
      "If you prefer to use 🤗 Accelerate, find the 🤗 Accelerate example [further in this guide](#using-accelerate).\n",
      "\n",
      "### BF16\n",
      "\n",
      "If you have access to an Ampere or newer hardware you can use bf16 for mixed precision training and evaluation. While bf16 has a worse precision than fp16, it has a much bigger dynamic range. In fp16 the biggest number you can have is `65535` and any number above that will result in an overflow. A bf16 number can be as large as `3.39e+38` (!) which is about the same as fp32 - because both have 8-bits used for the numerical range.\n",
      "\n",
      "You can enable BF16 in the 🤗 Trainer with:\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(bf16=True, **default_args)\n",
      "```\n",
      "\n",
      "### TF32\n",
      "\n",
      "The Ampere hardware uses a magical data type called tf32. It has the same numerical range as fp32 (8-bits), but instead of 23 bits precision it has only 10 bits (same as fp16) and uses only 19 bits in total. It’s “magical” in the sense that you can use the normal fp32 training and/or inference code and by enabling tf32 support you can get up to 3x throughput improvement. All you need to do is to add the following to your code:\n",
      "\n",
      "```\n",
      "import torch\n",
      "torch.backends.cuda.matmul.allow_tf32 = True\n",
      "torch.backends.cudnn.allow_tf32 = True\n",
      "```\n",
      "\n",
      "CUDA will automatically switch to using tf32 instead of fp32 where possible, assuming that the used GPU is from the Ampere series.\n",
      "\n",
      "According to [NVIDIA research](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/), the majority of machine learning training workloads show the same perplexity and convergence with tf32 training as with fp32. If you’re already using fp16 or bf16 mixed precision it may help with the throughput as well.\n",
      "\n",
      "You can enable this mode in the 🤗 Trainer:\n",
      "\n",
      "```\n",
      "TrainingArguments(tf32=True, **default_args)\n",
      "```\n",
      "\n",
      "tf32 can’t be accessed directly via `tensor.to(dtype=torch.tf32)` because it is an internal CUDA data type. You need `torch>=1.7` to use tf32 data types.\n",
      "\n",
      "For additional information on tf32 vs other precisions, please refer to the following benchmarks: [RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004390803) and [A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1004543189).\n",
      "\n",
      "## Flash Attention 2\n",
      "\n",
      "You can speedup the training throughput by using Flash Attention 2 integration in transformers. Check out the appropriate section in the [single GPU section](./perf_infer_gpu_one#Flash-Attention-2) to learn more about how to load a model with Flash Attention 2 modules.\n",
      "\n",
      "## Optimizer choice\n",
      "\n",
      "The most common optimizer used to train transformer models is Adam or AdamW (Adam with weight decay). Adam achieves good convergence by storing the rolling average of the previous gradients; however, it adds an additional memory footprint of the order of the number of model parameters. To remedy this, you can use an alternative optimizer. For example if you have [NVIDIA/apex](https://github.com/NVIDIA/apex) installed, `adamw_apex_fused` will give you the fastest training experience among all supported AdamW optimizers.\n",
      "\n",
      "[Trainer](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer) integrates a variety of optimizers that can be used out of box: `adamw_hf`, `adamw_torch`, `adamw_torch_fused`, `adamw_apex_fused`, `adamw_anyprecision`, `adafactor`, or `adamw_bnb_8bit`. More optimizers can be plugged in via a third-party implementation.\n",
      "\n",
      "Let’s take a closer look at two alternatives to AdamW optimizer:\n",
      "\n",
      "1.  `adafactor` which is available in [Trainer](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer)\n",
      "2.  `adamw_bnb_8bit` is also available in Trainer, but a third-party integration is provided below for demonstration.\n",
      "\n",
      "For comparison, for a 3B-parameter model, like “t5-3b”:\n",
      "\n",
      "-   A standard AdamW optimizer will need 24GB of GPU memory because it uses 8 bytes for each parameter (8\\*3 => 24GB)\n",
      "-   Adafactor optimizer will need more than 12GB. It uses slightly more than 4 bytes for each parameter, so 4\\*3 and then some extra.\n",
      "-   8bit BNB quantized optimizer will use only (2\\*3) 6GB if all optimizer states are quantized.\n",
      "\n",
      "### Adafactor\n",
      "\n",
      "Adafactor doesn’t store rolling averages for each element in weight matrices. Instead, it keeps aggregated information (sums of rolling averages row- and column-wise), significantly reducing its footprint. However, compared to Adam, Adafactor may have slower convergence in certain cases.\n",
      "\n",
      "You can switch to Adafactor by setting `optim=\"adafactor\"` in [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments):\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(per_device_train_batch_size=4, optim=\"adafactor\", **default_args)\n",
      "```\n",
      "\n",
      "Combined with other approaches (gradient accumulation, gradient checkpointing, and mixed precision training) you can notice up to 3x improvement while maintaining the throughput! However, as mentioned before, the convergence of Adafactor can be worse than Adam.\n",
      "\n",
      "### 8-bit Adam\n",
      "\n",
      "Instead of aggregating optimizer states like Adafactor, 8-bit Adam keeps the full state and quantizes it. Quantization means that it stores the state with lower precision and dequantizes it only for the optimization. This is similar to the idea behind mixed precision training.\n",
      "\n",
      "To use `adamw_bnb_8bit`, you simply need to set `optim=\"adamw_bnb_8bit\"` in [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments):\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(per_device_train_batch_size=4, optim=\"adamw_bnb_8bit\", **default_args)\n",
      "```\n",
      "\n",
      "However, we can also use a third-party implementation of the 8-bit optimizer for demonstration purposes to see how that can be integrated.\n",
      "\n",
      "First, follow the installation guide in the GitHub [repo](https://github.com/TimDettmers/bitsandbytes) to install the `bitsandbytes` library that implements the 8-bit Adam optimizer.\n",
      "\n",
      "Next you need to initialize the optimizer. This involves two steps:\n",
      "\n",
      "-   First, group the model’s parameters into two groups - one where weight decay should be applied, and the other one where it should not. Usually, biases and layer norm parameters are not weight decayed.\n",
      "-   Then do some argument housekeeping to use the same parameters as the previously used AdamW optimizer.\n",
      "\n",
      "```\n",
      "import bitsandbytes as bnb\n",
      "from torch import nn\n",
      "from transformers.trainer_pt_utils import get_parameter_names\n",
      "\n",
      "training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)\n",
      "\n",
      "decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n",
      "decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n",
      "optimizer_grouped_parameters = [\n",
      "    {\n",
      "        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n",
      "        \"weight_decay\": training_args.weight_decay,\n",
      "    },\n",
      "    {\n",
      "        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n",
      "        \"weight_decay\": 0.0,\n",
      "    },\n",
      "]\n",
      "\n",
      "optimizer_kwargs = {\n",
      "    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n",
      "    \"eps\": training_args.adam_epsilon,\n",
      "}\n",
      "optimizer_kwargs[\"lr\"] = training_args.learning_rate\n",
      "adam_bnb_optim = bnb.optim.Adam8bit(\n",
      "    optimizer_grouped_parameters,\n",
      "    betas=(training_args.adam_beta1, training_args.adam_beta2),\n",
      "    eps=training_args.adam_epsilon,\n",
      "    lr=training_args.learning_rate,\n",
      ")\n",
      "```\n",
      "\n",
      "Finally, pass the custom optimizer as an argument to the `Trainer`:\n",
      "\n",
      "```\n",
      "trainer = Trainer(model=model, args=training_args, train_dataset=ds, optimizers=(adam_bnb_optim, None))\n",
      "```\n",
      "\n",
      "Combined with other approaches (gradient accumulation, gradient checkpointing, and mixed precision training), you can expect to get about a 3x memory improvement and even slightly higher throughput as using Adafactor.\n",
      "\n",
      "### multi\\_tensor\n",
      "\n",
      "pytorch-nightly introduced `torch.optim._multi_tensor` which should significantly speed up the optimizers for situations with lots of small feature tensors. It should eventually become the default, but if you want to experiment with it sooner, take a look at this GitHub [issue](https://github.com/huggingface/transformers/issues/9965).\n",
      "\n",
      "## Data preloading\n",
      "\n",
      "One of the important requirements to reach great training speed is the ability to feed the GPU at the maximum speed it can handle. By default, everything happens in the main process, and it might not be able to read the data from disk fast enough, and thus create a bottleneck, leading to GPU under-utilization. Configure the following arguments to reduce the bottleneck:\n",
      "\n",
      "-   `DataLoader(pin_memory=True, ...)` - ensures the data gets preloaded into the pinned memory on CPU and typically leads to much faster transfers from CPU to GPU memory.\n",
      "-   `DataLoader(num_workers=4, ...)` - spawn several workers to preload data faster. During training, watch the GPU utilization stats; if it’s far from 100%, experiment with increasing the number of workers. Of course, the problem could be elsewhere, so many workers won’t necessarily lead to better performance.\n",
      "\n",
      "When using [Trainer](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer), the corresponding [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments) are: `dataloader_pin_memory` (`True` by default), and `dataloader_num_workers` (defaults to `0`).\n",
      "\n",
      "## DeepSpeed ZeRO\n",
      "\n",
      "DeepSpeed is an open-source deep learning optimization library that is integrated with 🤗 Transformers and 🤗 Accelerate. It provides a wide range of features and optimizations designed to improve the efficiency and scalability of large-scale deep learning training.\n",
      "\n",
      "If your model fits onto a single GPU and you have enough space to fit a small batch size, you don’t need to use DeepSpeed as it’ll only slow things down. However, if the model doesn’t fit onto a single GPU or you can’t fit a small batch, you can leverage DeepSpeed ZeRO + CPU Offload, or NVMe Offload for much larger models. In this case, you need to separately [install the library](main_classes/deepspeed#installation), then follow one of the guides to create a configuration file and launch DeepSpeed:\n",
      "\n",
      "-   For an in-depth guide on DeepSpeed integration with [Trainer](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer), review [the corresponding documentation](main_classes/deepspeed), specifically the [section for a single GPU](main_classes/deepspeed#deployment-with-one-gpu). Some adjustments are required to use DeepSpeed in a notebook; please take a look at the [corresponding guide](main_classes/deepspeed#deployment-in-notebooks).\n",
      "-   If you prefer to use 🤗 Accelerate, refer to [🤗 Accelerate DeepSpeed guide](https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed).\n",
      "\n",
      "## Using torch.compile\n",
      "\n",
      "PyTorch 2.0 introduced a new compile function that doesn’t require any modification to existing PyTorch code but can optimize your code by adding a single line of code: `model = torch.compile(model)`.\n",
      "\n",
      "If using [Trainer](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.Trainer), you only need `to` pass the `torch_compile` option in the [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments):\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(torch_compile=True, **default_args)\n",
      "```\n",
      "\n",
      "`torch.compile` uses Python’s frame evaluation API to automatically create a graph from existing PyTorch programs. After capturing the graph, different backends can be deployed to lower the graph to an optimized engine. You can find more details and benchmarks in [PyTorch documentation](https://pytorch.org/get-started/pytorch-2.0/).\n",
      "\n",
      "`torch.compile` has a growing list of backends, which can be found in by calling `torchdynamo.list_backends()`, each of which with its optional dependencies.\n",
      "\n",
      "Choose which backend to use by specifying it via `torch_compile_backend` in the [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments). Some of the most commonly used backends are:\n",
      "\n",
      "**Debugging backends**:\n",
      "\n",
      "-   `dynamo.optimize(\"eager\")` - Uses PyTorch to run the extracted GraphModule. This is quite useful in debugging TorchDynamo issues.\n",
      "-   `dynamo.optimize(\"aot_eager\")` - Uses AotAutograd with no compiler, i.e, just using PyTorch eager for the AotAutograd’s extracted forward and backward graphs. This is useful for debugging, and unlikely to give speedups.\n",
      "\n",
      "**Training & inference backends**:\n",
      "\n",
      "-   `dynamo.optimize(\"inductor\")` - Uses TorchInductor backend with AotAutograd and cudagraphs by leveraging codegened Triton kernels [Read more](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)\n",
      "-   `dynamo.optimize(\"nvfuser\")` - nvFuser with TorchScript. [Read more](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)\n",
      "-   `dynamo.optimize(\"aot_nvfuser\")` - nvFuser with AotAutograd. [Read more](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)\n",
      "-   `dynamo.optimize(\"aot_cudagraphs\")` - cudagraphs with AotAutograd. [Read more](https://github.com/pytorch/torchdynamo/pull/757)\n",
      "\n",
      "**Inference-only backend**s:\n",
      "\n",
      "-   `dynamo.optimize(\"ofi\")` - Uses Torchscript optimize\\_for\\_inference. [Read more](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)\n",
      "-   `dynamo.optimize(\"fx2trt\")` - Uses Nvidia TensorRT for inference optimizations. [Read more](https://github.com/pytorch/TensorRT/blob/master/docsrc/tutorials/getting_started_with_fx_path.rst)\n",
      "-   `dynamo.optimize(\"onnxrt\")` - Uses ONNXRT for inference on CPU/GPU. [Read more](https://onnxruntime.ai/)\n",
      "-   `dynamo.optimize(\"ipex\")` - Uses IPEX for inference on CPU. [Read more](https://github.com/intel/intel-extension-for-pytorch)\n",
      "\n",
      "For an example of using `torch.compile` with 🤗 Transformers, check out this [blog post on fine-tuning a BERT model for Text Classification using the newest PyTorch 2.0 features](https://www.philschmid.de/getting-started-pytorch-2-0-transformers)\n",
      "\n",
      "## Using 🤗 Accelerate\n",
      "\n",
      "With [🤗 Accelerate](https://huggingface.co/docs/accelerate/index) you can use the above methods while gaining full control over the training loop and can essentially write the loop in pure PyTorch with some minor modifications.\n",
      "\n",
      "Suppose you have combined the methods in the [TrainingArguments](/docs/transformers/v4.34.0/en/main_classes/trainer#transformers.TrainingArguments) like so:\n",
      "\n",
      "```\n",
      "training_args = TrainingArguments(\n",
      "    per_device_train_batch_size=1,\n",
      "    gradient_accumulation_steps=4,\n",
      "    gradient_checkpointing=True,\n",
      "    fp16=True,\n",
      "    **default_args,\n",
      ")\n",
      "```\n",
      "\n",
      "The full example training loop with 🤗 Accelerate is only a handful of lines of code long:\n",
      "\n",
      "```\n",
      "from accelerate import Accelerator\n",
      "from torch.utils.data.dataloader import DataLoader\n",
      "\n",
      "dataloader = DataLoader(ds, batch_size=training_args.per_device_train_batch_size)\n",
      "\n",
      "if training_args.gradient_checkpointing:\n",
      "    model.gradient_checkpointing_enable()\n",
      "\n",
      "accelerator = Accelerator(fp16=training_args.fp16)\n",
      "model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)\n",
      "\n",
      "model.train()\n",
      "for step, batch in enumerate(dataloader, start=1):\n",
      "    loss = model(**batch).loss\n",
      "    loss = loss / training_args.gradient_accumulation_steps\n",
      "    accelerator.backward(loss)\n",
      "    if step % training_args.gradient_accumulation_steps == 0:\n",
      "        optimizer.step()\n",
      "        optimizer.zero_grad()\n",
      "```\n",
      "\n",
      "First we wrap the dataset in a [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). Then we can enable gradient checkpointing by calling the model’s [gradient\\_checkpointing\\_enable()](/docs/transformers/v4.34.0/en/main_classes/model#transformers.PreTrainedModel.gradient_checkpointing_enab\n",
      "\n",
      "文本已分成 577 块。\n",
      "分块结果:\n",
      "Chunk 1: , a high number of gradient accumulation steps can\n",
      "Chunk 2: steps can result in a more pronounced training\n",
      "Chunk 3: training slowdown. Consider the following\n",
      "Chunk 4: following example. Let’s say, the\n",
      "Chunk 5: say, the `per_device_train_batch_size=4` without\n",
      "Chunk 6: without gradient accumulation hits the GPU’s\n",
      "Chunk 7: the GPU’s limit. If you would like to train with\n",
      "Chunk 8: with batches of size 64, do not set the\n",
      "Chunk 9: set the `per_device_train_batch_size` to 1 and\n",
      "Chunk 10: to 1 and `gradient_accumulation_steps` to 64.\n",
      "Chunk 11: to 64. Instead, keep\n",
      "Chunk 12: keep `per_device_train_batch_size=4` and set\n",
      "Chunk 13: and set `gradient_accumulation_steps=16`. This\n",
      "Chunk 14: This results in the same effective batch size\n",
      "Chunk 15: size while making better use of the available GPU\n",
      "Chunk 16: GPU resources.\n",
      "Chunk 17: For additional information, please refer to batch\n",
      "Chunk 18: to batch size and gradient accumulation\n",
      "Chunk 19: benchmarks for\n",
      "Chunk 20: [RTX-3090](https://github.com/huggingface/transfo\n",
      "Chunk 21: ce/transformers/issues/14608#issuecomment-10043925\n",
      "Chunk 22: t-1004392537)\n",
      "Chunk 23: and\n",
      "Chunk 24: [A100](https://github.com/huggingface/transformer\n",
      "Chunk 25: ransformers/issues/15026#issuecomment-1005033957).\n",
      "Chunk 26: ## Gradient Checkpointing\n",
      "Chunk 27: Some large models may still face memory issues\n",
      "Chunk 28: issues even when the batch size is set to 1 and\n",
      "Chunk 29: to 1 and gradient accumulation is used. This is\n",
      "Chunk 30: This is because there are other components that\n",
      "Chunk 31: that also require memory storage.\n",
      "Chunk 32: Saving all activations from the forward pass in\n",
      "Chunk 33: pass in order to compute the gradients during the\n",
      "Chunk 34: the backward pass can result in significant\n",
      "Chunk 35: memory overhead. The alternative approach of\n",
      "Chunk 36: of discarding the activations and recalculating\n",
      "Chunk 37: them when needed during the backward pass, would\n",
      "Chunk 38: would introduce a considerable computational\n",
      "Chunk 39: overhead and slow down the training process.\n",
      "Chunk 40: **Gradient checkpointing** offers a compromise\n",
      "Chunk 41: between these two approaches and saves\n",
      "Chunk 42: and saves strategically selected activations\n",
      "Chunk 43: throughout the computational graph so only a\n",
      "Chunk 44: so only a fraction of the activations need to be\n",
      "Chunk 45: to be re-computed for the gradients. For an\n",
      "Chunk 46: For an in-depth explanation of gradient\n",
      "Chunk 47: gradient checkpointing, refer to [this great\n",
      "Chunk 48: article](https://medium.com/tensorflow/fitting-la\n",
      "Chunk 49: fitting-larger-networks-into-memory-583e3c758ff9).\n",
      "Chunk 50: To enable gradient checkpointing in the\n",
      "Chunk 51: [Trainer](/docs/transformers/v4.34.0/en/main_clas\n",
      "Chunk 52: /main_classes/trainer#transformers.Trainer),\n",
      "Chunk 53: pass the corresponding a flag to\n",
      "Chunk 54: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 55: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 56: mers.TrainingArguments):\n",
      "Chunk 57: ```\n",
      "training_args = TrainingArguments(\n",
      "Chunk 58: per_device_train_batch_size=1,\n",
      "Chunk 59: gradient_accumulation_steps=4,\n",
      "Chunk 60: gradient_checkpointing=True, **default_args\n",
      "Chunk 61: )\n",
      "Chunk 62: ```\n",
      "Chunk 63: Alternatively, use 🤗 Accelerate - find the 🤗\n",
      "Chunk 64: the 🤗 Accelerate example [further in this\n",
      "Chunk 65: in this guide](#using-accelerate).\n",
      "Chunk 66: While gradient checkpointing may improve memory\n",
      "Chunk 67: memory efficiency, it slows training by\n",
      "Chunk 68: by approximately 20%.\n",
      "Chunk 69: ## Mixed precision training\n",
      "Chunk 70: **Mixed precision training** is a technique that\n",
      "Chunk 71: that aims to optimize the computational\n",
      "Chunk 72: efficiency of training models by utilizing\n",
      "Chunk 73: utilizing lower-precision numerical formats for\n",
      "Chunk 74: for certain variables. Traditionally, most models\n",
      "Chunk 75: models use 32-bit floating point precision (fp32\n",
      "Chunk 76: (fp32 or float32) to represent and process\n",
      "Chunk 77: process variables. However, not all variables\n",
      "Chunk 78: variables require this high precision level to\n",
      "Chunk 79: level to achieve accurate results. By reducing\n",
      "Chunk 80: reducing the precision of certain variables to\n",
      "Chunk 81: to lower numerical formats like 16-bit floating\n",
      "Chunk 82: floating point (fp16 or float16), we can speed up\n",
      "Chunk 83: speed up the computations. Because in this\n",
      "Chunk 84: in this approach some computations are performed\n",
      "Chunk 85: performed in half-precision, while some are still\n",
      "Chunk 86: are still in full precision, the approach is\n",
      "Chunk 87: is called mixed precision training.\n",
      "Chunk 88: Most commonly mixed precision training is\n",
      "Chunk 89: is achieved by using fp16 (float16) data types,\n",
      "Chunk 90: types, however, some GPU architectures (such as\n",
      "Chunk 91: (such as the Ampere architecture) offer bf16 and\n",
      "Chunk 92: bf16 and tf32 (CUDA internal data type) data\n",
      "Chunk 93: data types. Check out the [NVIDIA\n",
      "Chunk 94: Blog](https://developer.nvidia.com/blog/accelerat\n",
      "Chunk 95: /accelerating-ai-training-with-tf32-tensor-cores/)\n",
      "Chunk 96: to learn more about the differences between these\n",
      "Chunk 97: these data types.\n",
      "Chunk 98: ### fp16\n",
      "Chunk 99: The main advantage of mixed precision training\n",
      "Chunk 100: training comes from saving the activations in\n",
      "Chunk 101: in half precision (fp16). Although the gradients\n",
      "Chunk 102: gradients are also computed in half precision\n",
      "Chunk 103: precision they are converted back to full\n",
      "Chunk 104: to full precision for the optimization step so no\n",
      "Chunk 105: so no memory is saved here. While mixed precision\n",
      "Chunk 106: precision training results in faster\n",
      "Chunk 107: in faster computations, it can also lead to more\n",
      "Chunk 108: to more GPU memory being utilized, especially for\n",
      "Chunk 109: for small batch sizes. This is because the model\n",
      "Chunk 110: the model is now present on the GPU in both\n",
      "Chunk 111: in both 16-bit and 32-bit precision (1.5x the\n",
      "Chunk 112: (1.5x the original model on the GPU).\n",
      "Chunk 113: To enable mixed precision training, set the\n",
      "Chunk 114: set the `fp16` flag to `True`:\n",
      "Chunk 115: ```\n",
      "Chunk 116: training_args =\n",
      "Chunk 117: TrainingArguments(per_device_train_batch_size=4,\n",
      "Chunk 118: fp16=True, **default_args)\n",
      "Chunk 119: ```\n",
      "Chunk 120: If you prefer to use 🤗 Accelerate, find the 🤗\n",
      "Chunk 121: the 🤗 Accelerate example [further in this\n",
      "Chunk 122: in this guide](#using-accelerate).\n",
      "Chunk 123: ### BF16\n",
      "Chunk 124: If you have access to an Ampere or newer hardware\n",
      "Chunk 125: hardware you can use bf16 for mixed precision\n",
      "Chunk 126: precision training and evaluation. While bf16 has\n",
      "Chunk 127: bf16 has a worse precision than fp16, it has a\n",
      "Chunk 128: it has a much bigger dynamic range. In fp16 the\n",
      "Chunk 129: fp16 the biggest number you can have is `65535`\n",
      "Chunk 130: `65535` and any number above that will result in\n",
      "Chunk 131: result in an overflow. A bf16 number can be as\n",
      "Chunk 132: can be as large as `3.39e+38` (!) which is about\n",
      "Chunk 133: is about the same as fp32 - because both have\n",
      "Chunk 134: both have 8-bits used for the numerical range.\n",
      "Chunk 135: You can enable BF16 in the 🤗 Trainer with:\n",
      "Chunk 136: ```\n",
      "Chunk 137: training_args = TrainingArguments(bf16=True,\n",
      "Chunk 138: **default_args)\n",
      "Chunk 139: ```\n",
      "\n",
      "### TF32\n",
      "Chunk 140: The Ampere hardware uses a magical data type\n",
      "Chunk 141: data type called tf32. It has the same numerical\n",
      "Chunk 142: numerical range as fp32 (8-bits), but instead of\n",
      "Chunk 143: of 23 bits precision it has only 10 bits (same as\n",
      "Chunk 144: (same as fp16) and uses only 19 bits in total.\n",
      "Chunk 145: in total. It’s “magical” in the sense that you\n",
      "Chunk 146: that you can use the normal fp32 training and/or\n",
      "Chunk 147: and/or inference code and by enabling tf32\n",
      "Chunk 148: tf32 support you can get up to 3x throughput\n",
      "Chunk 149: improvement. All you need to do is to add the\n",
      "Chunk 150: add the following to your code:\n",
      "Chunk 151: ```\n",
      "import torch\n",
      "Chunk 152: torch.backends.cuda.matmul.allow_tf32 = True\n",
      "Chunk 153: torch.backends.cudnn.allow_tf32 = True\n",
      "Chunk 154: ```\n",
      "Chunk 155: CUDA will automatically switch to using tf32\n",
      "Chunk 156: tf32 instead of fp32 where possible, assuming\n",
      "Chunk 157: assuming that the used GPU is from the Ampere\n",
      "Chunk 158: Ampere series.\n",
      "Chunk 159: According to [NVIDIA\n",
      "Chunk 160: research](https://developer.nvidia.com/blog/accel\n",
      "Chunk 161: blog/accelerating-ai-training-with-tf32-tensor-cor\n",
      "Chunk 162: tensor-cores/),\n",
      "Chunk 163: the majority of machine learning training\n",
      "Chunk 164: training workloads show the same perplexity and\n",
      "Chunk 165: and convergence with tf32 training as with fp32.\n",
      "Chunk 166: fp32. If you’re already using fp16 or bf16 mixed\n",
      "Chunk 167: mixed precision it may help with the throughput\n",
      "Chunk 168: as well.\n",
      "Chunk 169: You can enable this mode in the 🤗 Trainer:\n",
      "Chunk 170: ```\n",
      "TrainingArguments(tf32=True, **default_args)\n",
      "Chunk 171: ```\n",
      "Chunk 172: tf32 can’t be accessed directly via\n",
      "Chunk 173: via `tensor.to(dtype=torch.tf32)` because it is\n",
      "Chunk 174: it is an internal CUDA data type. You need\n",
      "Chunk 175: You need `torch>=1.7` to use tf32 data types.\n",
      "Chunk 176: For additional information on tf32 vs other\n",
      "Chunk 177: vs other precisions, please refer to the\n",
      "Chunk 178: to the following benchmarks:\n",
      "Chunk 179: [RTX-3090](https://github.com/huggingface/transfo\n",
      "Chunk 180: ce/transformers/issues/14608#issuecomment-10043908\n",
      "Chunk 181: t-1004390803)\n",
      "Chunk 182: and\n",
      "Chunk 183: [A100](https://github.com/huggingface/transformer\n",
      "Chunk 184: ransformers/issues/15026#issuecomment-1004543189).\n",
      "Chunk 185: ## Flash Attention 2\n",
      "Chunk 186: You can speedup the training throughput by using\n",
      "Chunk 187: by using Flash Attention 2 integration in\n",
      "Chunk 188: in transformers. Check out the appropriate\n",
      "Chunk 189: section in the [single GPU\n",
      "Chunk 190: section](./perf_infer_gpu_one#Flash-Attention-2)\n",
      "Chunk 191: to learn more about how to load a model with\n",
      "Chunk 192: with Flash Attention 2 modules.\n",
      "Chunk 193: ## Optimizer choice\n",
      "Chunk 194: The most common optimizer used to train\n",
      "Chunk 195: to train transformer models is Adam or AdamW\n",
      "Chunk 196: or AdamW (Adam with weight decay). Adam achieves\n",
      "Chunk 197: achieves good convergence by storing the rolling\n",
      "Chunk 198: rolling average of the previous gradients;\n",
      "Chunk 199: however, it adds an additional memory footprint\n",
      "Chunk 200: footprint of the order of the number of model\n",
      "Chunk 201: of model parameters. To remedy this, you can use\n",
      "Chunk 202: can use an alternative optimizer. For example if\n",
      "Chunk 203: if you have\n",
      "Chunk 204: [NVIDIA/apex](https://github.com/NVIDIA/apex)\n",
      "Chunk 205: installed, `adamw_apex_fused` will give you the\n",
      "Chunk 206: you the fastest training experience among all\n",
      "Chunk 207: among all supported AdamW optimizers.\n",
      "Chunk 208: [Trainer](/docs/transformers/v4.34.0/en/main_clas\n",
      "Chunk 209: /main_classes/trainer#transformers.Trainer)\n",
      "Chunk 210: integrates a variety of optimizers that can be\n",
      "Chunk 211: can be used out of box: `adamw_hf`,\n",
      "Chunk 212: `adamw_torch`, `adamw_torch_fused`,\n",
      "Chunk 213: `adamw_apex_fused`, `adamw_anyprecision`,\n",
      "Chunk 214: `adafactor`, or `adamw_bnb_8bit`. More optimizers\n",
      "Chunk 215: can be plugged in via a third-party\n",
      "Chunk 216: implementation.\n",
      "Chunk 217: Let’s take a closer look at two alternatives to\n",
      "Chunk 218: to AdamW optimizer:\n",
      "Chunk 219: 1.  `adafactor` which is available in\n",
      "Chunk 220: [Trainer](/docs/transformers/v4.34.0/en/main_clas\n",
      "Chunk 221: /main_classes/trainer#transformers.Trainer)\n",
      "Chunk 222: 2.  `adamw_bnb_8bit` is also available in\n",
      "Chunk 223: in Trainer, but a third-party integration is\n",
      "Chunk 224: is provided below for demonstration.\n",
      "Chunk 225: For comparison, for a 3B-parameter model, like\n",
      "Chunk 226: like “t5-3b”:\n",
      "Chunk 227: -   A standard AdamW optimizer will need 24GB of\n",
      "Chunk 228: 24GB of GPU memory because it uses 8 bytes for\n",
      "Chunk 229: bytes for each parameter (8\\*3 => 24GB)\n",
      "Chunk 230: -   Adafactor optimizer will need more than 12GB.\n",
      "Chunk 231: 12GB. It uses slightly more than 4 bytes for each\n",
      "Chunk 232: for each parameter, so 4\\*3 and then some extra.\n",
      "Chunk 233: -   8bit BNB quantized optimizer will use only\n",
      "Chunk 234: use only (2\\*3) 6GB if all optimizer states are\n",
      "Chunk 235: are quantized.\n",
      "Chunk 236: ### Adafactor\n",
      "Chunk 237: Adafactor doesn’t store rolling averages for each\n",
      "Chunk 238: for each element in weight matrices. Instead, it\n",
      "Chunk 239: it keeps aggregated information (sums of rolling\n",
      "Chunk 240: rolling averages row- and column-wise),\n",
      "Chunk 241: significantly reducing its footprint. However,\n",
      "Chunk 242: However, compared to Adam, Adafactor may have\n",
      "Chunk 243: may have slower convergence in certain cases.\n",
      "Chunk 244: You can switch to Adafactor by setting\n",
      "Chunk 245: setting `optim=\"adafactor\"` in\n",
      "Chunk 246: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 247: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 248: mers.TrainingArguments):\n",
      "Chunk 249: ```\n",
      "Chunk 250: training_args =\n",
      "Chunk 251: TrainingArguments(per_device_train_batch_size=4,\n",
      "Chunk 252: optim=\"adafactor\", **default_args)\n",
      "Chunk 253: ```\n",
      "Chunk 254: Combined with other approaches (gradient\n",
      "Chunk 255: (gradient accumulation, gradient checkpointing,\n",
      "Chunk 256: and mixed precision training) you can notice up\n",
      "Chunk 257: notice up to 3x improvement while maintaining the\n",
      "Chunk 258: the throughput! However, as mentioned before, the\n",
      "Chunk 259: the convergence of Adafactor can be worse than\n",
      "Chunk 260: than Adam.\n",
      "Chunk 261: ### 8-bit Adam\n",
      "Chunk 262: Instead of aggregating optimizer states like\n",
      "Chunk 263: like Adafactor, 8-bit Adam keeps the full state\n",
      "Chunk 264: state and quantizes it. Quantization means that\n",
      "Chunk 265: that it stores the state with lower precision and\n",
      "Chunk 266: and dequantizes it only for the optimization.\n",
      "Chunk 267: This is similar to the idea behind mixed\n",
      "Chunk 268: mixed precision training.\n",
      "Chunk 269: To use `adamw_bnb_8bit`, you simply need to set\n",
      "Chunk 270: to set `optim=\"adamw_bnb_8bit\"` in\n",
      "Chunk 271: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 272: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 273: mers.TrainingArguments):\n",
      "Chunk 274: ```\n",
      "Chunk 275: training_args =\n",
      "Chunk 276: TrainingArguments(per_device_train_batch_size=4,\n",
      "Chunk 277: optim=\"adamw_bnb_8bit\", **default_args)\n",
      "Chunk 278: ```\n",
      "Chunk 279: However, we can also use a third-party\n",
      "Chunk 280: implementation of the 8-bit optimizer for\n",
      "Chunk 281: for demonstration purposes to see how that can be\n",
      "Chunk 282: can be integrated.\n",
      "Chunk 283: First, follow the installation guide in the\n",
      "Chunk 284: in the GitHub\n",
      "Chunk 285: [repo](https://github.com/TimDettmers/bitsandbyte\n",
      "Chunk 286: itsandbytes)\n",
      "Chunk 287: to install the `bitsandbytes` library that\n",
      "Chunk 288: that implements the 8-bit Adam optimizer.\n",
      "Chunk 289: Next you need to initialize the optimizer. This\n",
      "Chunk 290: This involves two steps:\n",
      "Chunk 291: -   First, group the model’s parameters into two\n",
      "Chunk 292: into two groups - one where weight decay should\n",
      "Chunk 293: should be applied, and the other one where it\n",
      "Chunk 294: where it should not. Usually, biases and layer\n",
      "Chunk 295: and layer norm parameters are not weight decayed.\n",
      "Chunk 296: -   Then do some argument housekeeping to use the\n",
      "Chunk 297: use the same parameters as the previously used\n",
      "Chunk 298: used AdamW optimizer.\n",
      "Chunk 299: ```\n",
      "import bitsandbytes as bnb\n",
      "Chunk 300: from torch import nn\n",
      "Chunk 301: from transformers.trainer_pt_utils import\n",
      "Chunk 302: import get_parameter_names\n",
      "Chunk 303: training_args =\n",
      "Chunk 304: TrainingArguments(per_device_train_batch_size=4,\n",
      "Chunk 305: **default_args)\n",
      "Chunk 306: decay_parameters = get_parameter_names(model,\n",
      "Chunk 307: [nn.LayerNorm])\n",
      "Chunk 308: decay_parameters = [name for name in\n",
      "Chunk 309: name in decay_parameters if \"bias\" not in name]\n",
      "Chunk 310: optimizer_grouped_parameters = [\n",
      "    {\n",
      "Chunk 311: \"params\": [p for n, p in\n",
      "Chunk 312: n, p in model.named_parameters() if n in\n",
      "Chunk 313: if n in decay_parameters],\n",
      "Chunk 314: \"weight_decay\":\n",
      "Chunk 315: training_args.weight_decay,\n",
      "Chunk 316: },\n",
      "    {\n",
      "Chunk 317: \"params\": [p for n, p in\n",
      "Chunk 318: n, p in model.named_parameters() if n not in\n",
      "Chunk 319: n not in decay_parameters],\n",
      "Chunk 320: \"weight_decay\": 0.0,\n",
      "    },\n",
      "]\n",
      "Chunk 321: optimizer_kwargs = {\n",
      "Chunk 322: \"betas\": (training_args.adam_beta1,\n",
      "Chunk 323: training_args.adam_beta2),\n",
      "Chunk 324: \"eps\": training_args.adam_epsilon,\n",
      "}\n",
      "Chunk 325: optimizer_kwargs[\"lr\"] =\n",
      "Chunk 326: = training_args.learning_rate\n",
      "Chunk 327: adam_bnb_optim = bnb.optim.Adam8bit(\n",
      "Chunk 328: optimizer_grouped_parameters,\n",
      "Chunk 329: betas=(training_args.adam_beta1,\n",
      "Chunk 330: training_args.adam_beta2),\n",
      "Chunk 331: eps=training_args.adam_epsilon,\n",
      "Chunk 332: lr=training_args.learning_rate,\n",
      ")\n",
      "Chunk 333: ```\n",
      "Chunk 334: Finally, pass the custom optimizer as an argument\n",
      "Chunk 335: argument to the `Trainer`:\n",
      "Chunk 336: ```\n",
      "Chunk 337: trainer = Trainer(model=model,\n",
      "Chunk 338: args=training_args, train_dataset=ds,\n",
      "Chunk 339: optimizers=(adam_bnb_optim, None))\n",
      "Chunk 340: ```\n",
      "Chunk 341: Combined with other approaches (gradient\n",
      "Chunk 342: (gradient accumulation, gradient checkpointing,\n",
      "Chunk 343: and mixed precision training), you can expect to\n",
      "Chunk 344: expect to get about a 3x memory improvement and\n",
      "Chunk 345: and even slightly higher throughput as using\n",
      "Chunk 346: as using Adafactor.\n",
      "Chunk 347: ### multi\\_tensor\n",
      "Chunk 348: pytorch-nightly introduced\n",
      "Chunk 349: `torch.optim._multi_tensor` which should\n",
      "Chunk 350: should significantly speed up the optimizers for\n",
      "Chunk 351: for situations with lots of small feature\n",
      "Chunk 352: feature tensors. It should eventually become the\n",
      "Chunk 353: the default, but if you want to experiment with\n",
      "Chunk 354: with it sooner, take a look at this GitHub\n",
      "Chunk 355: [issue](https://github.com/huggingface/transforme\n",
      "Chunk 356: transformers/issues/9965).\n",
      "Chunk 357: ## Data preloading\n",
      "Chunk 358: One of the important requirements to reach great\n",
      "Chunk 359: great training speed is the ability to feed the\n",
      "Chunk 360: feed the GPU at the maximum speed it can handle.\n",
      "Chunk 361: handle. By default, everything happens in the\n",
      "Chunk 362: in the main process, and it might not be able to\n",
      "Chunk 363: able to read the data from disk fast enough, and\n",
      "Chunk 364: and thus create a bottleneck, leading to GPU\n",
      "Chunk 365: to GPU under-utilization. Configure the following\n",
      "Chunk 366: following arguments to reduce the bottleneck:\n",
      "Chunk 367: -   `DataLoader(pin_memory=True, ...)` - ensures\n",
      "Chunk 368: - ensures the data gets preloaded into the pinned\n",
      "Chunk 369: pinned memory on CPU and typically leads to much\n",
      "Chunk 370: to much faster transfers from CPU to GPU memory.\n",
      "Chunk 371: -   `DataLoader(num_workers=4, ...)` - spawn\n",
      "Chunk 372: - spawn several workers to preload data faster.\n",
      "Chunk 373: faster. During training, watch the GPU\n",
      "Chunk 374: the GPU utilization stats; if it’s far from 100%,\n",
      "Chunk 375: 100%, experiment with increasing the number of\n",
      "Chunk 376: number of workers. Of course, the problem could\n",
      "Chunk 377: could be elsewhere, so many workers won’t\n",
      "Chunk 378: won’t necessarily lead to better performance.\n",
      "Chunk 379: When using\n",
      "Chunk 380: [Trainer](/docs/transformers/v4.34.0/en/main_clas\n",
      "Chunk 381: /main_classes/trainer#transformers.Trainer),\n",
      "Chunk 382: the corresponding\n",
      "Chunk 383: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 384: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 385: mers.TrainingArguments)\n",
      "Chunk 386: are: `dataloader_pin_memory` (`True` by default),\n",
      "Chunk 387: default), and `dataloader_num_workers` (defaults\n",
      "Chunk 388: (defaults to `0`).\n",
      "Chunk 389: ## DeepSpeed ZeRO\n",
      "Chunk 390: DeepSpeed is an open-source deep learning\n",
      "Chunk 391: learning optimization library that is integrated\n",
      "Chunk 392: with 🤗 Transformers and 🤗 Accelerate. It provides\n",
      "Chunk 393: provides a wide range of features and\n",
      "Chunk 394: and optimizations designed to improve the\n",
      "Chunk 395: the efficiency and scalability of large-scale\n",
      "Chunk 396: deep learning training.\n",
      "Chunk 397: If your model fits onto a single GPU and you have\n",
      "Chunk 398: you have enough space to fit a small batch size,\n",
      "Chunk 399: size, you don’t need to use DeepSpeed as it’ll\n",
      "Chunk 400: as it’ll only slow things down. However, if the\n",
      "Chunk 401: if the model doesn’t fit onto a single GPU or you\n",
      "Chunk 402: or you can’t fit a small batch, you can leverage\n",
      "Chunk 403: leverage DeepSpeed ZeRO + CPU Offload, or NVMe\n",
      "Chunk 404: or NVMe Offload for much larger models. In this\n",
      "Chunk 405: In this case, you need to separately [install the\n",
      "Chunk 406: library](main_classes/deepspeed#installation),\n",
      "Chunk 407: then follow one of the guides to create a\n",
      "Chunk 408: create a configuration file and launch DeepSpeed:\n",
      "Chunk 409: -   For an in-depth guide on DeepSpeed\n",
      "Chunk 410: DeepSpeed integration with\n",
      "Chunk 411: [Trainer](/docs/transformers/v4.34.0/en/main_clas\n",
      "Chunk 412: /main_classes/trainer#transformers.Trainer),\n",
      "Chunk 413: review [the corresponding\n",
      "Chunk 414: documentation](main_classes/deepspeed),\n",
      "Chunk 415: specifically the [section for a single\n",
      "Chunk 416: GPU](main_classes/deepspeed#deployment-with-one-g\n",
      "Chunk 417: with-one-gpu).\n",
      "Chunk 418: Some adjustments are required to use DeepSpeed in\n",
      "Chunk 419: in a notebook; please take a look at the\n",
      "Chunk 420: at the [corresponding\n",
      "Chunk 421: guide](main_classes/deepspeed#deployment-in-noteb\n",
      "Chunk 422: t-in-notebooks).\n",
      "Chunk 423: -   If you prefer to use 🤗 Accelerate, refer to\n",
      "Chunk 424: refer to [🤗 Accelerate DeepSpeed\n",
      "Chunk 425: guide](https://huggingface.co/docs/accelerate/en/\n",
      "Chunk 426: lerate/en/usage_guides/deepspeed).\n",
      "Chunk 427: ## Using torch.compile\n",
      "Chunk 428: PyTorch 2.0 introduced a new compile function\n",
      "Chunk 429: function that doesn’t require any modification to\n",
      "Chunk 430: to existing PyTorch code but can optimize your\n",
      "Chunk 431: your code by adding a single line of code: `model\n",
      "Chunk 432: `model = torch.compile(model)`.\n",
      "Chunk 433: If using\n",
      "Chunk 434: [Trainer](/docs/transformers/v4.34.0/en/main_clas\n",
      "Chunk 435: /main_classes/trainer#transformers.Trainer),\n",
      "Chunk 436: you only need `to` pass the `torch_compile`\n",
      "Chunk 437: option in the\n",
      "Chunk 438: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 439: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 440: mers.TrainingArguments):\n",
      "Chunk 441: ```\n",
      "Chunk 442: training_args =\n",
      "Chunk 443: = TrainingArguments(torch_compile=True,\n",
      "Chunk 444: **default_args)\n",
      "Chunk 445: ```\n",
      "Chunk 446: `torch.compile` uses Python’s frame evaluation\n",
      "Chunk 447: API to automatically create a graph from existing\n",
      "Chunk 448: existing PyTorch programs. After capturing the\n",
      "Chunk 449: the graph, different backends can be deployed to\n",
      "Chunk 450: to lower the graph to an optimized engine. You\n",
      "Chunk 451: You can find more details and benchmarks in\n",
      "Chunk 452: in [PyTorch\n",
      "Chunk 453: documentation](https://pytorch.org/get-started/py\n",
      "Chunk 454: started/pytorch-2.0/).\n",
      "Chunk 455: `torch.compile` has a growing list of backends,\n",
      "Chunk 456: backends, which can be found in by calling\n",
      "Chunk 457: calling `torchdynamo.list_backends()`, each of\n",
      "Chunk 458: each of which with its optional dependencies.\n",
      "Chunk 459: Choose which backend to use by specifying it via\n",
      "Chunk 460: it via `torch_compile_backend` in the\n",
      "Chunk 461: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 462: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 463: mers.TrainingArguments).\n",
      "Chunk 464: Some of the most commonly used backends are:\n",
      "Chunk 465: **Debugging backends**:\n",
      "Chunk 466: -   `dynamo.optimize(\"eager\")` - Uses PyTorch to\n",
      "Chunk 467: to run the extracted GraphModule. This is quite\n",
      "Chunk 468: is quite useful in debugging TorchDynamo issues.\n",
      "Chunk 469: -   `dynamo.optimize(\"aot_eager\")` - Uses\n",
      "Chunk 470: - Uses AotAutograd with no compiler, i.e, just\n",
      "Chunk 471: i.e, just using PyTorch eager for the\n",
      "Chunk 472: for the AotAutograd’s extracted forward and\n",
      "Chunk 473: and backward graphs. This is useful for\n",
      "Chunk 474: for debugging, and unlikely to give speedups.\n",
      "Chunk 475: **Training & inference backends**:\n",
      "Chunk 476: -   `dynamo.optimize(\"inductor\")` - Uses\n",
      "Chunk 477: - Uses TorchInductor backend with AotAutograd and\n",
      "Chunk 478: and cudagraphs by leveraging codegened Triton\n",
      "Chunk 479: Triton kernels [Read\n",
      "Chunk 480: more](https://dev-discuss.pytorch.org/t/torchindu\n",
      "Chunk 481: /torchinductor-a-pytorch-native-compiler-with-defi\n",
      "Chunk 482: -with-define-by-run-ir-and-symbolic-shapes/747)\n",
      "Chunk 483: -   `dynamo.optimize(\"nvfuser\")` - nvFuser with\n",
      "Chunk 484: with TorchScript. [Read\n",
      "Chunk 485: more](https://dev-discuss.pytorch.org/t/tracing-w\n",
      "Chunk 486: /tracing-with-primitives-update-1-nvfuser-and-its-\n",
      "Chunk 487: r-and-its-primitives/593)\n",
      "Chunk 488: -   `dynamo.optimize(\"aot_nvfuser\")` - nvFuser\n",
      "Chunk 489: - nvFuser with AotAutograd. [Read\n",
      "Chunk 490: more](https://dev-discuss.pytorch.org/t/tracing-w\n",
      "Chunk 491: /tracing-with-primitives-update-1-nvfuser-and-its-\n",
      "Chunk 492: r-and-its-primitives/593)\n",
      "Chunk 493: -   `dynamo.optimize(\"aot_cudagraphs\")` -\n",
      "Chunk 494: - cudagraphs with AotAutograd. [Read\n",
      "Chunk 495: more](https://github.com/pytorch/torchdynamo/pull\n",
      "Chunk 496: ynamo/pull/757)\n",
      "Chunk 497: **Inference-only backend**s:\n",
      "Chunk 498: -   `dynamo.optimize(\"ofi\")` - Uses Torchscript\n",
      "Chunk 499: optimize\\_for\\_inference. [Read\n",
      "Chunk 500: more](https://pytorch.org/docs/stable/generated/t\n",
      "Chunk 501: enerated/torch.jit.optimize_for_inference.html)\n",
      "Chunk 502: -   `dynamo.optimize(\"fx2trt\")` - Uses Nvidia\n",
      "Chunk 503: Nvidia TensorRT for inference optimizations.\n",
      "Chunk 504: [Read\n",
      "Chunk 505: more](https://github.com/pytorch/TensorRT/blob/ma\n",
      "Chunk 506: RT/blob/master/docsrc/tutorials/getting_started_wi\n",
      "Chunk 507: started_with_fx_path.rst)\n",
      "Chunk 508: -   `dynamo.optimize(\"onnxrt\")` - Uses ONNXRT for\n",
      "Chunk 509: for inference on CPU/GPU. [Read\n",
      "Chunk 510: [Read more](https://onnxruntime.ai/)\n",
      "Chunk 511: -   `dynamo.optimize(\"ipex\")` - Uses IPEX for\n",
      "Chunk 512: IPEX for inference on CPU. [Read\n",
      "Chunk 513: more](https://github.com/intel/intel-extension-fo\n",
      "Chunk 514: tension-for-pytorch)\n",
      "Chunk 515: For an example of using `torch.compile` with 🤗\n",
      "Chunk 516: with 🤗 Transformers, check out this [blog post on\n",
      "Chunk 517: post on fine-tuning a BERT model for Text\n",
      "Chunk 518: for Text Classification using the newest PyTorch\n",
      "Chunk 519: PyTorch 2.0\n",
      "Chunk 520: features](https://www.philschmid.de/getting-start\n",
      "Chunk 521: ting-started-pytorch-2-0-transformers)\n",
      "Chunk 522: ## Using 🤗 Accelerate\n",
      "Chunk 523: With [🤗\n",
      "Chunk 524: Accelerate](https://huggingface.co/docs/accelerat\n",
      "Chunk 525: /accelerate/index)\n",
      "Chunk 526: you can use the above methods while gaining full\n",
      "Chunk 527: full control over the training loop and can\n",
      "Chunk 528: and can essentially write the loop in pure\n",
      "Chunk 529: in pure PyTorch with some minor modifications.\n",
      "Chunk 530: Suppose you have combined the methods in the\n",
      "Chunk 531: [TrainingArguments](/docs/transformers/v4.34.0/en\n",
      "Chunk 532: v4.34.0/en/main_classes/trainer#transformers.Train\n",
      "Chunk 533: mers.TrainingArguments)\n",
      "Chunk 534: like so:\n",
      "Chunk 535: ```\n",
      "training_args = TrainingArguments(\n",
      "Chunk 536: per_device_train_batch_size=1,\n",
      "Chunk 537: gradient_accumulation_steps=4,\n",
      "Chunk 538: gradient_checkpointing=True,\n",
      "    fp16=True,\n",
      "Chunk 539: **default_args,\n",
      ")\n",
      "Chunk 540: ```\n",
      "Chunk 541: The full example training loop with 🤗 Accelerate\n",
      "Chunk 542: is only a handful of lines of code long:\n",
      "Chunk 543: ```\n",
      "from accelerate import Accelerator\n",
      "Chunk 544: from torch.utils.data.dataloader import\n",
      "Chunk 545: import DataLoader\n",
      "Chunk 546: dataloader = DataLoader(ds,\n",
      "Chunk 547: batch_size=training_args.per_device_train_batch_s\n",
      "Chunk 548: in_batch_size)\n",
      "Chunk 549: if training_args.gradient_checkpointing:\n",
      "Chunk 550: model.gradient_checkpointing_enable()\n",
      "Chunk 551: accelerator =\n",
      "Chunk 552: = Accelerator(fp16=training_args.fp16)\n",
      "Chunk 553: model, optimizer, dataloader =\n",
      "Chunk 554: = accelerator.prepare(model, adam_bnb_optim,\n",
      "Chunk 555: dataloader)\n",
      "Chunk 556: model.train()\n",
      "Chunk 557: for step, batch in enumerate(dataloader,\n",
      "Chunk 558: start=1):\n",
      "Chunk 559: loss = model(**batch).loss\n",
      "Chunk 560: loss = loss /\n",
      "Chunk 561: loss / training_args.gradient_accumulation_steps\n",
      "Chunk 562: accelerator.backward(loss)\n",
      "Chunk 563: if step %\n",
      "Chunk 564: step % training_args.gradient_accumulation_steps\n",
      "Chunk 565: == 0:\n",
      "Chunk 566: optimizer.step()\n",
      "Chunk 567: optimizer.zero_grad()\n",
      "Chunk 568: ```\n",
      "Chunk 569: First we wrap the dataset in a\n",
      "Chunk 570: [`DataLoader`](https://pytorch.org/docs/stable/da\n",
      "Chunk 571: /stable/data.html#torch.utils.data.DataLoader).\n",
      "Chunk 572: Then we can enable gradient checkpointing by\n",
      "Chunk 573: by calling the model’s\n",
      "Chunk 574: [gradient\\_checkpointing\\_enable()](/docs/transfo\n",
      "Chunk 575: cs/transformers/v4.34.0/en/main_classes/model#tran\n",
      "Chunk 576: model#transformers.PreTrainedModel.gradient_checkp\n",
      "Chunk 577: ent_checkpointing_enab\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">, a high number of gradient accumulation steps can</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">steps can result in a more pronounced training</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training slowdown. Consider the following</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">following example. Let’s say, the</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">say, the `per_device_train_batch_size=4` without</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">without gradient accumulation hits the GPU’s</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the GPU’s limit. If you would like to train with</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with batches of size 64, do not set the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">set the `per_device_train_batch_size` to 1 and</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to 1 and `gradient_accumulation_steps` to 64.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to 64. Instead, keep</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">keep `per_device_train_batch_size=4` and set</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and set `gradient_accumulation_steps=16`. This</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This results in the same effective batch size</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">size while making better use of the available GPU</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">GPU resources.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For additional information, please refer to batch</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to batch size and gradient accumulation</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">benchmarks for</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[RTX-3090](https://github.com/huggingface/transfo</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ce/transformers/issues/14608#issuecomment-10043925</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">t-1004392537)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[A100](https://github.com/huggingface/transformer</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ransformers/issues/15026#issuecomment-1005033957).</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Gradient Checkpointing</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Some large models may still face memory issues</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">issues even when the batch size is set to 1 and</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to 1 and gradient accumulation is used. This is</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This is because there are other components that</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that also require memory storage.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Saving all activations from the forward pass in</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">pass in order to compute the gradients during the</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the backward pass can result in significant</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">memory overhead. The alternative approach of</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of discarding the activations and recalculating</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">them when needed during the backward pass, would</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">would introduce a considerable computational</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">overhead and slow down the training process.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**Gradient checkpointing** offers a compromise</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">between these two approaches and saves</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and saves strategically selected activations</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">throughout the computational graph so only a</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">so only a fraction of the activations need to be</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to be re-computed for the gradients. For an</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For an in-depth explanation of gradient</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gradient checkpointing, refer to [this great</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">article](https://medium.com/tensorflow/fitting-la</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">fitting-larger-networks-into-memory-583e3c758ff9).</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">To enable gradient checkpointing in the</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Trainer](/docs/transformers/v4.34.0/en/main_clas</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/main_classes/trainer#transformers.Trainer),</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">pass the corresponding a flag to</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments):</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "training_args = TrainingArguments(</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">per_device_train_batch_size=1,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gradient_accumulation_steps=4,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gradient_checkpointing=True, **default_args</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Alternatively, use 🤗 Accelerate - find the 🤗</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the 🤗 Accelerate example [further in this</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in this guide](#using-accelerate).</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">While gradient checkpointing may improve memory</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">memory efficiency, it slows training by</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">by approximately 20%.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Mixed precision training</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**Mixed precision training** is a technique that</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that aims to optimize the computational</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">efficiency of training models by utilizing</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">utilizing lower-precision numerical formats for</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for certain variables. Traditionally, most models</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">models use 32-bit floating point precision (fp32</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(fp32 or float32) to represent and process</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">process variables. However, not all variables</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">variables require this high precision level to</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">level to achieve accurate results. By reducing</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">reducing the precision of certain variables to</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to lower numerical formats like 16-bit floating</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">floating point (fp16 or float16), we can speed up</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">speed up the computations. Because in this</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in this approach some computations are performed</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">performed in half-precision, while some are still</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">are still in full precision, the approach is</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is called mixed precision training.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Most commonly mixed precision training is</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is achieved by using fp16 (float16) data types,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">types, however, some GPU architectures (such as</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(such as the Ampere architecture) offer bf16 and</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">bf16 and tf32 (CUDA internal data type) data</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">data types. Check out the [NVIDIA</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Blog](https://developer.nvidia.com/blog/accelerat</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/accelerating-ai-training-with-tf32-tensor-cores/)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to learn more about the differences between these</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">these data types.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">### fp16</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The main advantage of mixed precision training</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training comes from saving the activations in</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in half precision (fp16). Although the gradients</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gradients are also computed in half precision</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">precision they are converted back to full</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to full precision for the optimization step so no</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">so no memory is saved here. While mixed precision</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">precision training results in faster</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in faster computations, it can also lead to more</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to more GPU memory being utilized, especially for</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for small batch sizes. This is because the model</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the model is now present on the GPU in both</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in both 16-bit and 32-bit precision (1.5x the</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(1.5x the original model on the GPU).</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">To enable mixed precision training, set the</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">set the `fp16` flag to `True`:</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args =</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">TrainingArguments(per_device_train_batch_size=4,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">fp16=True, **default_args)</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">If you prefer to use 🤗 Accelerate, find the 🤗</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the 🤗 Accelerate example [further in this</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in this guide](#using-accelerate).</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">### BF16</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">If you have access to an Ampere or newer hardware</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">hardware you can use bf16 for mixed precision</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">precision training and evaluation. While bf16 has</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">bf16 has a worse precision than fp16, it has a</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">it has a much bigger dynamic range. In fp16 the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">fp16 the biggest number you can have is `65535`</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`65535` and any number above that will result in</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">result in an overflow. A bf16 number can be as</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">can be as large as `3.39e+38` (!) which is about</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is about the same as fp32 - because both have</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">both have 8-bits used for the numerical range.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">You can enable BF16 in the 🤗 Trainer with:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args = TrainingArguments(bf16=True,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**default_args)</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "\n",
       "### TF32</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The Ampere hardware uses a magical data type</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">data type called tf32. It has the same numerical</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">numerical range as fp32 (8-bits), but instead of</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of 23 bits precision it has only 10 bits (same as</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(same as fp16) and uses only 19 bits in total.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in total. It’s “magical” in the sense that you</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that you can use the normal fp32 training and/or</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and/or inference code and by enabling tf32</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tf32 support you can get up to 3x throughput</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">improvement. All you need to do is to add the</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">add the following to your code:</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "import torch</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">torch.backends.cuda.matmul.allow_tf32 = True</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">torch.backends.cudnn.allow_tf32 = True</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">CUDA will automatically switch to using tf32</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tf32 instead of fp32 where possible, assuming</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">assuming that the used GPU is from the Ampere</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Ampere series.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">According to [NVIDIA</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">research](https://developer.nvidia.com/blog/accel</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">blog/accelerating-ai-training-with-tf32-tensor-cor</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tensor-cores/),</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the majority of machine learning training</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training workloads show the same perplexity and</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and convergence with tf32 training as with fp32.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">fp32. If you’re already using fp16 or bf16 mixed</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mixed precision it may help with the throughput</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">as well.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">You can enable this mode in the 🤗 Trainer:</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "TrainingArguments(tf32=True, **default_args)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tf32 can’t be accessed directly via</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">via `tensor.to(dtype=torch.tf32)` because it is</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">it is an internal CUDA data type. You need</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">You need `torch>=1.7` to use tf32 data types.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For additional information on tf32 vs other</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">vs other precisions, please refer to the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to the following benchmarks:</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[RTX-3090](https://github.com/huggingface/transfo</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ce/transformers/issues/14608#issuecomment-10043908</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">t-1004390803)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[A100](https://github.com/huggingface/transformer</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ransformers/issues/15026#issuecomment-1004543189).</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Flash Attention 2</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">You can speedup the training throughput by using</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">by using Flash Attention 2 integration in</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in transformers. Check out the appropriate</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">section in the [single GPU</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">section](./perf_infer_gpu_one#Flash-Attention-2)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to learn more about how to load a model with</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with Flash Attention 2 modules.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Optimizer choice</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The most common optimizer used to train</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to train transformer models is Adam or AdamW</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">or AdamW (Adam with weight decay). Adam achieves</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">achieves good convergence by storing the rolling</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">rolling average of the previous gradients;</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">however, it adds an additional memory footprint</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">footprint of the order of the number of model</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">of model parameters. To remedy this, you can use</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">can use an alternative optimizer. For example if</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if you have</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[NVIDIA/apex](https://github.com/NVIDIA/apex)</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">installed, `adamw_apex_fused` will give you the</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">you the fastest training experience among all</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">among all supported AdamW optimizers.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Trainer](/docs/transformers/v4.34.0/en/main_clas</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/main_classes/trainer#transformers.Trainer)</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">integrates a variety of optimizers that can be</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">can be used out of box: `adamw_hf`,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`adamw_torch`, `adamw_torch_fused`,</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`adamw_apex_fused`, `adamw_anyprecision`,</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`adafactor`, or `adamw_bnb_8bit`. More optimizers</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">can be plugged in via a third-party</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">implementation.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Let’s take a closer look at two alternatives to</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to AdamW optimizer:</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">1.  `adafactor` which is available in</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Trainer](/docs/transformers/v4.34.0/en/main_clas</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/main_classes/trainer#transformers.Trainer)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">2.  `adamw_bnb_8bit` is also available in</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in Trainer, but a third-party integration is</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is provided below for demonstration.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For comparison, for a 3B-parameter model, like</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">like “t5-3b”:</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   A standard AdamW optimizer will need 24GB of</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">24GB of GPU memory because it uses 8 bytes for</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">bytes for each parameter (8\\*3 => 24GB)</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   Adafactor optimizer will need more than 12GB.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">12GB. It uses slightly more than 4 bytes for each</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for each parameter, so 4\\*3 and then some extra.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   8bit BNB quantized optimizer will use only</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">use only (2\\*3) 6GB if all optimizer states are</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">are quantized.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">### Adafactor</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Adafactor doesn’t store rolling averages for each</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for each element in weight matrices. Instead, it</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">it keeps aggregated information (sums of rolling</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">rolling averages row- and column-wise),</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">significantly reducing its footprint. However,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">However, compared to Adam, Adafactor may have</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">may have slower convergence in certain cases.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">You can switch to Adafactor by setting</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">setting `optim=\"adafactor\"` in</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments):</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args =</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">TrainingArguments(per_device_train_batch_size=4,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optim=\"adafactor\", **default_args)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Combined with other approaches (gradient</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(gradient accumulation, gradient checkpointing,</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and mixed precision training) you can notice up</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">notice up to 3x improvement while maintaining the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the throughput! However, as mentioned before, the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the convergence of Adafactor can be worse than</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">than Adam.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">### 8-bit Adam</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Instead of aggregating optimizer states like</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">like Adafactor, 8-bit Adam keeps the full state</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">state and quantizes it. Quantization means that</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that it stores the state with lower precision and</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and dequantizes it only for the optimization.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This is similar to the idea behind mixed</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mixed precision training.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">To use `adamw_bnb_8bit`, you simply need to set</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to set `optim=\"adamw_bnb_8bit\"` in</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments):</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args =</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">TrainingArguments(per_device_train_batch_size=4,</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optim=\"adamw_bnb_8bit\", **default_args)</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">However, we can also use a third-party</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">implementation of the 8-bit optimizer for</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for demonstration purposes to see how that can be</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">can be integrated.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">First, follow the installation guide in the</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in the GitHub</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[repo](https://github.com/TimDettmers/bitsandbyte</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">itsandbytes)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to install the `bitsandbytes` library that</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">that implements the 8-bit Adam optimizer.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Next you need to initialize the optimizer. This</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This involves two steps:</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   First, group the model’s parameters into two</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">into two groups - one where weight decay should</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">should be applied, and the other one where it</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">where it should not. Usually, biases and layer</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and layer norm parameters are not weight decayed.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   Then do some argument housekeeping to use the</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">use the same parameters as the previously used</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">used AdamW optimizer.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "import bitsandbytes as bnb</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from torch import nn</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from transformers.trainer_pt_utils import</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">import get_parameter_names</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args =</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">TrainingArguments(per_device_train_batch_size=4,</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**default_args)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">decay_parameters = get_parameter_names(model,</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[nn.LayerNorm])</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">decay_parameters = [name for name in</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">name in decay_parameters if \"bias\" not in name]</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizer_grouped_parameters = [\n",
       "    {</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"params\": [p for n, p in</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">n, p in model.named_parameters() if n in</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if n in decay_parameters],</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"weight_decay\":</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args.weight_decay,</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">},\n",
       "    {</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"params\": [p for n, p in</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">n, p in model.named_parameters() if n not in</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">n not in decay_parameters],</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"weight_decay\": 0.0,\n",
       "    },\n",
       "]</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizer_kwargs = {</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"betas\": (training_args.adam_beta1,</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args.adam_beta2),</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"eps\": training_args.adam_epsilon,\n",
       "}</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizer_kwargs[\"lr\"] =</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">= training_args.learning_rate</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">adam_bnb_optim = bnb.optim.Adam8bit(</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizer_grouped_parameters,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">betas=(training_args.adam_beta1,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args.adam_beta2),</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">eps=training_args.adam_epsilon,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lr=training_args.learning_rate,\n",
       ")</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Finally, pass the custom optimizer as an argument</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">argument to the `Trainer`:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">trainer = Trainer(model=model,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">args=training_args, train_dataset=ds,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizers=(adam_bnb_optim, None))</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Combined with other approaches (gradient</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(gradient accumulation, gradient checkpointing,</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and mixed precision training), you can expect to</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">expect to get about a 3x memory improvement and</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and even slightly higher throughput as using</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">as using Adafactor.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">### multi\\_tensor</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">pytorch-nightly introduced</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`torch.optim._multi_tensor` which should</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">should significantly speed up the optimizers for</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for situations with lots of small feature</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">feature tensors. It should eventually become the</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the default, but if you want to experiment with</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with it sooner, take a look at this GitHub</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[issue](https://github.com/huggingface/transforme</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">transformers/issues/9965).</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Data preloading</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">One of the important requirements to reach great</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">great training speed is the ability to feed the</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">feed the GPU at the maximum speed it can handle.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">handle. By default, everything happens in the</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in the main process, and it might not be able to</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">able to read the data from disk fast enough, and</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and thus create a bottleneck, leading to GPU</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to GPU under-utilization. Configure the following</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">following arguments to reduce the bottleneck:</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `DataLoader(pin_memory=True, ...)` - ensures</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- ensures the data gets preloaded into the pinned</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">pinned memory on CPU and typically leads to much</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to much faster transfers from CPU to GPU memory.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `DataLoader(num_workers=4, ...)` - spawn</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- spawn several workers to preload data faster.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">faster. During training, watch the GPU</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the GPU utilization stats; if it’s far from 100%,</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">100%, experiment with increasing the number of</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">number of workers. Of course, the problem could</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">could be elsewhere, so many workers won’t</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">won’t necessarily lead to better performance.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">When using</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Trainer](/docs/transformers/v4.34.0/en/main_clas</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/main_classes/trainer#transformers.Trainer),</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the corresponding</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">are: `dataloader_pin_memory` (`True` by default),</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">default), and `dataloader_num_workers` (defaults</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">(defaults to `0`).</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## DeepSpeed ZeRO</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">DeepSpeed is an open-source deep learning</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">learning optimization library that is integrated</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with 🤗 Transformers and 🤗 Accelerate. It provides</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">provides a wide range of features and</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and optimizations designed to improve the</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the efficiency and scalability of large-scale</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">deep learning training.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">If your model fits onto a single GPU and you have</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">you have enough space to fit a small batch size,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">size, you don’t need to use DeepSpeed as it’ll</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">as it’ll only slow things down. However, if the</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if the model doesn’t fit onto a single GPU or you</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">or you can’t fit a small batch, you can leverage</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">leverage DeepSpeed ZeRO + CPU Offload, or NVMe</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">or NVMe Offload for much larger models. In this</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">In this case, you need to separately [install the</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">library](main_classes/deepspeed#installation),</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">then follow one of the guides to create a</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">create a configuration file and launch DeepSpeed:</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   For an in-depth guide on DeepSpeed</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">DeepSpeed integration with</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Trainer](/docs/transformers/v4.34.0/en/main_clas</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/main_classes/trainer#transformers.Trainer),</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">review [the corresponding</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">documentation](main_classes/deepspeed),</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">specifically the [section for a single</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">GPU](main_classes/deepspeed#deployment-with-one-g</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with-one-gpu).</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Some adjustments are required to use DeepSpeed in</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in a notebook; please take a look at the</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">at the [corresponding</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">guide](main_classes/deepspeed#deployment-in-noteb</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">t-in-notebooks).</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   If you prefer to use 🤗 Accelerate, refer to</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">refer to [🤗 Accelerate DeepSpeed</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">guide](https://huggingface.co/docs/accelerate/en/</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">lerate/en/usage_guides/deepspeed).</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Using torch.compile</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">PyTorch 2.0 introduced a new compile function</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">function that doesn’t require any modification to</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to existing PyTorch code but can optimize your</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">your code by adding a single line of code: `model</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`model = torch.compile(model)`.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">If using</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Trainer](/docs/transformers/v4.34.0/en/main_clas</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/main_classes/trainer#transformers.Trainer),</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">you only need `to` pass the `torch_compile`</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">option in the</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments):</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">training_args =</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">= TrainingArguments(torch_compile=True,</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**default_args)</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`torch.compile` uses Python’s frame evaluation</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">API to automatically create a graph from existing</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">existing PyTorch programs. After capturing the</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">the graph, different backends can be deployed to</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to lower the graph to an optimized engine. You</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">You can find more details and benchmarks in</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in [PyTorch</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">documentation](https://pytorch.org/get-started/py</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">started/pytorch-2.0/).</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">`torch.compile` has a growing list of backends,</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">backends, which can be found in by calling</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">calling `torchdynamo.list_backends()`, each of</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">each of which with its optional dependencies.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Choose which backend to use by specifying it via</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">it via `torch_compile_backend` in the</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments).</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Some of the most commonly used backends are:</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**Debugging backends**:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"eager\")` - Uses PyTorch to</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">to run the extracted GraphModule. This is quite</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is quite useful in debugging TorchDynamo issues.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"aot_eager\")` - Uses</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- Uses AotAutograd with no compiler, i.e, just</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">i.e, just using PyTorch eager for the</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for the AotAutograd’s extracted forward and</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and backward graphs. This is useful for</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for debugging, and unlikely to give speedups.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**Training & inference backends**:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"inductor\")` - Uses</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- Uses TorchInductor backend with AotAutograd and</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and cudagraphs by leveraging codegened Triton</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Triton kernels [Read</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://dev-discuss.pytorch.org/t/torchindu</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/torchinductor-a-pytorch-native-compiler-with-defi</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-with-define-by-run-ir-and-symbolic-shapes/747)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"nvfuser\")` - nvFuser with</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with TorchScript. [Read</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://dev-discuss.pytorch.org/t/tracing-w</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/tracing-with-primitives-update-1-nvfuser-and-its-</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">r-and-its-primitives/593)</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"aot_nvfuser\")` - nvFuser</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- nvFuser with AotAutograd. [Read</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://dev-discuss.pytorch.org/t/tracing-w</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/tracing-with-primitives-update-1-nvfuser-and-its-</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">r-and-its-primitives/593)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"aot_cudagraphs\")` -</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- cudagraphs with AotAutograd. [Read</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://github.com/pytorch/torchdynamo/pull</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ynamo/pull/757)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**Inference-only backend**s:</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"ofi\")` - Uses Torchscript</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimize\\_for\\_inference. [Read</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://pytorch.org/docs/stable/generated/t</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">enerated/torch.jit.optimize_for_inference.html)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"fx2trt\")` - Uses Nvidia</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Nvidia TensorRT for inference optimizations.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Read</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://github.com/pytorch/TensorRT/blob/ma</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">RT/blob/master/docsrc/tutorials/getting_started_wi</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">started_with_fx_path.rst)</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"onnxrt\")` - Uses ONNXRT for</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for inference on CPU/GPU. [Read</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[Read more](https://onnxruntime.ai/)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-   `dynamo.optimize(\"ipex\")` - Uses IPEX for</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">IPEX for inference on CPU. [Read</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more](https://github.com/intel/intel-extension-fo</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">tension-for-pytorch)</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">For an example of using `torch.compile` with 🤗</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">with 🤗 Transformers, check out this [blog post on</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">post on fine-tuning a BERT model for Text</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for Text Classification using the newest PyTorch</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">PyTorch 2.0</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">features](https://www.philschmid.de/getting-start</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ting-started-pytorch-2-0-transformers)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">## Using 🤗 Accelerate</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">With [🤗</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Accelerate](https://huggingface.co/docs/accelerat</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/accelerate/index)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">you can use the above methods while gaining full</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">full control over the training loop and can</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">and can essentially write the loop in pure</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in pure PyTorch with some minor modifications.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Suppose you have combined the methods in the</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[TrainingArguments](/docs/transformers/v4.34.0/en</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">v4.34.0/en/main_classes/trainer#transformers.Train</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mers.TrainingArguments)</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">like so:</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "training_args = TrainingArguments(</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">per_device_train_batch_size=1,</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gradient_accumulation_steps=4,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">gradient_checkpointing=True,\n",
       "    fp16=True,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">**default_args,\n",
       ")</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">The full example training loop with 🤗 Accelerate</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">is only a handful of lines of code long:</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```\n",
       "from accelerate import Accelerator</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">from torch.utils.data.dataloader import</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">import DataLoader</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">dataloader = DataLoader(ds,</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">batch_size=training_args.per_device_train_batch_s</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">in_batch_size)</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if training_args.gradient_checkpointing:</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">model.gradient_checkpointing_enable()</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">accelerator =</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">= Accelerator(fp16=training_args.fp16)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">model, optimizer, dataloader =</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">= accelerator.prepare(model, adam_bnb_optim,</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">dataloader)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">model.train()</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for step, batch in enumerate(dataloader,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">start=1):</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">loss = model(**batch).loss</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">loss = loss /</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">loss / training_args.gradient_accumulation_steps</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">accelerator.backward(loss)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if step %</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">step % training_args.gradient_accumulation_steps</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">== 0:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizer.step()</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">optimizer.zero_grad()</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">```</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">First we wrap the dataset in a</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[`DataLoader`](https://pytorch.org/docs/stable/da</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">/stable/data.html#torch.utils.data.DataLoader).</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Then we can enable gradient checkpointing by</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">by calling the model’s</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">[gradient\\_checkpointing\\_enable()](/docs/transfo</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">cs/transformers/v4.34.0/en/main_classes/model#tran</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">model#transformers.PreTrainedModel.gradient_checkp</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">ent_checkpointing_enab</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 20000\n",
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text,\n",
    "    chunking_api=splitter.split_text,\n",
    "    max_length=max_len\n",
    ")\n",
    "\n",
    "# 显示高亮文本\n",
    "highlighter.display_highlighted_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type=\".py\"\n",
    "paths,splitter = choose_type(type)\n",
    "\n",
    "file_paths = [os.path.join(paths, f) for f in os.listdir(paths) if f.endswith(type)]\n",
    "file_paths = file_paths[:100]\n",
    "total_time = 0\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sample_text = f.read()\n",
    "\n",
    "    print(f\"\\n测试文件: {file_path}\")\n",
    "    start_time = time.time()\n",
    "    splitter.split_text(sample_text)\n",
    "    end_time = time.time()\n",
    "    \n",
    "average_time = total_time / len(file_paths)\n",
    "print(f\"100个文档平均运行时间:{average_time:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高亮展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机选取的文本片段起始索引: 1083, 长度: 20000\n",
      "选取的文本片段:\n",
      " -> List[np.ndarray]:\n",
      "        \"\"\"Embed a batch of texts and return a list of embedding vectors.\n",
      "\n",
      "        Args:\n",
      "            texts (List[str]): List of texts to embed.\n",
      "\n",
      "        Returns:\n",
      "            List[np.ndarray]: List of embedding vectors.\n",
      "        \"\"\"\n",
      "        # 中文注释: 返回模拟的随机嵌入向量，实际情况需调用真实模型方法。\n",
      "        # return [np.random.rand(self.embedding_dim).astype(np.float32) for _ in texts]\n",
      "        # embeddings = embedding_api(texts)\n",
      "        # 每十个文本一组，避免一次请求过多文本\n",
      "        batch_size = 10\n",
      "        embeddings = []\n",
      "        for i in range(0, len(texts), batch_size):\n",
      "            batch_texts = texts[i : i + batch_size]\n",
      "            response = self.embedding_client.get_embeddings(batch_texts)\n",
      "            batch_embeddings = response.get(\"data\", {}).get(\"resultList\", [])\n",
      "            embeddings.extend(batch_embeddings)\n",
      "        return [np.array(embedding).astype(np.float32) for embedding in embeddings]\n",
      "\n",
      "    def similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:\n",
      "        \"\"\"Compute cosine similarity between two embeddings.\n",
      "\n",
      "        Args:\n",
      "            embedding1 (np.ndarray): Embedding vector 1.\n",
      "            embedding2 (np.ndarray): Embedding vector 2.\n",
      "\n",
      "        Returns:\n",
      "            float: Cosine similarity between the two embeddings.\n",
      "        \"\"\"\n",
      "        return float(np.dot(embedding1, embedding2))\n",
      "\n",
      "\n",
      "class Sentence:\n",
      "    \"\"\"A simple Sentence class to store raw sentence text and metadata.\"\"\"\n",
      "\n",
      "    def __init__(self, text: str, start_index: int, end_index: int):\n",
      "        # 中文注释: 基础句子类，用于存储句子文本和起始结束位置。\n",
      "        self.text = text\n",
      "        self.start_index = start_index\n",
      "        self.end_index = end_index\n",
      "\n",
      "\n",
      "class SemanticSentence(Sentence):\n",
      "    \"\"\"A SemanticSentence class that includes embedding and token count information.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        text: str,\n",
      "        start_index: int,\n",
      "        end_index: int,\n",
      "        token_count: int,\n",
      "        embedding: np.ndarray,\n",
      "    ):\n",
      "        # 中文注释: 扩展的句子类，包含嵌入向量和token计数信息。\n",
      "        super().__init__(text, start_index, end_index)\n",
      "        self.token_count = token_count\n",
      "        self.embedding = embedding\n",
      "\n",
      "\n",
      "class SemanticChunk:\n",
      "    \"\"\"A SemanticChunk class representing a coherent text chunk.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        text: str,\n",
      "        start_index: int,\n",
      "        end_index: int,\n",
      "        token_count: int,\n",
      "        sentences: List[SemanticSentence],\n",
      "        chunk_embedding: np.ndarray,\n",
      "    ):\n",
      "        # 中文注释: 语义块类，包含块文本、起止位置、token计数及所属句子列表、以及预先计算好的chunk embedding。\n",
      "        self.text = text\n",
      "        self.start_index = start_index\n",
      "        self.end_index = end_index\n",
      "        self.token_count = token_count\n",
      "        self.sentences = sentences\n",
      "        self.chunk_embedding = chunk_embedding\n",
      "\n",
      "\n",
      "class SemanticChunker:\n",
      "    \"\"\"A SemanticChunker class to split text into semantically coherent chunks.\n",
      "\n",
      "    This class:\n",
      "    - Splits text into sentences.\n",
      "    - Computes embeddings for sentences.\n",
      "    - Groups sentences based on semantic similarity.\n",
      "    - Splits groups into chunks that respect a specified maximum size.\n",
      "\n",
      "    Attributes:\n",
      "        embedding_model (EmbeddingModel): The embedding model.\n",
      "        min_characters_per_sentence (int): Minimum char length to consider a valid sentence.\n",
      "        similarity_threshold (Optional[float]): Fixed similarity threshold or None.\n",
      "        similarity_percentile (Optional[float]): Percentile to compute dynamic threshold.\n",
      "        similarity_window (int): Window size for window-based grouping mode.\n",
      "        mode (str): \"cumulative\" or \"window\" grouping mode.\n",
      "        initial_sentences (int): Initial number of sentences to start the cumulative grouping.\n",
      "        min_sentences (int): Minimum number of sentences per chunk/group.\n",
      "        chunk_size (int): Maximum token count allowed per chunk.\n",
      "        min_chunk_size (int): Minimum token count per chunk.\n",
      "        threshold_step (float): Step size for binary search threshold adjustments.\n",
      "        sep (str): Separator for sentence splitting.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        embedding_model: EmbeddingModel,\n",
      "        min_characters_per_sentence: int = 5,\n",
      "        similarity_threshold: Optional[float] = None,\n",
      "        similarity_percentile: Optional[float] = 90,\n",
      "        similarity_window: int = 1,\n",
      "        mode: str = \"cumulative\",\n",
      "        initial_sentences: int = 1,\n",
      "        min_sentences: int = 1,\n",
      "        chunk_size: int = 200,\n",
      "        min_chunk_size: int = 50,\n",
      "        threshold_step: float = 0.05,\n",
      "        sep: str = \"🐮🍺\",\n",
      "    ):\n",
      "        # 中文注释: 初始化分块器参数，支持两种模式并设置各种限制参数和分句分隔符。\n",
      "        self.embedding_model = embedding_model\n",
      "        self.min_characters_per_sentence = min_characters_per_sentence\n",
      "        self.similarity_threshold = similarity_threshold\n",
      "        self.similarity_percentile = similarity_percentile\n",
      "        self.similarity_window = similarity_window\n",
      "        self.mode = mode\n",
      "        self.initial_sentences = initial_sentences\n",
      "        self.min_sentences = min_sentences\n",
      "        self.chunk_size = chunk_size\n",
      "        self.min_chunk_size = min_chunk_size\n",
      "        self.threshold_step = threshold_step\n",
      "        self.sep = sep\n",
      "        self.splitter = GeneralTextSplitter(max_sentence_length=120)\n",
      "\n",
      "    def _count_tokens(self, text: str) -> int:\n",
      "        \"\"\"Count approximate tokens in text based on whitespace splitting.\n",
      "\n",
      "        Args:\n",
      "            text (str): Input text.\n",
      "\n",
      "        Returns:\n",
      "            int: Approximate token count.\n",
      "        \"\"\"\n",
      "        # 中文注释: 粗略计算token数，实际可使用更严格的tokenizer。\n",
      "        return len(text.split())\n",
      "\n",
      "    def _count_tokens_batch(self, texts: List[str]) -> List[int]:\n",
      "        \"\"\"Count tokens for a batch of texts.\n",
      "\n",
      "        Args:\n",
      "            texts (List[str]): Input texts.\n",
      "\n",
      "        Returns:\n",
      "            List[int]: List of token counts.\n",
      "        \"\"\"\n",
      "        # 中文注释: 批量计算token数。\n",
      "        return [self._count_tokens(t) for t in texts]\n",
      "\n",
      "    def _split_sentences(self, text: str) -> List[str]:\n",
      "        \"\"\"Fast sentence splitting while maintaining accuracy.\n",
      "\n",
      "        This method is faster than using regex for sentence splitting and\n",
      "        more accurate than using spaCy sentence tokenizer.\n",
      "\n",
      "        Args:\n",
      "            text (str): Input text to be split into sentences.\n",
      "\n",
      "        Returns:\n",
      "            List[str]: List of sentences.\n",
      "        \"\"\"\n",
      "        sentences = self.splitter.split_text(text)\n",
      "        return sentences\n",
      "\n",
      "    def _compute_similarity_threshold(self, all_similarities: List[float]) -> float:\n",
      "        \"\"\"Compute similarity threshold based on percentile if specified.\"\"\"\n",
      "        # 中文注释: 若设置了固定threshold则返回，否则按percentile计算。\n",
      "        if self.similarity_threshold is not None:\n",
      "            return self.similarity_threshold\n",
      "        else:\n",
      "            return float(np.percentile(all_similarities, self.similarity_percentile))\n",
      "\n",
      "    def _prepare_sentences(self, text: str) -> List[SemanticSentence]:\n",
      "        \"\"\"Prepare sentences with precomputed information.\n",
      "\n",
      "        Args:\n",
      "            text (str): Input text to be processed.\n",
      "\n",
      "        Returns:\n",
      "            List[SemanticSentence]: List of Sentence objects with precomputed embeddings.\n",
      "        \"\"\"\n",
      "        # 中文注释: 将文本分句，计算句子embedding和token数，并构建SemanticSentence对象列表。\n",
      "        if not text.strip():\n",
      "            return []\n",
      "\n",
      "        raw_sentences = self._split_sentences(text)\n",
      "\n",
      "        # Compute start/end indices\n",
      "        sentence_indices = []\n",
      "        current_idx = 0\n",
      "        for sent in raw_sentences:\n",
      "            start_idx = text.find(sent, current_idx)\n",
      "            end_idx = start_idx + len(sent)\n",
      "            sentence_indices.append((start_idx, end_idx))\n",
      "            current_idx = end_idx\n",
      "\n",
      "        # Create sentence groups for embedding computation\n",
      "        sentence_groups = []\n",
      "        for i in range(len(raw_sentences)):\n",
      "            group = []\n",
      "            for j in range(i - self.similarity_window, i + self.similarity_window + 1):\n",
      "                if 0 <= j < len(raw_sentences):\n",
      "                    group.append(raw_sentences[j])\n",
      "            sentence_groups.append(\"\".join(group))\n",
      "\n",
      "        # Compute embeddings\n",
      "        embeddings = self.embedding_model.embed_batch(sentence_groups)\n",
      "        # Compute token counts\n",
      "        token_counts = self._count_tokens_batch(raw_sentences)\n",
      "        sentences = [\n",
      "            SemanticSentence(\n",
      "                text=sent,\n",
      "                start_index=start_idx,\n",
      "                end_index=end_idx,\n",
      "                token_count=count,\n",
      "                embedding=embedding,\n",
      "            )\n",
      "            for sent, (start_idx, end_idx), count, embedding in zip(\n",
      "                raw_sentences, sentence_indices, token_counts, embeddings\n",
      "            )\n",
      "        ]\n",
      "\n",
      "        return sentences\n",
      "\n",
      "    def _get_semantic_similarity(\n",
      "        self, embedding1: np.ndarray, embedding2: np.ndarray\n",
      "    ) -> float:\n",
      "        \"\"\"Compute cosine similarity between two embeddings.\"\"\"\n",
      "        # 中文注释: 简化调用embedding_model的similarity方法。\n",
      "        return self.embedding_model.similarity(embedding1, embedding2)\n",
      "\n",
      "    def _compute_group_embedding(self, sentences: List[SemanticSentence]) -> np.ndarray:\n",
      "        \"\"\"Compute mean embedding for a group of sentences.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            np.ndarray: Mean embedding vector.\n",
      "        \"\"\"\n",
      "        # 中文注释: 加权平均，考虑token数对平均值的影响。\n",
      "        return np.divide(\n",
      "            np.sum([(sent.embedding * sent.token_count) for sent in sentences], axis=0),\n",
      "            np.sum([sent.token_count for sent in sentences]),\n",
      "            dtype=np.float32,\n",
      "        )\n",
      "\n",
      "    def _compute_pairwise_similarities(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> List[float]:\n",
      "        \"\"\"Compute all pairwise similarities between sentences.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            List[float]: List of similarities between consecutive sentences.\n",
      "        \"\"\"\n",
      "        # 中文注释: 计算相邻句子间相似度。\n",
      "        return [\n",
      "            self._get_semantic_similarity(\n",
      "                sentences[i].embedding, sentences[i + 1].embedding\n",
      "            )\n",
      "            for i in range(len(sentences) - 1)\n",
      "        ]\n",
      "\n",
      "    def _get_split_indices(\n",
      "        self, similarities: List[float], threshold: float = None\n",
      "    ) -> List[int]:\n",
      "        \"\"\"Get indices of sentences to split at.\n",
      "\n",
      "        Args:\n",
      "            similarities (List[float]): List of pairwise similarities.\n",
      "            threshold (float): Similarity threshold.\n",
      "\n",
      "        Returns:\n",
      "            List[int]: Indices indicating the split points.\n",
      "        \"\"\"\n",
      "        # 中文注释: 根据相似度阈值确定分组的切分点。\n",
      "        if threshold is None:\n",
      "            threshold = (\n",
      "                self.similarity_threshold\n",
      "                if self.similarity_threshold is not None\n",
      "                else 0.5\n",
      "            )\n",
      "\n",
      "        # Get indices of sentences that are below the threshold\n",
      "        splits = [\n",
      "            i + 1\n",
      "            for i, s in enumerate(similarities)\n",
      "            if s <= threshold and i + 1 < len(similarities) + 1\n",
      "        ]\n",
      "\n",
      "        # Add the start and end of the text\n",
      "        splits = [0] + splits + [len(similarities) + 1]\n",
      "\n",
      "        # Ensure minimum sentences per group\n",
      "        i = 0\n",
      "        while i < len(splits) - 1:\n",
      "            if splits[i + 1] - splits[i] < self.min_sentences:\n",
      "                splits.pop(i + 1)\n",
      "            else:\n",
      "                i += 1\n",
      "        return splits\n",
      "\n",
      "    def _calculate_threshold_via_binary_search(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> float:\n",
      "        \"\"\"Calculate similarity threshold via binary search.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            float: Computed threshold.\n",
      "        \"\"\"\n",
      "        # 中文注释: 通过binary search来寻找合适的相似度阈值，使分块满足大小要求。\n",
      "        token_counts = [sent.token_count for sent in sentences]\n",
      "\n",
      "        similarities = self._compute_pairwise_similarities(sentences)\n",
      "\n",
      "        median = np.median(similarities)\n",
      "        std = np.std(similarities)\n",
      "\n",
      "        low = max(median - 1 * std, 0.0)\n",
      "        high = min(median + 1 * std, 1.0)\n",
      "\n",
      "        iterations = 0\n",
      "        threshold = (low + high) / 2\n",
      "\n",
      "        while abs(high - low) > self.threshold_step:\n",
      "            threshold = (low + high) / 2\n",
      "            split_indices = self._get_split_indices(similarities, threshold)\n",
      "            # Extract token counts of each segment\n",
      "            segment_lengths = []\n",
      "            for i in range(len(split_indices) - 1):\n",
      "                start = split_indices[i]\n",
      "                end = split_indices[i + 1]\n",
      "                segment_token_count = sum(token_counts[start:end])\n",
      "                segment_lengths.append(segment_token_count)\n",
      "\n",
      "            # Check condition: ideally segment lengths between min_chunk_size and chunk_size\n",
      "            if all(\n",
      "                self.min_chunk_size <= length <= self.chunk_size\n",
      "                for length in segment_lengths\n",
      "            ):\n",
      "                break\n",
      "            elif any(length > self.chunk_size for length in segment_lengths):\n",
      "                # 若有超过chunk_size的分段，增加threshold降低分组数量\n",
      "                low = threshold + self.threshold_step\n",
      "            else:\n",
      "                # 若有分段小于min_chunk_size，减少threshold增加分组数量\n",
      "                high = threshold - self.threshold_step\n",
      "\n",
      "            iterations += 1\n",
      "            if iterations > 10:\n",
      "                warnings.warn(\n",
      "                    \"Too many iterations in threshold calculation, stopping...\",\n",
      "                    stacklevel=2,\n",
      "                )\n",
      "                break\n",
      "\n",
      "        return threshold\n",
      "\n",
      "    def _calculate_threshold_via_percentile(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> float:\n",
      "        \"\"\"Calculate similarity threshold via percentile.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            float: Computed threshold.\n",
      "        \"\"\"\n",
      "        # 中文注释: 根据percentile计算相似度阈值。\n",
      "        all_similarities = self._compute_pairwise_similarities(sentences)\n",
      "        return float(np.percentile(all_similarities, 100 - self.similarity_percentile))\n",
      "\n",
      "    def _calculate_similarity_threshold(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> float:\n",
      "        \"\"\"Calculate similarity threshold either through binary search or percentile.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            float: Computed similarity threshold.\n",
      "        \"\"\"\n",
      "        # 中文注释: 根据配置决定使用固定值、percentile还是binary search。\n",
      "        if self.similarity_threshold is not None:\n",
      "            return self.similarity_threshold\n",
      "        elif self.similarity_percentile is not None:\n",
      "            return self._calculate_threshold_via_percentile(sentences)\n",
      "        else:\n",
      "            return self._calculate_threshold_via_binary_search(sentences)\n",
      "\n",
      "    def _group_sentences_cumulative(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> List[List[SemanticSentence]]:\n",
      "        \"\"\"Group sentences based on cumulative semantic similarity.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            List[List[SemanticSentence]]: Grouped sentences.\n",
      "        \"\"\"\n",
      "        # 中文注释: 累计方式分组，根据当前组平均embedding与新句子的相似度决定是否加入同组。\n",
      "        groups = []\n",
      "        if not sentences:\n",
      "            return groups\n",
      "\n",
      "        current_group = sentences[: self.initial_sentences]\n",
      "        current_embedding = self._compute_group_embedding(current_group)\n",
      "\n",
      "        for sentence in sentences[self.initial_sentences :]:\n",
      "            similarity = self._get_semantic_similarity(\n",
      "                current_embedding, sentence.embedding\n",
      "            )\n",
      "            if similarity >= self.similarity_threshold:\n",
      "                current_group.append(sentence)\n",
      "                current_embedding = self._compute_group_embedding(current_group)\n",
      "            else:\n",
      "                if current_group:\n",
      "                    groups.append(current_group)\n",
      "                current_group = [sentence]\n",
      "                current_embedding = sentence.embedding\n",
      "\n",
      "        if current_group:\n",
      "            groups.append(current_group)\n",
      "\n",
      "        return groups\n",
      "\n",
      "    def _group_sentences_window(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> List[List[SemanticSentence]]:\n",
      "        \"\"\"Group sentences based on semantic similarity using a window-based approach.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            List[List[SemanticSentence]]: Grouped sentences.\n",
      "        \"\"\"\n",
      "        # 中文注释: 窗口模式下根据相邻句子相似度和阈值分割。\n",
      "        similarities = self._compute_pairwise_similarities(sentences)\n",
      "        split_indices = self._get_split_indices(similarities, self.similarity_threshold)\n",
      "        groups = [\n",
      "            sentences[split_indices[i] : split_indices[i + 1]]\n",
      "            for i in range(len(split_indices) - 1)\n",
      "        ]\n",
      "        return groups\n",
      "\n",
      "    def _group_sentences(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "    ) -> List[List[SemanticSentence]]:\n",
      "        \"\"\"Group sentences based on semantic similarity, either cumulatively or by window.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            List[List[SemanticSentence]]: Grouped sentences.\n",
      "        \"\"\"\n",
      "        # 中文注释: 根据mode选择分组方式。\n",
      "        if self.mode == \"cumulative\":\n",
      "            return self._group_sentences_cumulative(sentences)\n",
      "        else:\n",
      "            return self._group_sentences_window(sentences)\n",
      "\n",
      "    def _create_chunk(self, sentences: List[SemanticSentence]) -> SemanticChunk:\n",
      "        \"\"\"Create a chunk from a list of sentences.\n",
      "\n",
      "        Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "\n",
      "        Returns:\n",
      "            SemanticChunk: Created chunk.\n",
      "        \"\"\"\n",
      "        # 中文注释: 将句子列表合并为一个chunk，并计算chunk的embedding。\n",
      "        if not sentences:\n",
      "            raise ValueError(\"Cannot create chunk from empty sentence list\")\n",
      "\n",
      "        text = \"\".join(sent.text for sent in sentences)\n",
      "        token_count = sum(sent.token_count for sent in sentences) + (len(sentences) - 1)\n",
      "        # 在这里计算并存储chunk级别的embedding\n",
      "        chunk_embedding = self._compute_group_embedding(sentences)\n",
      "\n",
      "        return SemanticChunk(\n",
      "            text=text,\n",
      "            start_index=sentences[0].start_index,\n",
      "            end_index=sentences[-1].end_index,\n",
      "            token_count=token_count,\n",
      "            sentences=sentences,\n",
      "            chunk_embedding=chunk_embedding,\n",
      "        )\n",
      "\n",
      "    def _split_chunks(\n",
      "        self, sentence_groups: List[List[SemanticSentence]]\n",
      "    ) -> List[SemanticChunk]:\n",
      "        \"\"\"Split sentence groups into chunks that respect chunk_size.\n",
      "\n",
      "        Args:\n",
      "            sentence_groups (List[List[SemanticSentence]]): Semantically coherent sentence groups.\n",
      "\n",
      "        Returns:\n",
      "            List[SemanticChunk]: List of SemanticChunk objects.\n",
      "        \"\"\"\n",
      "        # 中文注释: 将句子组按照chunk_size划分为更小的chunk。\n",
      "        chunks = []\n",
      "\n",
      "        for group in sentence_groups:\n",
      "            current_chunk_sentences = []\n",
      "            current_tokens = 0\n",
      "\n",
      "            for sentence in group:\n",
      "                test_tokens = (\n",
      "                    current_tokens\n",
      "                    + sentence.token_count\n",
      "                    + (1 if current_chunk_sentences else 0)\n",
      "                )\n",
      "\n",
      "                if test_tokens <= self.chunk_size:\n",
      "                    current_chunk_sentences.append(sentence)\n",
      "                    current_tokens = test_tokens\n",
      "                else:\n",
      "                    if current_chunk_sentences:\n",
      "                        chunks.append(self._create_chunk(current_chunk_sentences))\n",
      "                    current_chunk_sentences = [sentence]\n",
      "                    current_tokens = sentence.token_count\n",
      "\n",
      "            if current_chunk_sentences:\n",
      "                chunks.append(self._create_chunk(current_chunk_sentences))\n",
      "\n",
      "        return chunks\n",
      "\n",
      "    def chunk(self, text: str) -> List[SemanticChunk]:\n",
      "        \"\"\"Split text into semantically coherent chunks using a two-pass approach.\n",
      "\n",
      "        Args:\n",
      "            text (str): Input text to be chunked.\n",
      "\n",
      "        Returns:\n",
      "            List[SemanticChunk]: List of SemanticChunk objects containing chunked text and metadata.\n",
      "        \"\"\"\n",
      "        # 中文注释: 主流程：先准备句子与embedding，再计算相似度阈值，然后分组和二次分块。\n",
      "        if not text.strip():\n",
      "            return []\n",
      "\n",
      "        sentences = self._prepare_sentences(text)\n",
      "        if len(sentences) <= self.min_sentences:\n",
      "            # 所有句子过少，直接作为一个chunk返回\n",
      "            if sentences:\n",
      "                return [s\n",
      "\n",
      "文本已分成 281 块。\n",
      "分块结果:\n",
      "Chunk 1: -> List[np.ndarray]:\n",
      "        \"\"\"Embed a batch of texts and return a list of embedding vectors.\n",
      "Chunk 2: Args:\n",
      "            texts (List[str]): List of texts to embed.\n",
      "Chunk 3: Returns:\n",
      "            List[np.ndarray]: List of embedding vectors.\n",
      "        \"\"\"\n",
      "Chunk 4: \"\"\"\n",
      "        # 中文注释: 返回模拟的随机嵌入向量，实际情况需调用真实模型方法。\n",
      "Chunk 5: # return [np.random.rand(self.embedding_dim).astype(np.float32) for _ in texts]\n",
      "Chunk 6: # embeddings = embedding_api(texts)\n",
      "        # 每十个文本一组，避免一次请求过多文本\n",
      "        batch_size = 10\n",
      "Chunk 7: embeddings = []\n",
      "        for i in range(0, len(texts), batch_size):\n",
      "Chunk 8: batch_texts = texts[i : i + batch_size]\n",
      "Chunk 9: response = self.embedding_client.get_embeddings(batch_texts)\n",
      "Chunk 10: batch_embeddings = response.get(\"data\", {}).get(\"resultList\", [])\n",
      "Chunk 11: embeddings.extend(batch_embeddings)\n",
      "Chunk 12: return [np.array(embedding).astype(np.float32) for embedding in embeddings]\n",
      "Chunk 13: def similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:\n",
      "Chunk 14: \"\"\"Compute cosine similarity between two embeddings.\n",
      "Chunk 15: Args:\n",
      "            embedding1 (np.ndarray): Embedding vector 1.\n",
      "Chunk 16: embedding2 (np.ndarray): Embedding vector 2.\n",
      "Chunk 17: Returns:\n",
      "            float: Cosine similarity between the two embeddings.\n",
      "        \"\"\"\n",
      "Chunk 18: \"\"\"\n",
      "        return float(np.dot(embedding1, embedding2))\n",
      "Chunk 19: class Sentence:\n",
      "    \"\"\"A simple Sentence class to store raw sentence text and metadata.\"\"\"\n",
      "Chunk 20: def __init__(self, text: str, start_index: int, end_index: int):\n",
      "Chunk 21: # 中文注释: 基础句子类，用于存储句子文本和起始结束位置。\n",
      "        self.text = text\n",
      "Chunk 22: self.start_index = start_index\n",
      "        self.end_index = end_index\n",
      "Chunk 23: class SemanticSentence(Sentence):\n",
      "Chunk 24: \"\"\"A SemanticSentence class that includes embedding and token count information.\"\"\"\n",
      "Chunk 25: def __init__(\n",
      "        self,\n",
      "        text: str,\n",
      "        start_index: int,\n",
      "Chunk 26: end_index: int,\n",
      "        token_count: int,\n",
      "        embedding: np.ndarray,\n",
      "    ):\n",
      "Chunk 27: ):\n",
      "        # 中文注释: 扩展的句子类，包含嵌入向量和token计数信息。\n",
      "Chunk 28: super().__init__(text, start_index, end_index)\n",
      "        self.token_count = token_count\n",
      "Chunk 29: self.embedding = embedding\n",
      "Chunk 30: class SemanticChunk:\n",
      "    \"\"\"A SemanticChunk class representing a coherent text chunk.\"\"\"\n",
      "Chunk 31: def __init__(\n",
      "        self,\n",
      "        text: str,\n",
      "        start_index: int,\n",
      "Chunk 32: end_index: int,\n",
      "        token_count: int,\n",
      "        sentences: List[SemanticSentence],\n",
      "Chunk 33: chunk_embedding: np.ndarray,\n",
      "    ):\n",
      "Chunk 34: ):\n",
      "        # 中文注释: 语义块类，包含块文本、起止位置、token计数及所属句子列表、以及预先计算好的chunk embedding。\n",
      "Chunk 35: self.text = text\n",
      "        self.start_index = start_index\n",
      "        self.end_index = end_index\n",
      "Chunk 36: self.token_count = token_count\n",
      "        self.sentences = sentences\n",
      "Chunk 37: self.chunk_embedding = chunk_embedding\n",
      "Chunk 38: class SemanticChunker:\n",
      "Chunk 39: \"\"\"A SemanticChunker class to split text into semantically coherent chunks.\n",
      "Chunk 40: This class:\n",
      "    - Splits text into sentences.\n",
      "    - Computes embeddings for sentences.\n",
      "Chunk 41: - Groups sentences based on semantic similarity.\n",
      "Chunk 42: - Splits groups into chunks that respect a specified maximum size.\n",
      "Chunk 43: Attributes:\n",
      "        embedding_model (EmbeddingModel): The embedding model.\n",
      "Chunk 44: min_characters_per_sentence (int): Minimum char length to consider a valid sentence.\n",
      "Chunk 45: similarity_threshold (Optional[float]): Fixed similarity threshold or None.\n",
      "Chunk 46: similarity_percentile (Optional[float]): Percentile to compute dynamic threshold.\n",
      "Chunk 47: similarity_window (int): Window size for window-based grouping mode.\n",
      "Chunk 48: mode (str): \"cumulative\" or \"window\" grouping mode.\n",
      "Chunk 49: initial_sentences (int): Initial number of sentences to start the cumulative grouping.\n",
      "Chunk 50: min_sentences (int): Minimum number of sentences per chunk/group.\n",
      "Chunk 51: chunk_size (int): Maximum token count allowed per chunk.\n",
      "Chunk 52: min_chunk_size (int): Minimum token count per chunk.\n",
      "Chunk 53: threshold_step (float): Step size for binary search threshold adjustments.\n",
      "Chunk 54: sep (str): Separator for sentence splitting.\n",
      "    \"\"\"\n",
      "Chunk 55: def __init__(\n",
      "        self,\n",
      "        embedding_model: EmbeddingModel,\n",
      "Chunk 56: min_characters_per_sentence: int = 5,\n",
      "        similarity_threshold: Optional[float] = None,\n",
      "Chunk 57: similarity_percentile: Optional[float] = 90,\n",
      "        similarity_window: int = 1,\n",
      "Chunk 58: mode: str = \"cumulative\",\n",
      "        initial_sentences: int = 1,\n",
      "Chunk 59: min_sentences: int = 1,\n",
      "        chunk_size: int = 200,\n",
      "        min_chunk_size: int = 50,\n",
      "Chunk 60: threshold_step: float = 0.05,\n",
      "        sep: str = \"🐮🍺\",\n",
      "    ):\n",
      "Chunk 61: ):\n",
      "        # 中文注释: 初始化分块器参数，支持两种模式并设置各种限制参数和分句分隔符。\n",
      "Chunk 62: self.embedding_model = embedding_model\n",
      "Chunk 63: self.min_characters_per_sentence = min_characters_per_sentence\n",
      "Chunk 64: self.similarity_threshold = similarity_threshold\n",
      "Chunk 65: self.similarity_percentile = similarity_percentile\n",
      "Chunk 66: self.similarity_window = similarity_window\n",
      "        self.mode = mode\n",
      "Chunk 67: self.initial_sentences = initial_sentences\n",
      "        self.min_sentences = min_sentences\n",
      "Chunk 68: self.chunk_size = chunk_size\n",
      "        self.min_chunk_size = min_chunk_size\n",
      "Chunk 69: self.threshold_step = threshold_step\n",
      "        self.sep = sep\n",
      "Chunk 70: self.splitter = GeneralTextSplitter(max_sentence_length=120)\n",
      "Chunk 71: def _count_tokens(self, text: str) -> int:\n",
      "Chunk 72: \"\"\"Count approximate tokens in text based on whitespace splitting.\n",
      "Chunk 73: Args:\n",
      "            text (str): Input text.\n",
      "Chunk 74: Returns:\n",
      "            int: Approximate token count.\n",
      "        \"\"\"\n",
      "Chunk 75: \"\"\"\n",
      "        # 中文注释: 粗略计算token数，实际可使用更严格的tokenizer。\n",
      "        return len(text.split())\n",
      "Chunk 76: def _count_tokens_batch(self, texts: List[str]) -> List[int]:\n",
      "Chunk 77: \"\"\"Count tokens for a batch of texts.\n",
      "Chunk 78: Args:\n",
      "            texts (List[str]): Input texts.\n",
      "Chunk 79: Returns:\n",
      "            List[int]: List of token counts.\n",
      "        \"\"\"\n",
      "Chunk 80: \"\"\"\n",
      "        # 中文注释: 批量计算token数。\n",
      "        return [self._count_tokens(t) for t in texts]\n",
      "Chunk 81: def _split_sentences(self, text: str) -> List[str]:\n",
      "Chunk 82: \"\"\"Fast sentence splitting while maintaining accuracy.\n",
      "Chunk 83: This method is faster than using regex for sentence splitting and\n",
      "Chunk 84: more accurate than using spaCy sentence tokenizer.\n",
      "Chunk 85: Args:\n",
      "            text (str): Input text to be split into sentences.\n",
      "Chunk 86: Returns:\n",
      "            List[str]: List of sentences.\n",
      "        \"\"\"\n",
      "Chunk 87: \"\"\"\n",
      "        sentences = self.splitter.split_text(text)\n",
      "        return sentences\n",
      "Chunk 88: def _compute_similarity_threshold(self, all_similarities: List[float]) -> float:\n",
      "Chunk 89: \"\"\"Compute similarity threshold based on percentile if specified.\"\"\"\n",
      "Chunk 90: # 中文注释: 若设置了固定threshold则返回，否则按percentile计算。\n",
      "Chunk 91: if self.similarity_threshold is not None:\n",
      "            return self.similarity_threshold\n",
      "Chunk 92: else:\n",
      "            return float(np.percentile(all_similarities, self.similarity_percentile))\n",
      "Chunk 93: def _prepare_sentences(self, text: str) -> List[SemanticSentence]:\n",
      "Chunk 94: \"\"\"Prepare sentences with precomputed information.\n",
      "Chunk 95: Args:\n",
      "            text (str): Input text to be processed.\n",
      "Chunk 96: Returns:\n",
      "Chunk 97: List[SemanticSentence]: List of Sentence objects with precomputed embeddings.\n",
      "Chunk 98: \"\"\"\n",
      "        # 中文注释: 将文本分句，计算句子embedding和token数，并构建SemanticSentence对象列表。\n",
      "Chunk 99: if not text.strip():\n",
      "            return []\n",
      "Chunk 100: raw_sentences = self._split_sentences(text)\n",
      "Chunk 101: # Compute start/end indices\n",
      "        sentence_indices = []\n",
      "        current_idx = 0\n",
      "Chunk 102: for sent in raw_sentences:\n",
      "            start_idx = text.find(sent, current_idx)\n",
      "Chunk 103: end_idx = start_idx + len(sent)\n",
      "Chunk 104: sentence_indices.append((start_idx, end_idx))\n",
      "            current_idx = end_idx\n",
      "Chunk 105: # Create sentence groups for embedding computation\n",
      "        sentence_groups = []\n",
      "Chunk 106: for i in range(len(raw_sentences)):\n",
      "            group = []\n",
      "Chunk 107: for j in range(i - self.similarity_window, i + self.similarity_window + 1):\n",
      "Chunk 108: if 0 <= j < len(raw_sentences):\n",
      "                    group.append(raw_sentences[j])\n",
      "Chunk 109: sentence_groups.append(\"\".join(group))\n",
      "Chunk 110: # Compute embeddings\n",
      "Chunk 111: embeddings = self.embedding_model.embed_batch(sentence_groups)\n",
      "Chunk 112: # Compute token counts\n",
      "        token_counts = self._count_tokens_batch(raw_sentences)\n",
      "Chunk 113: sentences = [\n",
      "            SemanticSentence(\n",
      "                text=sent,\n",
      "Chunk 114: start_index=start_idx,\n",
      "                end_index=end_idx,\n",
      "Chunk 115: token_count=count,\n",
      "                embedding=embedding,\n",
      "            )\n",
      "Chunk 116: )\n",
      "            for sent, (start_idx, end_idx), count, embedding in zip(\n",
      "Chunk 117: raw_sentences, sentence_indices, token_counts, embeddings\n",
      "            )\n",
      "        ]\n",
      "Chunk 118: return sentences\n",
      "Chunk 119: def _get_semantic_similarity(\n",
      "        self, embedding1: np.ndarray, embedding2: np.ndarray\n",
      "Chunk 120: ) -> float:\n",
      "        \"\"\"Compute cosine similarity between two embeddings.\"\"\"\n",
      "Chunk 121: # 中文注释: 简化调用embedding_model的similarity方法。\n",
      "Chunk 122: return self.embedding_model.similarity(embedding1, embedding2)\n",
      "Chunk 123: def _compute_group_embedding(self, sentences: List[SemanticSentence]) -> np.ndarray:\n",
      "Chunk 124: \"\"\"Compute mean embedding for a group of sentences.\n",
      "Chunk 125: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 126: Returns:\n",
      "            np.ndarray: Mean embedding vector.\n",
      "        \"\"\"\n",
      "Chunk 127: \"\"\"\n",
      "        # 中文注释: 加权平均，考虑token数对平均值的影响。\n",
      "        return np.divide(\n",
      "Chunk 128: np.sum([(sent.embedding * sent.token_count) for sent in sentences], axis=0),\n",
      "Chunk 129: np.sum([sent.token_count for sent in sentences]),\n",
      "            dtype=np.float32,\n",
      "Chunk 130: )\n",
      "Chunk 131: def _compute_pairwise_similarities(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 132: ) -> List[float]:\n",
      "        \"\"\"Compute all pairwise similarities between sentences.\n",
      "Chunk 133: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 134: Returns:\n",
      "            List[float]: List of similarities between consecutive sentences.\n",
      "Chunk 135: \"\"\"\n",
      "        # 中文注释: 计算相邻句子间相似度。\n",
      "        return [\n",
      "            self._get_semantic_similarity(\n",
      "Chunk 136: sentences[i].embedding, sentences[i + 1].embedding\n",
      "            )\n",
      "Chunk 137: )\n",
      "            for i in range(len(sentences) - 1)\n",
      "        ]\n",
      "Chunk 138: def _get_split_indices(\n",
      "        self, similarities: List[float], threshold: float = None\n",
      "Chunk 139: ) -> List[int]:\n",
      "        \"\"\"Get indices of sentences to split at.\n",
      "Chunk 140: Args:\n",
      "            similarities (List[float]): List of pairwise similarities.\n",
      "Chunk 141: threshold (float): Similarity threshold.\n",
      "Chunk 142: Returns:\n",
      "            List[int]: Indices indicating the split points.\n",
      "        \"\"\"\n",
      "Chunk 143: \"\"\"\n",
      "        # 中文注释: 根据相似度阈值确定分组的切分点。\n",
      "        if threshold is None:\n",
      "Chunk 144: threshold = (\n",
      "                self.similarity_threshold\n",
      "Chunk 145: if self.similarity_threshold is not None\n",
      "                else 0.5\n",
      "            )\n",
      "Chunk 146: # Get indices of sentences that are below the threshold\n",
      "        splits = [\n",
      "Chunk 147: splits = [\n",
      "            i + 1\n",
      "            for i, s in enumerate(similarities)\n",
      "Chunk 148: if s <= threshold and i + 1 < len(similarities) + 1\n",
      "        ]\n",
      "Chunk 149: # Add the start and end of the text\n",
      "Chunk 150: splits = [0] + splits + [len(similarities) + 1]\n",
      "Chunk 151: # Ensure minimum sentences per group\n",
      "        i = 0\n",
      "        while i < len(splits) - 1:\n",
      "Chunk 152: if splits[i + 1] - splits[i] < self.min_sentences:\n",
      "                splits.pop(i + 1)\n",
      "Chunk 153: else:\n",
      "                i += 1\n",
      "        return splits\n",
      "Chunk 154: def _calculate_threshold_via_binary_search(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 155: ) -> float:\n",
      "        \"\"\"Calculate similarity threshold via binary search.\n",
      "Chunk 156: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 157: Returns:\n",
      "            float: Computed threshold.\n",
      "        \"\"\"\n",
      "Chunk 158: \"\"\"\n",
      "        # 中文注释: 通过binary search来寻找合适的相似度阈值，使分块满足大小要求。\n",
      "Chunk 159: token_counts = [sent.token_count for sent in sentences]\n",
      "Chunk 160: similarities = self._compute_pairwise_similarities(sentences)\n",
      "Chunk 161: median = np.median(similarities)\n",
      "        std = np.std(similarities)\n",
      "Chunk 162: low = max(median - 1 * std, 0.0)\n",
      "        high = min(median + 1 * std, 1.0)\n",
      "Chunk 163: iterations = 0\n",
      "        threshold = (low + high) / 2\n",
      "Chunk 164: while abs(high - low) > self.threshold_step:\n",
      "            threshold = (low + high) / 2\n",
      "Chunk 165: split_indices = self._get_split_indices(similarities, threshold)\n",
      "Chunk 166: # Extract token counts of each segment\n",
      "            segment_lengths = []\n",
      "Chunk 167: for i in range(len(split_indices) - 1):\n",
      "                start = split_indices[i]\n",
      "Chunk 168: end = split_indices[i + 1]\n",
      "Chunk 169: segment_token_count = sum(token_counts[start:end])\n",
      "Chunk 170: segment_lengths.append(segment_token_count)\n",
      "Chunk 171: # Check condition: ideally segment lengths between min_chunk_size and chunk_size\n",
      "Chunk 172: if all(\n",
      "                self.min_chunk_size <= length <= self.chunk_size\n",
      "Chunk 173: for length in segment_lengths\n",
      "            ):\n",
      "                break\n",
      "Chunk 174: elif any(length > self.chunk_size for length in segment_lengths):\n",
      "Chunk 175: # 若有超过chunk_size的分段，增加threshold降低分组数量\n",
      "Chunk 176: low = threshold + self.threshold_step\n",
      "            else:\n",
      "Chunk 177: else:\n",
      "                # 若有分段小于min_chunk_size，减少threshold增加分组数量\n",
      "Chunk 178: high = threshold - self.threshold_step\n",
      "Chunk 179: iterations += 1\n",
      "            if iterations > 10:\n",
      "                warnings.warn(\n",
      "Chunk 180: \"Too many iterations in threshold calculation, stopping...\",\n",
      "Chunk 181: stacklevel=2,\n",
      "                )\n",
      "                break\n",
      "Chunk 182: return threshold\n",
      "Chunk 183: def _calculate_threshold_via_percentile(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 184: ) -> float:\n",
      "        \"\"\"Calculate similarity threshold via percentile.\n",
      "Chunk 185: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 186: Returns:\n",
      "            float: Computed threshold.\n",
      "        \"\"\"\n",
      "Chunk 187: \"\"\"\n",
      "        # 中文注释: 根据percentile计算相似度阈值。\n",
      "Chunk 188: all_similarities = self._compute_pairwise_similarities(sentences)\n",
      "Chunk 189: return float(np.percentile(all_similarities, 100 - self.similarity_percentile))\n",
      "Chunk 190: def _calculate_similarity_threshold(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 191: ) -> float:\n",
      "Chunk 192: \"\"\"Calculate similarity threshold either through binary search or percentile.\n",
      "Chunk 193: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 194: Returns:\n",
      "            float: Computed similarity threshold.\n",
      "        \"\"\"\n",
      "Chunk 195: \"\"\"\n",
      "        # 中文注释: 根据配置决定使用固定值、percentile还是binary search。\n",
      "Chunk 196: if self.similarity_threshold is not None:\n",
      "            return self.similarity_threshold\n",
      "Chunk 197: elif self.similarity_percentile is not None:\n",
      "Chunk 198: return self._calculate_threshold_via_percentile(sentences)\n",
      "        else:\n",
      "Chunk 199: else:\n",
      "            return self._calculate_threshold_via_binary_search(sentences)\n",
      "Chunk 200: def _group_sentences_cumulative(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 201: ) -> List[List[SemanticSentence]]:\n",
      "Chunk 202: \"\"\"Group sentences based on cumulative semantic similarity.\n",
      "Chunk 203: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 204: Returns:\n",
      "            List[List[SemanticSentence]]: Grouped sentences.\n",
      "        \"\"\"\n",
      "Chunk 205: \"\"\"\n",
      "        # 中文注释: 累计方式分组，根据当前组平均embedding与新句子的相似度决定是否加入同组。\n",
      "        groups = []\n",
      "Chunk 206: groups = []\n",
      "        if not sentences:\n",
      "            return groups\n",
      "Chunk 207: current_group = sentences[: self.initial_sentences]\n",
      "Chunk 208: current_embedding = self._compute_group_embedding(current_group)\n",
      "Chunk 209: for sentence in sentences[self.initial_sentences :]:\n",
      "Chunk 210: similarity = self._get_semantic_similarity(\n",
      "Chunk 211: current_embedding, sentence.embedding\n",
      "            )\n",
      "Chunk 212: )\n",
      "            if similarity >= self.similarity_threshold:\n",
      "Chunk 213: current_group.append(sentence)\n",
      "Chunk 214: current_embedding = self._compute_group_embedding(current_group)\n",
      "            else:\n",
      "Chunk 215: else:\n",
      "                if current_group:\n",
      "Chunk 216: groups.append(current_group)\n",
      "                current_group = [sentence]\n",
      "Chunk 217: current_embedding = sentence.embedding\n",
      "Chunk 218: if current_group:\n",
      "            groups.append(current_group)\n",
      "\n",
      "        return groups\n",
      "Chunk 219: def _group_sentences_window(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 220: ) -> List[List[SemanticSentence]]:\n",
      "Chunk 221: \"\"\"Group sentences based on semantic similarity using a window-based approach.\n",
      "Chunk 222: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 223: Returns:\n",
      "            List[List[SemanticSentence]]: Grouped sentences.\n",
      "        \"\"\"\n",
      "Chunk 224: \"\"\"\n",
      "        # 中文注释: 窗口模式下根据相邻句子相似度和阈值分割。\n",
      "Chunk 225: similarities = self._compute_pairwise_similarities(sentences)\n",
      "Chunk 226: split_indices = self._get_split_indices(similarities, self.similarity_threshold)\n",
      "Chunk 227: groups = [\n",
      "            sentences[split_indices[i] : split_indices[i + 1]]\n",
      "Chunk 228: for i in range(len(split_indices) - 1)\n",
      "        ]\n",
      "        return groups\n",
      "Chunk 229: def _group_sentences(\n",
      "        self, sentences: List[SemanticSentence]\n",
      "Chunk 230: ) -> List[List[SemanticSentence]]:\n",
      "Chunk 231: \"\"\"Group sentences based on semantic similarity, either cumulatively or by window.\n",
      "Chunk 232: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 233: Returns:\n",
      "            List[List[SemanticSentence]]: Grouped sentences.\n",
      "        \"\"\"\n",
      "Chunk 234: \"\"\"\n",
      "        # 中文注释: 根据mode选择分组方式。\n",
      "        if self.mode == \"cumulative\":\n",
      "Chunk 235: return self._group_sentences_cumulative(sentences)\n",
      "        else:\n",
      "Chunk 236: else:\n",
      "            return self._group_sentences_window(sentences)\n",
      "Chunk 237: def _create_chunk(self, sentences: List[SemanticSentence]) -> SemanticChunk:\n",
      "Chunk 238: \"\"\"Create a chunk from a list of sentences.\n",
      "Chunk 239: Args:\n",
      "            sentences (List[SemanticSentence]): Input sentences.\n",
      "Chunk 240: Returns:\n",
      "            SemanticChunk: Created chunk.\n",
      "        \"\"\"\n",
      "Chunk 241: \"\"\"\n",
      "        # 中文注释: 将句子列表合并为一个chunk，并计算chunk的embedding。\n",
      "        if not sentences:\n",
      "Chunk 242: raise ValueError(\"Cannot create chunk from empty sentence list\")\n",
      "Chunk 243: text = \"\".join(sent.text for sent in sentences)\n",
      "Chunk 244: token_count = sum(sent.token_count for sent in sentences) + (len(sentences) - 1)\n",
      "Chunk 245: # 在这里计算并存储chunk级别的embedding\n",
      "Chunk 246: chunk_embedding = self._compute_group_embedding(sentences)\n",
      "Chunk 247: return SemanticChunk(\n",
      "            text=text,\n",
      "Chunk 248: start_index=sentences[0].start_index,\n",
      "            end_index=sentences[-1].end_index,\n",
      "Chunk 249: token_count=token_count,\n",
      "            sentences=sentences,\n",
      "Chunk 250: chunk_embedding=chunk_embedding,\n",
      "        )\n",
      "Chunk 251: def _split_chunks(\n",
      "        self, sentence_groups: List[List[SemanticSentence]]\n",
      "Chunk 252: ) -> List[SemanticChunk]:\n",
      "        \"\"\"Split sentence groups into chunks that respect chunk_size.\n",
      "Chunk 253: Args:\n",
      "Chunk 254: sentence_groups (List[List[SemanticSentence]]): Semantically coherent sentence groups.\n",
      "Chunk 255: Returns:\n",
      "            List[SemanticChunk]: List of SemanticChunk objects.\n",
      "        \"\"\"\n",
      "Chunk 256: \"\"\"\n",
      "        # 中文注释: 将句子组按照chunk_size划分为更小的chunk。\n",
      "        chunks = []\n",
      "Chunk 257: for group in sentence_groups:\n",
      "            current_chunk_sentences = []\n",
      "Chunk 258: current_tokens = 0\n",
      "Chunk 259: for sentence in group:\n",
      "                test_tokens = (\n",
      "Chunk 260: current_tokens\n",
      "                    + sentence.token_count\n",
      "Chunk 261: + (1 if current_chunk_sentences else 0)\n",
      "                )\n",
      "Chunk 262: if test_tokens <= self.chunk_size:\n",
      "Chunk 263: current_chunk_sentences.append(sentence)\n",
      "Chunk 264: current_tokens = test_tokens\n",
      "                else:\n",
      "Chunk 265: if current_chunk_sentences:\n",
      "Chunk 266: chunks.append(self._create_chunk(current_chunk_sentences))\n",
      "Chunk 267: current_chunk_sentences = [sentence]\n",
      "Chunk 268: current_tokens = sentence.token_count\n",
      "Chunk 269: if current_chunk_sentences:\n",
      "Chunk 270: chunks.append(self._create_chunk(current_chunk_sentences))\n",
      "Chunk 271: return chunks\n",
      "Chunk 272: def chunk(self, text: str) -> List[SemanticChunk]:\n",
      "Chunk 273: \"\"\"Split text into semantically coherent chunks using a two-pass approach.\n",
      "Chunk 274: Args:\n",
      "            text (str): Input text to be chunked.\n",
      "Chunk 275: Returns:\n",
      "Chunk 276: List[SemanticChunk]: List of SemanticChunk objects containing chunked text and\n",
      "Chunk 277: chunked text and metadata.\n",
      "Chunk 278: \"\"\"\n",
      "        # 中文注释: 主流程：先准备句子与embedding，再计算相似度阈值，然后分组和二次分块。\n",
      "        if not text.strip():\n",
      "Chunk 279: return []\n",
      "Chunk 280: sentences = self._prepare_sentences(text)\n",
      "        if len(sentences) <= self.min_sentences:\n",
      "Chunk 281: # 所有句子过少，直接作为一个chunk返回\n",
      "            if sentences:\n",
      "                return [s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">-> List[np.ndarray]:\n",
       "        \"\"\"Embed a batch of texts and return a list of embedding vectors.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            texts (List[str]): List of texts to embed.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[np.ndarray]: List of embedding vectors.\n",
       "        \"\"\"</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 返回模拟的随机嵌入向量，实际情况需调用真实模型方法。</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># return [np.random.rand(self.embedding_dim).astype(np.float32) for _ in texts]</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># embeddings = embedding_api(texts)\n",
       "        # 每十个文本一组，避免一次请求过多文本\n",
       "        batch_size = 10</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">embeddings = []\n",
       "        for i in range(0, len(texts), batch_size):</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">batch_texts = texts[i : i + batch_size]</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">response = self.embedding_client.get_embeddings(batch_texts)</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">batch_embeddings = response.get(\"data\", {}).get(\"resultList\", [])</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">embeddings.extend(batch_embeddings)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return [np.array(embedding).astype(np.float32) for embedding in embeddings]</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def similarity(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Compute cosine similarity between two embeddings.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            embedding1 (np.ndarray): Embedding vector 1.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">embedding2 (np.ndarray): Embedding vector 2.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            float: Cosine similarity between the two embeddings.\n",
       "        \"\"\"</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        return float(np.dot(embedding1, embedding2))</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">class Sentence:\n",
       "    \"\"\"A simple Sentence class to store raw sentence text and metadata.\"\"\"</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def __init__(self, text: str, start_index: int, end_index: int):</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># 中文注释: 基础句子类，用于存储句子文本和起始结束位置。\n",
       "        self.text = text</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.start_index = start_index\n",
       "        self.end_index = end_index</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">class SemanticSentence(Sentence):</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"A SemanticSentence class that includes embedding and token count information.\"\"\"</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def __init__(\n",
       "        self,\n",
       "        text: str,\n",
       "        start_index: int,</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">end_index: int,\n",
       "        token_count: int,\n",
       "        embedding: np.ndarray,\n",
       "    ):</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">):\n",
       "        # 中文注释: 扩展的句子类，包含嵌入向量和token计数信息。</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">super().__init__(text, start_index, end_index)\n",
       "        self.token_count = token_count</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.embedding = embedding</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">class SemanticChunk:\n",
       "    \"\"\"A SemanticChunk class representing a coherent text chunk.\"\"\"</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def __init__(\n",
       "        self,\n",
       "        text: str,\n",
       "        start_index: int,</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">end_index: int,\n",
       "        token_count: int,\n",
       "        sentences: List[SemanticSentence],</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunk_embedding: np.ndarray,\n",
       "    ):</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">):\n",
       "        # 中文注释: 语义块类，包含块文本、起止位置、token计数及所属句子列表、以及预先计算好的chunk embedding。</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.text = text\n",
       "        self.start_index = start_index\n",
       "        self.end_index = end_index</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.token_count = token_count\n",
       "        self.sentences = sentences</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.chunk_embedding = chunk_embedding</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">class SemanticChunker:</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"A SemanticChunker class to split text into semantically coherent chunks.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This class:\n",
       "    - Splits text into sentences.\n",
       "    - Computes embeddings for sentences.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- Groups sentences based on semantic similarity.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">- Splits groups into chunks that respect a specified maximum size.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Attributes:\n",
       "        embedding_model (EmbeddingModel): The embedding model.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">min_characters_per_sentence (int): Minimum char length to consider a valid sentence.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarity_threshold (Optional[float]): Fixed similarity threshold or None.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarity_percentile (Optional[float]): Percentile to compute dynamic threshold.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarity_window (int): Window size for window-based grouping mode.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mode (str): \"cumulative\" or \"window\" grouping mode.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">initial_sentences (int): Initial number of sentences to start the cumulative grouping.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">min_sentences (int): Minimum number of sentences per chunk/group.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunk_size (int): Maximum token count allowed per chunk.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">min_chunk_size (int): Minimum token count per chunk.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">threshold_step (float): Step size for binary search threshold adjustments.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sep (str): Separator for sentence splitting.\n",
       "    \"\"\"</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def __init__(\n",
       "        self,\n",
       "        embedding_model: EmbeddingModel,</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">min_characters_per_sentence: int = 5,\n",
       "        similarity_threshold: Optional[float] = None,</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarity_percentile: Optional[float] = 90,\n",
       "        similarity_window: int = 1,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">mode: str = \"cumulative\",\n",
       "        initial_sentences: int = 1,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">min_sentences: int = 1,\n",
       "        chunk_size: int = 200,\n",
       "        min_chunk_size: int = 50,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">threshold_step: float = 0.05,\n",
       "        sep: str = \"🐮🍺\",\n",
       "    ):</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">):\n",
       "        # 中文注释: 初始化分块器参数，支持两种模式并设置各种限制参数和分句分隔符。</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.embedding_model = embedding_model</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.min_characters_per_sentence = min_characters_per_sentence</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.similarity_threshold = similarity_threshold</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.similarity_percentile = similarity_percentile</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.similarity_window = similarity_window\n",
       "        self.mode = mode</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.initial_sentences = initial_sentences\n",
       "        self.min_sentences = min_sentences</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.chunk_size = chunk_size\n",
       "        self.min_chunk_size = min_chunk_size</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.threshold_step = threshold_step\n",
       "        self.sep = sep</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">self.splitter = GeneralTextSplitter(max_sentence_length=120)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _count_tokens(self, text: str) -> int:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Count approximate tokens in text based on whitespace splitting.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            text (str): Input text.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            int: Approximate token count.\n",
       "        \"\"\"</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 粗略计算token数，实际可使用更严格的tokenizer。\n",
       "        return len(text.split())</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _count_tokens_batch(self, texts: List[str]) -> List[int]:</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Count tokens for a batch of texts.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            texts (List[str]): Input texts.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[int]: List of token counts.\n",
       "        \"\"\"</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 批量计算token数。\n",
       "        return [self._count_tokens(t) for t in texts]</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _split_sentences(self, text: str) -> List[str]:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Fast sentence splitting while maintaining accuracy.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">This method is faster than using regex for sentence splitting and</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">more accurate than using spaCy sentence tokenizer.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            text (str): Input text to be split into sentences.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[str]: List of sentences.\n",
       "        \"\"\"</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        sentences = self.splitter.split_text(text)\n",
       "        return sentences</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _compute_similarity_threshold(self, all_similarities: List[float]) -> float:</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Compute similarity threshold based on percentile if specified.\"\"\"</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># 中文注释: 若设置了固定threshold则返回，否则按percentile计算。</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if self.similarity_threshold is not None:\n",
       "            return self.similarity_threshold</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">else:\n",
       "            return float(np.percentile(all_similarities, self.similarity_percentile))</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _prepare_sentences(self, text: str) -> List[SemanticSentence]:</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Prepare sentences with precomputed information.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            text (str): Input text to be processed.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">List[SemanticSentence]: List of Sentence objects with precomputed embeddings.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 将文本分句，计算句子embedding和token数，并构建SemanticSentence对象列表。</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if not text.strip():\n",
       "            return []</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">raw_sentences = self._split_sentences(text)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Compute start/end indices\n",
       "        sentence_indices = []\n",
       "        current_idx = 0</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for sent in raw_sentences:\n",
       "            start_idx = text.find(sent, current_idx)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">end_idx = start_idx + len(sent)</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sentence_indices.append((start_idx, end_idx))\n",
       "            current_idx = end_idx</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Create sentence groups for embedding computation\n",
       "        sentence_groups = []</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for i in range(len(raw_sentences)):\n",
       "            group = []</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for j in range(i - self.similarity_window, i + self.similarity_window + 1):</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if 0 <= j < len(raw_sentences):\n",
       "                    group.append(raw_sentences[j])</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sentence_groups.append(\"\".join(group))</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Compute embeddings</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">embeddings = self.embedding_model.embed_batch(sentence_groups)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Compute token counts\n",
       "        token_counts = self._count_tokens_batch(raw_sentences)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sentences = [\n",
       "            SemanticSentence(\n",
       "                text=sent,</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">start_index=start_idx,\n",
       "                end_index=end_idx,</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">token_count=count,\n",
       "                embedding=embedding,\n",
       "            )</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">)\n",
       "            for sent, (start_idx, end_idx), count, embedding in zip(</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">raw_sentences, sentence_indices, token_counts, embeddings\n",
       "            )\n",
       "        ]</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return sentences</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _get_semantic_similarity(\n",
       "        self, embedding1: np.ndarray, embedding2: np.ndarray</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> float:\n",
       "        \"\"\"Compute cosine similarity between two embeddings.\"\"\"</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># 中文注释: 简化调用embedding_model的similarity方法。</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return self.embedding_model.similarity(embedding1, embedding2)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _compute_group_embedding(self, sentences: List[SemanticSentence]) -> np.ndarray:</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Compute mean embedding for a group of sentences.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            np.ndarray: Mean embedding vector.\n",
       "        \"\"\"</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 加权平均，考虑token数对平均值的影响。\n",
       "        return np.divide(</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">np.sum([(sent.embedding * sent.token_count) for sent in sentences], axis=0),</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">np.sum([sent.token_count for sent in sentences]),\n",
       "            dtype=np.float32,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _compute_pairwise_similarities(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> List[float]:\n",
       "        \"\"\"Compute all pairwise similarities between sentences.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[float]: List of similarities between consecutive sentences.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 计算相邻句子间相似度。\n",
       "        return [\n",
       "            self._get_semantic_similarity(</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sentences[i].embedding, sentences[i + 1].embedding\n",
       "            )</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">)\n",
       "            for i in range(len(sentences) - 1)\n",
       "        ]</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _get_split_indices(\n",
       "        self, similarities: List[float], threshold: float = None</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> List[int]:\n",
       "        \"\"\"Get indices of sentences to split at.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            similarities (List[float]): List of pairwise similarities.</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">threshold (float): Similarity threshold.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[int]: Indices indicating the split points.\n",
       "        \"\"\"</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 根据相似度阈值确定分组的切分点。\n",
       "        if threshold is None:</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">threshold = (\n",
       "                self.similarity_threshold</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if self.similarity_threshold is not None\n",
       "                else 0.5\n",
       "            )</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Get indices of sentences that are below the threshold\n",
       "        splits = [</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">splits = [\n",
       "            i + 1\n",
       "            for i, s in enumerate(similarities)</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if s <= threshold and i + 1 < len(similarities) + 1\n",
       "        ]</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Add the start and end of the text</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">splits = [0] + splits + [len(similarities) + 1]</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Ensure minimum sentences per group\n",
       "        i = 0\n",
       "        while i < len(splits) - 1:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if splits[i + 1] - splits[i] < self.min_sentences:\n",
       "                splits.pop(i + 1)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">else:\n",
       "                i += 1\n",
       "        return splits</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _calculate_threshold_via_binary_search(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> float:\n",
       "        \"\"\"Calculate similarity threshold via binary search.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            float: Computed threshold.\n",
       "        \"\"\"</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 通过binary search来寻找合适的相似度阈值，使分块满足大小要求。</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">token_counts = [sent.token_count for sent in sentences]</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarities = self._compute_pairwise_similarities(sentences)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">median = np.median(similarities)\n",
       "        std = np.std(similarities)</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">low = max(median - 1 * std, 0.0)\n",
       "        high = min(median + 1 * std, 1.0)</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">iterations = 0\n",
       "        threshold = (low + high) / 2</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">while abs(high - low) > self.threshold_step:\n",
       "            threshold = (low + high) / 2</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">split_indices = self._get_split_indices(similarities, threshold)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Extract token counts of each segment\n",
       "            segment_lengths = []</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for i in range(len(split_indices) - 1):\n",
       "                start = split_indices[i]</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">end = split_indices[i + 1]</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">segment_token_count = sum(token_counts[start:end])</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">segment_lengths.append(segment_token_count)</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># Check condition: ideally segment lengths between min_chunk_size and chunk_size</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if all(\n",
       "                self.min_chunk_size <= length <= self.chunk_size</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for length in segment_lengths\n",
       "            ):\n",
       "                break</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">elif any(length > self.chunk_size for length in segment_lengths):</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># 若有超过chunk_size的分段，增加threshold降低分组数量</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">low = threshold + self.threshold_step\n",
       "            else:</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">else:\n",
       "                # 若有分段小于min_chunk_size，减少threshold增加分组数量</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">high = threshold - self.threshold_step</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">iterations += 1\n",
       "            if iterations > 10:\n",
       "                warnings.warn(</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"Too many iterations in threshold calculation, stopping...\",</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">stacklevel=2,\n",
       "                )\n",
       "                break</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return threshold</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _calculate_threshold_via_percentile(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> float:\n",
       "        \"\"\"Calculate similarity threshold via percentile.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            float: Computed threshold.\n",
       "        \"\"\"</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 根据percentile计算相似度阈值。</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">all_similarities = self._compute_pairwise_similarities(sentences)</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return float(np.percentile(all_similarities, 100 - self.similarity_percentile))</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _calculate_similarity_threshold(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> float:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Calculate similarity threshold either through binary search or percentile.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            float: Computed similarity threshold.\n",
       "        \"\"\"</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 根据配置决定使用固定值、percentile还是binary search。</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if self.similarity_threshold is not None:\n",
       "            return self.similarity_threshold</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">elif self.similarity_percentile is not None:</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return self._calculate_threshold_via_percentile(sentences)\n",
       "        else:</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">else:\n",
       "            return self._calculate_threshold_via_binary_search(sentences)</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _group_sentences_cumulative(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> List[List[SemanticSentence]]:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Group sentences based on cumulative semantic similarity.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[List[SemanticSentence]]: Grouped sentences.\n",
       "        \"\"\"</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 累计方式分组，根据当前组平均embedding与新句子的相似度决定是否加入同组。\n",
       "        groups = []</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">groups = []\n",
       "        if not sentences:\n",
       "            return groups</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_group = sentences[: self.initial_sentences]</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_embedding = self._compute_group_embedding(current_group)</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for sentence in sentences[self.initial_sentences :]:</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarity = self._get_semantic_similarity(</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_embedding, sentence.embedding\n",
       "            )</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">)\n",
       "            if similarity >= self.similarity_threshold:</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_group.append(sentence)</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_embedding = self._compute_group_embedding(current_group)\n",
       "            else:</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">else:\n",
       "                if current_group:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">groups.append(current_group)\n",
       "                current_group = [sentence]</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_embedding = sentence.embedding</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if current_group:\n",
       "            groups.append(current_group)\n",
       "\n",
       "        return groups</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _group_sentences_window(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> List[List[SemanticSentence]]:</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Group sentences based on semantic similarity using a window-based approach.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[List[SemanticSentence]]: Grouped sentences.\n",
       "        \"\"\"</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 窗口模式下根据相邻句子相似度和阈值分割。</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">similarities = self._compute_pairwise_similarities(sentences)</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">split_indices = self._get_split_indices(similarities, self.similarity_threshold)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">groups = [\n",
       "            sentences[split_indices[i] : split_indices[i + 1]]</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for i in range(len(split_indices) - 1)\n",
       "        ]\n",
       "        return groups</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _group_sentences(\n",
       "        self, sentences: List[SemanticSentence]</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> List[List[SemanticSentence]]:</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Group sentences based on semantic similarity, either cumulatively or by window.</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[List[SemanticSentence]]: Grouped sentences.\n",
       "        \"\"\"</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 根据mode选择分组方式。\n",
       "        if self.mode == \"cumulative\":</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return self._group_sentences_cumulative(sentences)\n",
       "        else:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">else:\n",
       "            return self._group_sentences_window(sentences)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _create_chunk(self, sentences: List[SemanticSentence]) -> SemanticChunk:</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Create a chunk from a list of sentences.</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            sentences (List[SemanticSentence]): Input sentences.</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            SemanticChunk: Created chunk.\n",
       "        \"\"\"</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 将句子列表合并为一个chunk，并计算chunk的embedding。\n",
       "        if not sentences:</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">raise ValueError(\"Cannot create chunk from empty sentence list\")</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">text = \"\".join(sent.text for sent in sentences)</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">token_count = sum(sent.token_count for sent in sentences) + (len(sentences) - 1)</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># 在这里计算并存储chunk级别的embedding</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunk_embedding = self._compute_group_embedding(sentences)</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return SemanticChunk(\n",
       "            text=text,</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">start_index=sentences[0].start_index,\n",
       "            end_index=sentences[-1].end_index,</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">token_count=token_count,\n",
       "            sentences=sentences,</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunk_embedding=chunk_embedding,\n",
       "        )</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def _split_chunks(\n",
       "        self, sentence_groups: List[List[SemanticSentence]]</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">) -> List[SemanticChunk]:\n",
       "        \"\"\"Split sentence groups into chunks that respect chunk_size.</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sentence_groups (List[List[SemanticSentence]]): Semantically coherent sentence groups.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:\n",
       "            List[SemanticChunk]: List of SemanticChunk objects.\n",
       "        \"\"\"</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 将句子组按照chunk_size划分为更小的chunk。\n",
       "        chunks = []</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for group in sentence_groups:\n",
       "            current_chunk_sentences = []</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_tokens = 0</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">for sentence in group:\n",
       "                test_tokens = (</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_tokens\n",
       "                    + sentence.token_count</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">+ (1 if current_chunk_sentences else 0)\n",
       "                )</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if test_tokens <= self.chunk_size:</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_chunk_sentences.append(sentence)</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_tokens = test_tokens\n",
       "                else:</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if current_chunk_sentences:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunks.append(self._create_chunk(current_chunk_sentences))</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_chunk_sentences = [sentence]</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">current_tokens = sentence.token_count</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">if current_chunk_sentences:</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunks.append(self._create_chunk(current_chunk_sentences))</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return chunks</span> <span style=\"background-color: lightgreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">def chunk(self, text: str) -> List[SemanticChunk]:</span> <span style=\"background-color: lightpink; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"Split text into semantically coherent chunks using a two-pass approach.</span> <span style=\"background-color: lightyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Args:\n",
       "            text (str): Input text to be chunked.</span> <span style=\"background-color: lightcoral; padding: 2px 4px; border-radius: 3px; margin: 1px;\">Returns:</span> <span style=\"background-color: lightsalmon; padding: 2px 4px; border-radius: 3px; margin: 1px;\">List[SemanticChunk]: List of SemanticChunk objects containing chunked text and</span> <span style=\"background-color: lightseagreen; padding: 2px 4px; border-radius: 3px; margin: 1px;\">chunked text and metadata.</span> <span style=\"background-color: lightsteelblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\">\"\"\"\n",
       "        # 中文注释: 主流程：先准备句子与embedding，再计算相似度阈值，然后分组和二次分块。\n",
       "        if not text.strip():</span> <span style=\"background-color: lightgoldenrodyellow; padding: 2px 4px; border-radius: 3px; margin: 1px;\">return []</span> <span style=\"background-color: lightcyan; padding: 2px 4px; border-radius: 3px; margin: 1px;\">sentences = self._prepare_sentences(text)\n",
       "        if len(sentences) <= self.min_sentences:</span> <span style=\"background-color: lightblue; padding: 2px 4px; border-radius: 3px; margin: 1px;\"># 所有句子过少，直接作为一个chunk返回\n",
       "            if sentences:\n",
       "                return [s</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 20000\n",
    "highlighter = TextHighlighter(\n",
    "    long_text=sample_text,\n",
    "    chunking_api=splitter.split_text,\n",
    "    max_length=max_len\n",
    ")\n",
    "\n",
    "# 显示高亮文本\n",
    "highlighter.display_highlighted_text()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
